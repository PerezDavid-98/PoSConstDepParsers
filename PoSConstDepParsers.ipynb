{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["aEMUF-xuVEH2","_I_WPl79VHnp","oHrkpkyhxX9a","c6VU6P5w4awd","pK0A698p4fOf","K9SL_9Y4z7Yb","ay8X0iHA0WBv","ljQjP4-7nK_N","c-MCiHuGpAHk","nBt474W_phHs","fImxQoHRo9eW","kuvlTY49pmQq","yANyli90pwcL","t6uv29IipuJC","bp7_9tQQBy05","u8XBK5zfp0QY","njIh8dhuqEMW","lzSGgCkvqBZh","7yAxbQvtCNZ9","SIJseqKtCAs4","ek6JOk8SR3Oq","1H2RS2yOC3RU","YlLyrIR8pQB_","ZcraIbcu4iup","UNcUWTAh6g9e","scA6d3VK7aGo","aggZJWFCxfn4","L0JY5TzXxph8","HfvqkLumFM9w","3_rCT4deD4_o","dOPhn2MPEMGa","DrRA-lTXEsBO","UKEDp6wGEsBU","RkkcLEELEsBW","EoLx6UHKEsBc","1G193zPLEsBe","JKfXXg-TEwmX","SsZunAluEwmZ","F4mD2Nx4Ewma","x4xf96bcEwmb","WNGMaGviEwmc","xcGTck8-Ewmc","WXJIzEZBEwmd","E42T_YU9yC8P","-a6OdrMV08-7","UaBFLX1TGYSl","_bL7GrsUGYSm","rXHQeUSVGYSm","F5YVNWdZGYSm","P02x9RcCGcNP","7UXC-nfxGcNQ","TRD3hZToGcNR","3sbduyW7GcNS","0Cg6Cj0DGcNT","R4RfxFcqGcNT","LBekKfIwGcNT","dvObytnDGf4K","Bor3e25mGf4N","MM3X6q4-Gf4O"],"gpuType":"T4","authorship_tag":"ABX9TyMFkStUQjVEMb5h3yd3uqkW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"4d4cdefcb8314247a29817eab82ea0ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1342393725b641caaf4baa8560bd5241","IPY_MODEL_53691b24fbf84c5b95466e16b9a58f1c","IPY_MODEL_987a43e428174e1b887d5e4ad57e389d"],"layout":"IPY_MODEL_0b25c2355bf74d75bd50083cf37a4dd4"}},"1342393725b641caaf4baa8560bd5241":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3435c58daa349488cebf32dfa8333df","placeholder":"​","style":"IPY_MODEL_0ac5cc09769a4120bdc71c6d6edcf553","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "}},"53691b24fbf84c5b95466e16b9a58f1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04c6048aa4df411986323b7590f5c028","max":46620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12e5338dbb2448ffacd739355dc84727","value":46620}},"987a43e428174e1b887d5e4ad57e389d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4e5db1a96d549cfa9fe38f7281050d6","placeholder":"​","style":"IPY_MODEL_c97d07b6a84d4a6d98016b3671915933","value":" 373k/? [00:00&lt;00:00, 15.3MB/s]"}},"0b25c2355bf74d75bd50083cf37a4dd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3435c58daa349488cebf32dfa8333df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ac5cc09769a4120bdc71c6d6edcf553":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04c6048aa4df411986323b7590f5c028":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12e5338dbb2448ffacd739355dc84727":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4e5db1a96d549cfa9fe38f7281050d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c97d07b6a84d4a6d98016b3671915933":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"044dcc7daa104db5a09c7ccd95caf875":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55a2f5d0ac3b4ee491dc2e0c4f960ee2","IPY_MODEL_ac96442e287d4f948b338930c3422507","IPY_MODEL_7b585495d9dc42198b413e3eb69a7642"],"layout":"IPY_MODEL_c0a9217cb6ea4a0d825b8997f76fc737"}},"55a2f5d0ac3b4ee491dc2e0c4f960ee2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1273db334464dcf82fbdbd1ad0f87b6","placeholder":"​","style":"IPY_MODEL_b5351dbb0e1a4c1babd7c9d42ce88872","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/tokenize/combined.pt: 100%"}},"ac96442e287d4f948b338930c3422507":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f125096f30c74934a78d981abbc6ec9c","max":636823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc51249f04674c0cb5cdf9605c0d0ac0","value":636823}},"7b585495d9dc42198b413e3eb69a7642":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9a5b2d9bbc44a2824d4a8649781885","placeholder":"​","style":"IPY_MODEL_66c0d5b2c25e45cba46a8dd38ee271c2","value":" 637k/637k [00:00&lt;00:00, 10.8MB/s]"}},"c0a9217cb6ea4a0d825b8997f76fc737":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1273db334464dcf82fbdbd1ad0f87b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5351dbb0e1a4c1babd7c9d42ce88872":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f125096f30c74934a78d981abbc6ec9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc51249f04674c0cb5cdf9605c0d0ac0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a9a5b2d9bbc44a2824d4a8649781885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66c0d5b2c25e45cba46a8dd38ee271c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c171673696b4420b9fbe8f4e8d9e393f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b0742b0ec084d0caf8a5459b28f73d5","IPY_MODEL_add7c43e5ef049fe82c5e41bbb2204ff","IPY_MODEL_980d63d47faf4be49981b8b2ec918284"],"layout":"IPY_MODEL_e55fd040b4cf414aa1341a44ccd80e44"}},"5b0742b0ec084d0caf8a5459b28f73d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_737beac83216446899e992ee78a55ea0","placeholder":"​","style":"IPY_MODEL_d303515bffda499087af421d69a76a7f","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/mwt/combined.pt: 100%"}},"add7c43e5ef049fe82c5e41bbb2204ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_178bdddf4a63449ea4a3a3df1e9d1dd0","max":1167937,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9dd05edf7c0a467eafdbd649df2b390a","value":1167937}},"980d63d47faf4be49981b8b2ec918284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3324aebe97bb48f4b1c62b1bd09ab7ca","placeholder":"​","style":"IPY_MODEL_98b8a0646f1345179d54cb88ecf2fdde","value":" 1.17M/1.17M [00:00&lt;00:00, 15.6MB/s]"}},"e55fd040b4cf414aa1341a44ccd80e44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737beac83216446899e992ee78a55ea0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d303515bffda499087af421d69a76a7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"178bdddf4a63449ea4a3a3df1e9d1dd0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9dd05edf7c0a467eafdbd649df2b390a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3324aebe97bb48f4b1c62b1bd09ab7ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b8a0646f1345179d54cb88ecf2fdde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c2075215f9e4ea384e98eb26d4ea1de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bd69c039cf9495f81f291391b448779","IPY_MODEL_e2568143e60f4743a38900355918566b","IPY_MODEL_267fa8ae5c8646d99537d4763c31a656"],"layout":"IPY_MODEL_7c3cdb7b20da4787aa12ce3e59f141b2"}},"5bd69c039cf9495f81f291391b448779":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85bdadb2a50c467aa2ba18c33f92f13f","placeholder":"​","style":"IPY_MODEL_463d289f9b8a4d3cae96b27e863a802a","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/pos/combined_charlm.pt: 100%"}},"e2568143e60f4743a38900355918566b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e5ec59d15447a4a118950df95db00d","max":35016044,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4df7243839e6433da8024e5ce69e85b4","value":35016044}},"267fa8ae5c8646d99537d4763c31a656":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c662370eb8da4167a28fd2bd74b54b70","placeholder":"​","style":"IPY_MODEL_8d40b5779be34685913e99132f22f4d6","value":" 35.0M/35.0M [00:00&lt;00:00, 96.1MB/s]"}},"7c3cdb7b20da4787aa12ce3e59f141b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85bdadb2a50c467aa2ba18c33f92f13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"463d289f9b8a4d3cae96b27e863a802a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e5ec59d15447a4a118950df95db00d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4df7243839e6433da8024e5ce69e85b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c662370eb8da4167a28fd2bd74b54b70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d40b5779be34685913e99132f22f4d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9e5e16049054d87bc3fa1ec5a6e868d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc70fd99697b44dda94c6c04ee47bfa1","IPY_MODEL_83fa9a0b812f42dbb1e99bbb9359251f","IPY_MODEL_352b5289f47848d7bcb77afccc4e6bbe"],"layout":"IPY_MODEL_cd6a61d5e4ce423095576f9dfb801fbf"}},"fc70fd99697b44dda94c6c04ee47bfa1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3ad738d1258483b8d8eabbf576b4888","placeholder":"​","style":"IPY_MODEL_62cd263d095d4209951e359511423a71","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/lemma/combined_nocharlm.pt: 100%"}},"83fa9a0b812f42dbb1e99bbb9359251f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56f45fdf8ac9490ab1d701cbf1ae7b35","max":5715177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27995e8a9e5c4a3b8dbdfb920206db30","value":5715177}},"352b5289f47848d7bcb77afccc4e6bbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cd991219aa9406c872ca104df9c5fe1","placeholder":"​","style":"IPY_MODEL_c5c36360e8ec45b5938338972c12259e","value":" 5.72M/5.72M [00:00&lt;00:00, 36.6MB/s]"}},"cd6a61d5e4ce423095576f9dfb801fbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3ad738d1258483b8d8eabbf576b4888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62cd263d095d4209951e359511423a71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56f45fdf8ac9490ab1d701cbf1ae7b35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27995e8a9e5c4a3b8dbdfb920206db30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5cd991219aa9406c872ca104df9c5fe1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c36360e8ec45b5938338972c12259e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e8aae2a311d4128a92ef110cbbd2553":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74c979dc12664848b8dcfa3da796f355","IPY_MODEL_3558067f53f84896b7329da0ac059271","IPY_MODEL_f980bf555420440884e77f9e3bf5a41c"],"layout":"IPY_MODEL_a386da73afca4af9ac3206564a669226"}},"74c979dc12664848b8dcfa3da796f355":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb923d0b4954c9ab783f30573c8b010","placeholder":"​","style":"IPY_MODEL_6699f150d5f74aafa36dc45fa6d74453","value":"Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/depparse/combined_charlm.pt: 100%"}},"3558067f53f84896b7329da0ac059271":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0c0d1177d454dca8f461b49ef5abf9f","max":148755694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19f995d082b6471ab46a4b774d10a675","value":148755694}},"f980bf555420440884e77f9e3bf5a41c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f18873462a848afa6cd474c3fd5f9f2","placeholder":"​","style":"IPY_MODEL_b53334c0b8da4affabe687edba4d2ff8","value":" 149M/149M [00:02&lt;00:00, 65.0MB/s]"}},"a386da73afca4af9ac3206564a669226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeb923d0b4954c9ab783f30573c8b010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6699f150d5f74aafa36dc45fa6d74453":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0c0d1177d454dca8f461b49ef5abf9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19f995d082b6471ab46a4b774d10a675":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f18873462a848afa6cd474c3fd5f9f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b53334c0b8da4affabe687edba4d2ff8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f50785f4b2784255baf4558cddf98dae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29b1eeab5f1247ec8cfe2e2e2907e498","IPY_MODEL_b36b97f51ceb4ba0b4c7293e683e7b83","IPY_MODEL_98dce7c1d29e4dc49c2aa1c12ef12c78"],"layout":"IPY_MODEL_6387b73078ff49fda582a7e13a224ca5"}},"29b1eeab5f1247ec8cfe2e2e2907e498":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daf627957dcb46eea10ad8ece7c77a49","placeholder":"​","style":"IPY_MODEL_a185bd4dd53843c8a023cc1425a2396e","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "}},"b36b97f51ceb4ba0b4c7293e683e7b83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2e7ee324f064007a69f8862c7697545","max":46620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7f3baf0aeab74b4c9da89c6fe871b0f7","value":46620}},"98dce7c1d29e4dc49c2aa1c12ef12c78":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0439068979034bc5bf8f20f0d25106f6","placeholder":"​","style":"IPY_MODEL_d44762014b3f48fda32cc49ae4d91993","value":" 373k/? [00:00&lt;00:00, 18.0MB/s]"}},"6387b73078ff49fda582a7e13a224ca5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"daf627957dcb46eea10ad8ece7c77a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a185bd4dd53843c8a023cc1425a2396e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2e7ee324f064007a69f8862c7697545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f3baf0aeab74b4c9da89c6fe871b0f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0439068979034bc5bf8f20f0d25106f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d44762014b3f48fda32cc49ae4d91993":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bef3d218eed4ece933caec2887099ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fb3704833844045bd6702f6ba806c5d","IPY_MODEL_7608631d25bd4c9aa3c08bb123384d20","IPY_MODEL_6968157f5531408ca20aa16e06bd5a81"],"layout":"IPY_MODEL_46814b3b2edd49f5afaf563e705f47f0"}},"2fb3704833844045bd6702f6ba806c5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06865aeda00f4ac9a3b145df05a51913","placeholder":"​","style":"IPY_MODEL_56a22399db0147129312199298aee76c","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "}},"7608631d25bd4c9aa3c08bb123384d20":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f6a9fe9e7d7475e92cd170de6689c63","max":46620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42dcfa0e80b046fea76763cf16ecf58b","value":46620}},"6968157f5531408ca20aa16e06bd5a81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c991073a117a46be97acbf9b802eaa81","placeholder":"​","style":"IPY_MODEL_eaa0c134fd124f26b3f4781f7ac33576","value":" 373k/? [00:00&lt;00:00, 17.5MB/s]"}},"46814b3b2edd49f5afaf563e705f47f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06865aeda00f4ac9a3b145df05a51913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56a22399db0147129312199298aee76c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f6a9fe9e7d7475e92cd170de6689c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42dcfa0e80b046fea76763cf16ecf58b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c991073a117a46be97acbf9b802eaa81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaa0c134fd124f26b3f4781f7ac33576":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ca4ae733d5543cf8a0368e72c9a4146":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1edc6fa3be0741e6b1ba86556d588c7d","IPY_MODEL_de3206b40f3240679cd760b0e8330d70","IPY_MODEL_f496c5f7f887463692270ff0f190395e"],"layout":"IPY_MODEL_62bb6af2f3ed414696dc810902c9c58c"}},"1edc6fa3be0741e6b1ba86556d588c7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97cc4c0b625743e0a2602269a0c2bc35","placeholder":"​","style":"IPY_MODEL_18864426d29b4ee68a7d99e0085b6169","value":"Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/tokenize/syntagrus.pt: 100%"}},"de3206b40f3240679cd760b0e8330d70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a29aadbc7aa4e39b8d9b1ec9b18ea6f","max":641177,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4f55b43c456458e95c2465c0f99ce2a","value":641177}},"f496c5f7f887463692270ff0f190395e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_876c68bbd15a44de919f7efb5e1b9e41","placeholder":"​","style":"IPY_MODEL_dc171a3f94474a2c913e02380bcc2852","value":" 641k/641k [00:00&lt;00:00, 8.88MB/s]"}},"62bb6af2f3ed414696dc810902c9c58c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97cc4c0b625743e0a2602269a0c2bc35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18864426d29b4ee68a7d99e0085b6169":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0a29aadbc7aa4e39b8d9b1ec9b18ea6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4f55b43c456458e95c2465c0f99ce2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"876c68bbd15a44de919f7efb5e1b9e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc171a3f94474a2c913e02380bcc2852":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c167801ef664f9b82f93ee7a585e148":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a55239c124b4847b2f1a722c1a5e097","IPY_MODEL_003a127f7de44397a3e62ea91382b859","IPY_MODEL_71e654423b674d469fb66f866218f4b6"],"layout":"IPY_MODEL_90989651f0e548078bdc0a7810579cc7"}},"8a55239c124b4847b2f1a722c1a5e097":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd797a8636bd4b8a887dc5dd1168d623","placeholder":"​","style":"IPY_MODEL_777b5308aec64be1bf97bea98fb7c167","value":"Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/pos/syntagrus_charlm.pt: 100%"}},"003a127f7de44397a3e62ea91382b859":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a3ea1b08caa3448a87fbc1a703a8ed43","max":38766719,"min":0,"orientation":"horizontal","style":"IPY_MODEL_babd3748a7d84299a7afcf419c2f689d","value":38766719}},"71e654423b674d469fb66f866218f4b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35566139333549f4a6d87cde53983fd4","placeholder":"​","style":"IPY_MODEL_b05fb043f30e4eb795c858953f60e72c","value":" 38.8M/38.8M [00:00&lt;00:00, 85.0MB/s]"}},"90989651f0e548078bdc0a7810579cc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd797a8636bd4b8a887dc5dd1168d623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"777b5308aec64be1bf97bea98fb7c167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a3ea1b08caa3448a87fbc1a703a8ed43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"babd3748a7d84299a7afcf419c2f689d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35566139333549f4a6d87cde53983fd4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b05fb043f30e4eb795c858953f60e72c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c258837b4c5e47c6a03d8e07530a8760":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f533087aa2d4a48b62752f270b364d8","IPY_MODEL_b1b8650baf7441d9850df538f133f691","IPY_MODEL_4f003351e6664c29bc0fdd1da0b41df2"],"layout":"IPY_MODEL_68ed1d8e8b854457b19f9b67889a9091"}},"2f533087aa2d4a48b62752f270b364d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c17ed8d25fba440e928f7d932ccf76df","placeholder":"​","style":"IPY_MODEL_e29fbd283fb64bd68cb2331c25031695","value":"Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/lemma/syntagrus_nocharlm.pt: 100%"}},"b1b8650baf7441d9850df538f133f691":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84fe3705b637423898ce8ae2ad0ea935","max":13489832,"min":0,"orientation":"horizontal","style":"IPY_MODEL_db1f9cd9c4f24633b4c18679ab476de4","value":13489832}},"4f003351e6664c29bc0fdd1da0b41df2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb04f3e043784b8ab95fd8dc51c67081","placeholder":"​","style":"IPY_MODEL_f61566ea259f419daaf1661a974a8f8e","value":" 13.5M/13.5M [00:00&lt;00:00, 44.4MB/s]"}},"68ed1d8e8b854457b19f9b67889a9091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c17ed8d25fba440e928f7d932ccf76df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e29fbd283fb64bd68cb2331c25031695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84fe3705b637423898ce8ae2ad0ea935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db1f9cd9c4f24633b4c18679ab476de4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb04f3e043784b8ab95fd8dc51c67081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f61566ea259f419daaf1661a974a8f8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff0f3acc08f940f0b8b8f23069fb2d70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21ff49fcc05a4f1f8f14ef5eaa20e1a7","IPY_MODEL_5f660bdf8fa44170831a288cee1ff9e5","IPY_MODEL_357d202d412042fcbc8ef3ab684bc1d4"],"layout":"IPY_MODEL_4245d8d606384b589e34a918fdfe42c7"}},"21ff49fcc05a4f1f8f14ef5eaa20e1a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff61a4b781e4792b100d3712ba6d893","placeholder":"​","style":"IPY_MODEL_086e0a7d66984e8e90a053eccc43ad7c","value":"Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/depparse/syntagrus_charlm.pt: 100%"}},"5f660bdf8fa44170831a288cee1ff9e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e85bc099a97a467fae6310ffbab241d0","max":146831059,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5e3c1ec1b3c433e8c89b40baa30ce56","value":146831059}},"357d202d412042fcbc8ef3ab684bc1d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dbbb7f18cad4f59a20412b648589faa","placeholder":"​","style":"IPY_MODEL_68ac7220e695437499571bd993e32371","value":" 147M/147M [00:02&lt;00:00, 69.7MB/s]"}},"4245d8d606384b589e34a918fdfe42c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ff61a4b781e4792b100d3712ba6d893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"086e0a7d66984e8e90a053eccc43ad7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e85bc099a97a467fae6310ffbab241d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5e3c1ec1b3c433e8c89b40baa30ce56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dbbb7f18cad4f59a20412b648589faa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ac7220e695437499571bd993e32371":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5970587f545348f2b35b918fbffcf2b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1277f9a1b517449bbbf05ade931580bb","IPY_MODEL_10db060c4e1b40858db5d7662ac1e8ad","IPY_MODEL_c67b212bf15f46d5aad146041ab0946f"],"layout":"IPY_MODEL_885266e609764cc894c267f6a6c85792"}},"1277f9a1b517449bbbf05ade931580bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91e60356d4724dd19c9ce1a2344cc344","placeholder":"​","style":"IPY_MODEL_3e2a12caa34441faaec05ddfd57e4325","value":"Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip: 100%"}},"10db060c4e1b40858db5d7662ac1e8ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9836f24765cf466cb598c9dcbc1532e2","max":505656981,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdb2ab5a4af246e59f469cc279596750","value":505656981}},"c67b212bf15f46d5aad146041ab0946f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2006d35e13c8446583db94516ea5cb19","placeholder":"​","style":"IPY_MODEL_2b4da8dc37e04daf965420b6976c943f","value":" 506M/506M [00:40&lt;00:00, 15.5MB/s]"}},"885266e609764cc894c267f6a6c85792":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91e60356d4724dd19c9ce1a2344cc344":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e2a12caa34441faaec05ddfd57e4325":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9836f24765cf466cb598c9dcbc1532e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdb2ab5a4af246e59f469cc279596750":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2006d35e13c8446583db94516ea5cb19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b4da8dc37e04daf965420b6976c943f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4d59602bc954acf8c7655a46cb90a62":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c5ee07ec6f04a20a1191deb3d3e4433","IPY_MODEL_f39bc92762424d7b90578ad27aea6cfb","IPY_MODEL_7cb2ee6f762c4543aaf4d0c3b7accc83"],"layout":"IPY_MODEL_eeff787662374cfeaec6eda78ae2316d"}},"5c5ee07ec6f04a20a1191deb3d3e4433":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74dc4dbad3ec404f91e4c7504bb39ac3","placeholder":"​","style":"IPY_MODEL_55c79d28eca747bda2b95c646cc8e1af","value":"Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: "}},"f39bc92762424d7b90578ad27aea6cfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8c3300954b842c397addaba3a0c0838","max":47208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d822cdbb879c45d7aff9d7ad6f40f104","value":47208}},"7cb2ee6f762c4543aaf4d0c3b7accc83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d369392d35fd4442bdfe6c839f854bb1","placeholder":"​","style":"IPY_MODEL_36ebe0fec7474b71b7b427e24f2f28b6","value":" 379k/? [00:00&lt;00:00, 19.1MB/s]"}},"eeff787662374cfeaec6eda78ae2316d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74dc4dbad3ec404f91e4c7504bb39ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55c79d28eca747bda2b95c646cc8e1af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8c3300954b842c397addaba3a0c0838":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d822cdbb879c45d7aff9d7ad6f40f104":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d369392d35fd4442bdfe6c839f854bb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36ebe0fec7474b71b7b427e24f2f28b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9fdbc387cfbd4d2cac947bf9adab450f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7192a62689f84eeea3f3c09b67a03057","IPY_MODEL_8839fdc829a74229bfabb8d68cc604d2","IPY_MODEL_a7fa62cc299f4b62bf3186d61a063e87"],"layout":"IPY_MODEL_471cc6408f274dfa9590f59b0f950d38"}},"7192a62689f84eeea3f3c09b67a03057":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7622f296092d41c5b81147af14216a48","placeholder":"​","style":"IPY_MODEL_942b6d893d084bb3bd8f421394cf33ef","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt: 100%"}},"8839fdc829a74229bfabb8d68cc604d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dbc258d8de840f991287c2d965483f5","max":650849,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74386b8e349c4fb0856b7daba873902c","value":650849}},"a7fa62cc299f4b62bf3186d61a063e87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_860b1ed750594136b9dead5cfe8314f8","placeholder":"​","style":"IPY_MODEL_1a8a9b089e1845949530bc9b5a0b0b71","value":" 651k/651k [00:00&lt;00:00, 7.60MB/s]"}},"471cc6408f274dfa9590f59b0f950d38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7622f296092d41c5b81147af14216a48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"942b6d893d084bb3bd8f421394cf33ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dbc258d8de840f991287c2d965483f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74386b8e349c4fb0856b7daba873902c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"860b1ed750594136b9dead5cfe8314f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8a9b089e1845949530bc9b5a0b0b71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b6f2d90b12274b0bbd6896a8b9b853a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_253c81d1d105447a8ec8cf4e073f4923","IPY_MODEL_a90993f10612441fac9270b1b84256b9","IPY_MODEL_e17456ae56cf4a27b81785be9261fab9"],"layout":"IPY_MODEL_5e3f7adab11a4e2c9e0b8ed3946ca818"}},"253c81d1d105447a8ec8cf4e073f4923":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eee1b13d5c2046eebc8506b65fb30431","placeholder":"​","style":"IPY_MODEL_0303000f8b0c463a8b1c480e7bcb8872","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/mwt/combined.pt: 100%"}},"a90993f10612441fac9270b1b84256b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_27c9de3071a34ea086d0e4acf0cb67c3","max":615741,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21240e9a396e47f485ebe48c155f983a","value":615741}},"e17456ae56cf4a27b81785be9261fab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_025f602258bf475ba42212007eba1c1f","placeholder":"​","style":"IPY_MODEL_6124840ff9bd4411bf5842cb60e39585","value":" 616k/616k [00:00&lt;00:00, 13.3MB/s]"}},"5e3f7adab11a4e2c9e0b8ed3946ca818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee1b13d5c2046eebc8506b65fb30431":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0303000f8b0c463a8b1c480e7bcb8872":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"27c9de3071a34ea086d0e4acf0cb67c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21240e9a396e47f485ebe48c155f983a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"025f602258bf475ba42212007eba1c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6124840ff9bd4411bf5842cb60e39585":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9acedf82f49f48c585ec58540310e374":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9096ec9d7aaf4251865a660c6de4efb5","IPY_MODEL_d6b9c893f57143938c44201dc6a538a5","IPY_MODEL_2c284a2e97b44480a2faad5027c79e32"],"layout":"IPY_MODEL_cdff387092074444b52117f1aca35558"}},"9096ec9d7aaf4251865a660c6de4efb5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_462e1d41b40c4e9cbd7749b326a79d70","placeholder":"​","style":"IPY_MODEL_87f8a31b30df40c8b36c19d5e36405fe","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pos/combined_charlm.pt: 100%"}},"d6b9c893f57143938c44201dc6a538a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18e329d1be494f8bb539143d38f4d935","max":38554272,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d172b2de5953401a9f03caff3af9781e","value":38554272}},"2c284a2e97b44480a2faad5027c79e32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9ea9bcd04784e42ace35b11cf9113ae","placeholder":"​","style":"IPY_MODEL_e97e91b3231b4667a332548f2426e606","value":" 38.6M/38.6M [00:00&lt;00:00, 66.8MB/s]"}},"cdff387092074444b52117f1aca35558":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"462e1d41b40c4e9cbd7749b326a79d70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87f8a31b30df40c8b36c19d5e36405fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18e329d1be494f8bb539143d38f4d935":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d172b2de5953401a9f03caff3af9781e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f9ea9bcd04784e42ace35b11cf9113ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e97e91b3231b4667a332548f2426e606":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3881b394d1d4e4fa0f54972bd82f25e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_35aa2d2b3c7343ddab32bf10df25ab73","IPY_MODEL_477d0c4d1fe5485382d8a5d50b60fda1","IPY_MODEL_58993144f29f4ce281bb42b2c1a4202c"],"layout":"IPY_MODEL_e7c6e6adac9c4ca1b6018940bb9a51e5"}},"35aa2d2b3c7343ddab32bf10df25ab73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dc6ffdc2f2448ddb0896799aeeed076","placeholder":"​","style":"IPY_MODEL_1749ae76d4854c6dadf5e98236e60406","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/lemma/combined_nocharlm.pt: 100%"}},"477d0c4d1fe5485382d8a5d50b60fda1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3670b79e081540f494f49a280ebc0156","max":4232801,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6eb5983c01742d08eced3dffe3df694","value":4232801}},"58993144f29f4ce281bb42b2c1a4202c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e107fb3b1f704ea5a3e9b582b7f60136","placeholder":"​","style":"IPY_MODEL_05a06baf9b204439986501b63b69860d","value":" 4.23M/4.23M [00:00&lt;00:00, 55.2MB/s]"}},"e7c6e6adac9c4ca1b6018940bb9a51e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dc6ffdc2f2448ddb0896799aeeed076":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1749ae76d4854c6dadf5e98236e60406":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3670b79e081540f494f49a280ebc0156":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6eb5983c01742d08eced3dffe3df694":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e107fb3b1f704ea5a3e9b582b7f60136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a06baf9b204439986501b63b69860d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"283b72fd8ce242439c719e44f2cde749":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_100a267e1cf34717acf755dd1a12ec2e","IPY_MODEL_4c6d2b12558b4ba49696fbbd5bff036a","IPY_MODEL_62bb1556ee144b2397cc3411d2f02e75"],"layout":"IPY_MODEL_20d9f74e159f462f90f7796500636a14"}},"100a267e1cf34717acf755dd1a12ec2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e94cd15ba264fe692abe6829d162abd","placeholder":"​","style":"IPY_MODEL_6beecfdc4ffd4ef1ace45e76973dd5c4","value":"Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/depparse/combined_charlm.pt: 100%"}},"4c6d2b12558b4ba49696fbbd5bff036a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_381f76bedbc242319932df8784fb52c2","max":145409414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e4c5e35b7c54abeb50c1c20a4d2c78e","value":145409414}},"62bb1556ee144b2397cc3411d2f02e75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d3424ebd3784e2296bdebf3c643bb56","placeholder":"​","style":"IPY_MODEL_e926cfa7471542db97e1a618200a905c","value":" 145M/145M [00:00&lt;00:00, 216MB/s]"}},"20d9f74e159f462f90f7796500636a14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e94cd15ba264fe692abe6829d162abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6beecfdc4ffd4ef1ace45e76973dd5c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"381f76bedbc242319932df8784fb52c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e4c5e35b7c54abeb50c1c20a4d2c78e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d3424ebd3784e2296bdebf3c643bb56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e926cfa7471542db97e1a618200a905c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# EJERCICIO 1. ENTRENAMIENTO Y ETIQUETACIÓN CON PoS TAGGERS"],"metadata":{"id":"aEMUF-xuVEH2"}},{"cell_type":"markdown","source":["## **(a)** CON MODELOS PRE-ENTRENADOS (ELEGIBLE, 0.75 PUNTOS)\n","\n","Buscar y descargar un etiquetador(es) de uso libre que incluya ya modelos pre-entrenados para dos idiomas: (1) inglés y (2) alguna lengua romance.  Etiquetar con él un fichero de texto (.txt) de 10.000 palabras (aprox.) para cada idioma.\n","\n","\n","ENTREGABLES:\n","\n","Para cada tagger empleado se incluirá en la memoria un apartado en el que se analicen sus características (modelo en el que se basa, etc.), URL de la web donde se obtuvo, si fue necesario preprocesar el texto de entrada y cómo, un breve análisis de la salida obtenida, etc. Asimismo, se adjuntará un fichero comprimido que contenga un subdirectorio por idioma y, dentro de cada uno:\n","*\tUn fichero de texto indicando la URL de la fuente original del texto etiquetado (URL.txt),\n","*\tEl fichero de texto de entrada en bruto a etiquetar (INPUT_RAW.txt)\n","*\tUna copia de la salida del tagger para dicha entrada (OUTPUT_RAW.txt).\n"],"metadata":{"id":"_I_WPl79VHnp"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import random as rn\n","from google.colab import drive"],"metadata":{"id":"IQmCBM88nPZ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qgjpTpc74Y8U","executionInfo":{"status":"ok","timestamp":1709464131989,"user_tz":-60,"elapsed":20767,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"3c3d5f2f-a86e-4fca-d67d-d3d8f1a01767"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### Preprocesado de los datos\n","\n","En esta seccion se preprocesan los datasets obtenidos para que se ajusten a las necesidades del problema."],"metadata":{"id":"oHrkpkyhxX9a"}},{"cell_type":"markdown","source":["#### EN"],"metadata":{"id":"c6VU6P5w4awd"}},{"cell_type":"code","source":["!unzip -n '/content/gdrive/MyDrive/PLN/1/(a)/EN_Blogger_Corpus.zip' >> /dev/null\n","\n","# Especificamos los paths\n","en_raw_text_path = \"/content/gdrive/MyDrive/PLN/1/(a)/EN/\"\n","en_raw_text_file_name = \"INPUT_RAW.txt\"\n","en_complete_path = en_raw_text_path + en_raw_text_file_name\n","en_corpus_dataset = \"blogtext.csv\""],"metadata":{"id":"dafVC9o_2N8O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el csv como dataframe\n","blogtext_df = pd.read_csv(en_corpus_dataset, usecols=[6])\n","print(blogtext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXe9AYAj4w2K","executionInfo":{"status":"ok","timestamp":1709389951466,"user_tz":-60,"elapsed":11197,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"2cc5ed32-b226-473a-9724-f3f97465ca02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text\n","0             Info has been found (+/- 100 pages,...\n","1             These are the team members:   Drewe...\n","2             In het kader van kernfusie op aarde...\n","3                   testing!!!  testing!!!          \n","4               Thanks to Yahoo!'s Toolbar I can ...\n"]}]},{"cell_type":"code","source":["# Se eliminan filas vacias\n","blogtext_df[\"text\"].dropna(inplace=True)\n","# Se establece el tipo de dato del texto como str\n","blogtext_df[\"text\"] = blogtext_df[\"text\"].astype(str)\n","# Se eliminan los espacios al principio y final de los textos\n","blogtext_df.text = blogtext_df.text.apply(lambda s: s.strip())\n","print(blogtext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVRJJoWQ7ccR","executionInfo":{"status":"ok","timestamp":1709389995684,"user_tz":-60,"elapsed":981,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"d8a7f533-2e0f-4b1b-9779-31f996cde565"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text\n","0  Info has been found (+/- 100 pages, and 4.5 MB...\n","1  These are the team members:   Drewes van der L...\n","2  In het kader van kernfusie op aarde:  MAAK JE ...\n","3                             testing!!!  testing!!!\n","4  Thanks to Yahoo!'s Toolbar I can now 'capture'...\n"]}]},{"cell_type":"code","source":["# Se añade una columna con el numero de palabras que contiene el texto de cada fila\n","blogtext_df[\"word_count\"] = blogtext_df.text.apply(lambda s: len(s.split()))\n","print(blogtext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9UWhvhwkvLv","executionInfo":{"status":"ok","timestamp":1709392754380,"user_tz":-60,"elapsed":9088,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"93da37a8-1c66-4b65-d01d-da2b4ddbd976"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text  word_count\n","0  Info has been found (+/- 100 pages, and 4.5 MB...          28\n","1  These are the team members:   Drewes van der L...          20\n","2  In het kader van kernfusie op aarde:  MAAK JE ...        4326\n","3                             testing!!!  testing!!!           2\n","4  Thanks to Yahoo!'s Toolbar I can now 'capture'...          65\n"]}]},{"cell_type":"code","source":["# Se genera un nuevo DataFrame, reordenando de forma aleatoria el DataFrame existente\n","seed = 7\n","rand_blogtext_df = blogtext_df.sample(frac=1, random_state=seed, ignore_index=True)\n","print(rand_blogtext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NA2m8-PQn6US","executionInfo":{"status":"ok","timestamp":1709391553387,"user_tz":-60,"elapsed":261,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"7f8aed8c-93b9-485c-c00a-595ff4476a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                text  word_count\n","0  urlLink    Do you see the man in the picture o...          17\n","1  Yeah, cause it's  obviously  a  urlLink family...           9\n","2              (damned tarnished halo showing again)           5\n","3  I suggest that the underground press could per...        5470\n","4  sometimes when I am quiet and in tune  I feel ...         120\n"]}]},{"cell_type":"code","source":["# Se implementa un bucle en el que se escribirá el archivo INPUT_RAW.txt\n","# Se mantiene la cuenta de palabras del txt para deternerse al llegar a 10000\n","word_count = 0\n","row = 0\n","with open(en_complete_path, 'w') as f:\n","  while word_count < 10000:\n","    f.write(rand_blogtext_df[\"text\"][row])\n","    f.write('\\n')\n","    row += 1\n","    word_count += rand_blogtext_df[\"word_count\"][row]"],"metadata":{"id":"Zl6QVwYwl0xV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ES"],"metadata":{"id":"pK0A698p4fOf"}},{"cell_type":"code","source":["!unzip -n '/content/gdrive/MyDrive/PLN/1/(a)/ES_News_Corpus.zip' >> /dev/null\n","\n","# Especificamos los paths\n","es_raw_text_path = \"/content/gdrive/MyDrive/PLN/1/(a)/ES/\"\n","es_raw_text_file_name = \"INPUT_RAW.txt\"\n","es_complete_path = es_raw_text_path + es_raw_text_file_name\n","es_corpus_dataset = \"df_total.csv\""],"metadata":{"id":"dajkvBlR4g0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el csv como dataframe\n","newstext_df = pd.read_csv(es_corpus_dataset, usecols=[1])\n","print(newstext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8ph-JtyuqK0","executionInfo":{"status":"ok","timestamp":1709392602454,"user_tz":-60,"elapsed":253,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"4c884c46-d646-4af7-f103-df3a2587df5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                news\n","0  Durante el foro La banca articulador empresari...\n","1  El regulador de valores de China dijo el domin...\n","2  En una industria históricamente masculina como...\n","3  Con el dato de marzo el IPC interanual encaden...\n","4  Ayer en Cartagena se dio inicio a la versión n...\n"]}]},{"cell_type":"code","source":["# Se eliminan filas vacias\n","newstext_df[\"news\"].dropna(inplace=True)\n","# Se establece el tipo de dato del texto como str\n","newstext_df[\"news\"] = newstext_df[\"news\"].astype(str)\n","# Se eliminan los espacios al principio y final de los textos\n","newstext_df.news = newstext_df.news.apply(lambda s: s.strip())\n","print(newstext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a-0SVWZevT4n","executionInfo":{"status":"ok","timestamp":1709392732808,"user_tz":-60,"elapsed":224,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"8521bc72-14c6-428d-fd9b-cbf70cd7e964"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                news\n","0  Durante el foro La banca articulador empresari...\n","1  El regulador de valores de China dijo el domin...\n","2  En una industria históricamente masculina como...\n","3  Con el dato de marzo el IPC interanual encaden...\n","4  Ayer en Cartagena se dio inicio a la versión n...\n"]}]},{"cell_type":"code","source":["# Se añade una columna con el numero de palabras que contiene el texto de cada fila\n","newstext_df[\"word_count\"] = newstext_df.news.apply(lambda s: len(s.split()))\n","print(newstext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yj5opMSWvzlk","executionInfo":{"status":"ok","timestamp":1709392777703,"user_tz":-60,"elapsed":253,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"6f791886-3b9b-4203-def2-6086cc42ba4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                news  word_count\n","0  Durante el foro La banca articulador empresari...         221\n","1  El regulador de valores de China dijo el domin...         342\n","2  En una industria históricamente masculina como...         367\n","3  Con el dato de marzo el IPC interanual encaden...         477\n","4  Ayer en Cartagena se dio inicio a la versión n...         793\n"]}]},{"cell_type":"code","source":["# Se genera un nuevo DataFrame, reordenando de forma aleatoria el DataFrame existente\n","seed = 7\n","rand_newstext_df = newstext_df.sample(frac=1, random_state=seed, ignore_index=True)\n","print(rand_newstext_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PNvdNJOv-I6","executionInfo":{"status":"ok","timestamp":1709392809437,"user_tz":-60,"elapsed":241,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f33015c7-f801-48f5-9832-0c285d6255fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                news  word_count\n","0  El Bbva Consumption Tracker es un indicador de...         408\n","1  Los cambios tecnológicos modifican la forma en...         195\n","2  Este viernes Shell inauguró su primera estació...         163\n","3  Los precios que pagan los consumidores estadou...         401\n","4  En un mundo tan hiperconectado como el actual,...         731\n"]}]},{"cell_type":"code","source":["# Se implementa un bucle en el que se escribirá el archivo INPUT_RAW.txt\n","# Se mantiene la cuenta de palabras del txt para deternerse al llegar a 10000\n","word_count = 0\n","row = 0\n","with open(es_complete_path, 'w') as f:\n","  while word_count < 10000:\n","    f.write(rand_newstext_df[\"news\"][row])\n","    f.write('\\n')\n","    row += 1\n","    word_count += rand_newstext_df[\"word_count\"][row]"],"metadata":{"id":"oN0_65PdwGSU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### PoS Tagging\n","\n","En esta sección se emplean los PoS Taggers pre-entrenados para etiquetar los textos generados en la sección anterior"],"metadata":{"id":"K9SL_9Y4z7Yb"}},{"cell_type":"markdown","source":["#### EN"],"metadata":{"id":"O-bqKqBL0T7Y"}},{"cell_type":"code","source":["# Se carga el modelo preentrenado y se especifican los paths del input y output.\n","nlp = spacy.load(\"en_core_web_sm\")\n","input_file = \"/content/gdrive/MyDrive/PLN/1/(a)/EN/INPUT_RAW.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/1/(a)/EN/OUTPUT_RAW.txt\""],"metadata":{"id":"U9bwjVO9KfzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el input y se le pasa al modelo\n","t_input = open(input_file).read()\n","doc = nlp(t_input)"],"metadata":{"id":"ZdxWh1dWKja_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto etiquetado frase a frase en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  for sentence in doc.sents:\n","    for token in sentence:\n","      of.write(f\"{token.text}({token.pos_}) \")\n","    of.write('\\n')"],"metadata":{"id":"JTnNNGQL8A4I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ES"],"metadata":{"id":"ay8X0iHA0WBv"}},{"cell_type":"code","source":["# Para poder emplear el pipeline en castellano, es necesario instalar el paquete primero:\n","!python -m spacy download es_core_news_sm\n","\n","# Se carga el modelo preentrenado y se especifican los paths del input y output.\n","nlp = spacy.load(\"es_core_news_sm\")\n","input_file = \"/content/gdrive/MyDrive/PLN/1/(a)/ES/INPUT_RAW.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/1/(a)/ES/OUTPUT_RAW.txt\""],"metadata":{"executionInfo":{"status":"ok","timestamp":1709400131242,"user_tz":-60,"elapsed":13301,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"GFUnO_GWK7Vm","outputId":"2a0a8e29-91eb-419f-d3a6-d822b73ac370"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting es-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from es-core-news-sm==3.7.0) (3.7.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.6.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.25.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.7.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]}]},{"cell_type":"code","source":["# Se lee el input y se le pasa al modelo\n","t_input = open(input_file).read()\n","doc = nlp(t_input)"],"metadata":{"id":"Ovo7Cq8DK9LZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto etiquetado frase a frase en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  for sentence in doc.sents:\n","    for token in sentence:\n","      of.write(f\"{token.text}({token.pos_}) \")\n","    of.write('\\n')"],"metadata":{"id":"PF2nfG30K_t2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **(b)** ENTRENANDO LOS MODELOS  (OPTATIVO, HASTA 1.5 PUNTOS)\n","\n","\n","Lo mismo pero sin emplear modelos pre-entrenados. El alumno deberá buscar corpus libremente disponibles con los que entrenar el tagger.   Recuérdese que si un treebank recoge también las etiquetas morfosintácticas de las palabras del texto, puede también emplearse para entrenar un tagger.\n","Se valorará positivamente que el alumno amplíe el experimento a más taggers y, sobre todo, más idiomas, especialmente (de menos a más): lenguas no latinas, lenguas no indo-europeas y lenguas con alfabeto diferente al latino. Se tendrá también en cuenta tanto la variedad del conjunto de idiomas como la variedad del tipo de taggers empleados.\n","\n","ENTREGABLES:\n","\n","Lo mismo que en el apartado anterior, incluyendo a mayores en la memoria la información concerniente a los diferentes corpus de entrenamiento que se hayan empleado, las características de la máquina empleada y los tiempos de entrenamiento requeridos.\n"],"metadata":{"id":"ljQjP4-7nK_N"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import random as rn\n","from google.colab import drive"],"metadata":{"id":"9cJqxmU3rJWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oai-nDzdlko-","executionInfo":{"status":"ok","timestamp":1712337196922,"user_tz":-120,"elapsed":39654,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"6a94ddc8-8a7e-4488-e6e4-65c2b52666a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### Preprocesado de los datos\n","\n","En este apartado se preprocesan los treebanks empleados para el entrenamiento y los datasets empleados para los tests."],"metadata":{"id":"c-MCiHuGpAHk"}},{"cell_type":"markdown","source":["#### JA"],"metadata":{"id":"nBt474W_phHs"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_train.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_dev.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TWzWF_VqNWA","executionInfo":{"status":"ok","timestamp":1712337223178,"user_tz":-120,"elapsed":26260,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"50a95163-b521-4b7f-b1e9-d94ca2e35538"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (705 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (51 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Se decide emplear la particion test del treebank de UD, el formato .txt tiene e texto crudo y el numero de palabras es adecuado, por lo que se puede emplear sin hacer modificaciones sobre el mismo."],"metadata":{"id":"9DyB4MVNxYh7"}},{"cell_type":"markdown","source":["#### RU"],"metadata":{"id":"fImxQoHRo9eW"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_train.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_dev.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"id":"zrHxiNj8qMcv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712337411157,"user_tz":-120,"elapsed":25257,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a2437d24-000b-4c7c-86ec-3b861d8b7bfd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1605 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (95 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["Se decide emplear la particion test del treebank de UD, el formato .txt tiene el texto crudo y se recorta para que el numero de palabras sea adecuado."],"metadata":{"id":"VRtSCUyjxqn6"}},{"cell_type":"markdown","source":["#### ZH"],"metadata":{"id":"x26BjaB0BfLt"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_train.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_dev.conllu\" \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"id":"F9J46dRkBkx7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712337428583,"user_tz":-120,"elapsed":17429,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a3c5d8be-243f-46b6-f3f5-1fa50e3fea74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (400 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (50 documents):\n","/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Entrenamiento\n","\n","En este apartado se entrenarán los etiquetadores para ambos idiomas.\n"],"metadata":{"id":"kuvlTY49pmQq"}},{"cell_type":"markdown","source":["#### JA"],"metadata":{"id":"yANyli90pwcL"}},{"cell_type":"code","source":["# Se instalan las dependencias para poder entrenar en Japones\n","!pip install sudachipy sudachidict_core"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIAtIYdlMUHV","executionInfo":{"status":"ok","timestamp":1712337236442,"user_tz":-120,"elapsed":13267,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"632eb607-6a84-4ec9-aaf8-ab47290f1b32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sudachipy\n","  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m2.1/2.6 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sudachidict_core\n","  Downloading SudachiDict_core-20240109-py3-none-any.whl (71.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sudachipy, sudachidict_core\n","Successfully installed sudachidict_core-20240109 sudachipy-0.6.8\n"]}]},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_config.cfg\""],"metadata":{"id":"mDxD6QKWqPtU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712337243863,"user_tz":-120,"elapsed":5698,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"12756fff-b013-4b49-e9be-625c148ce8d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train ja_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/ja_dev.spacy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pQ2f6UyaMsUN","executionInfo":{"status":"ok","timestamp":1712337374007,"user_tz":-120,"elapsed":130150,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"196bc4dc-ff4a-4cbe-fa9e-d5d3847e23dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory: /content/gdrive/MyDrive/PLN/1/(b)/JA\n","(GSD)/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  TAG_ACC  SCORE \n","---  ------  ------------  -----------  -------  ------\n","  0       0          0.00       191.52    76.98    0.77\n","  0     200        422.05     16352.68    76.98    0.77\n","  0     400        534.09      7665.17    76.98    0.77\n","  0     600        515.68      5920.69    76.98    0.77\n","  1     800        453.05      4530.33    76.98    0.77\n","  1    1000        447.13      3672.46    76.98    0.77\n","  1    1200        458.69      3616.99    76.98    0.77\n","  1    1400        449.00      3400.83    76.98    0.77\n","  2    1600        315.59      2131.50    76.98    0.77\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["#### RU"],"metadata":{"id":"t6uv29IipuJC"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_config.cfg\""],"metadata":{"id":"RQDRB8FTqOpU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712255480713,"user_tz":-120,"elapsed":6752,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"d2458879-a902-42da-f810-d390837596c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train ru_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/ru_dev.spacy\""],"metadata":{"id":"T7OWgbBgQ3bf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712255821470,"user_tz":-120,"elapsed":336979,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"8056d637-c313-417b-ec2c-45a883a5b965"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory: /content/gdrive/MyDrive/PLN/1/(b)/RU\n","(Taiga)/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  TAG_ACC  SCORE \n","---  ------  ------------  -----------  -------  ------\n","  0       0          0.00       221.93    27.12    0.27\n","  0     200        221.28      8269.95    73.95    0.74\n","  0     400        258.31      4072.54    79.06    0.79\n","  0     600        227.22      3505.29    83.90    0.84\n","  0     800        238.35      3729.30    85.30    0.85\n","  0    1000        244.76      3789.38    86.86    0.87\n","  1    1200        269.04      4120.66    87.47    0.87\n","  1    1400        273.16      3814.18    88.90    0.89\n","  1    1600        341.07      4799.93    88.50    0.89\n","  2    1800        367.69      5059.93    89.55    0.90\n","  2    2000        384.57      5016.32    89.66    0.90\n","  3    2200        392.20      4907.48    89.83    0.90\n","  4    2400        386.57      4694.33    89.96    0.90\n","  5    2600        347.30      4115.60    89.75    0.90\n","  6    2800        298.93      3488.89    89.83    0.90\n","  7    3000        247.79      2887.53    89.85    0.90\n","  8    3200        223.90      2592.15    89.63    0.90\n","  9    3400        196.80      2249.27    89.92    0.90\n"," 10    3600        183.55      2103.38    89.79    0.90\n"," 11    3800        159.51      1834.90    89.47    0.89\n"," 12    4000        141.45      1646.80    89.71    0.90\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["#### ZH"],"metadata":{"id":"bp7_9tQQBy05"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_config.cfg\""],"metadata":{"id":"BP5hV6p7B1uW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712255825717,"user_tz":-120,"elapsed":4249,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"e40dd7ab-1847-42b8-c79f-6cde3679c31f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train zh_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/zh_dev.spacy\""],"metadata":{"id":"2RomfsDJB2Su","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712256394878,"user_tz":-120,"elapsed":569164,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"18f85881-b616-4785-d809-c0f7455b8ee7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory: /content/gdrive/MyDrive/PLN/1/(b)/ZH\n","(GSD)/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  TAG_ACC  SCORE \n","---  ------  ------------  -----------  -------  ------\n","  0       0          0.00       445.23    33.29    0.33\n","  0     200        852.73     31544.49    79.39    0.79\n","  1     400       1215.99     20462.36    82.37    0.82\n","  1     600       1221.03     16127.07    84.66    0.85\n","  2     800       1347.94     16223.04    85.53    0.86\n","  2    1000       1314.94     13311.15    85.81    0.86\n","  3    1200       1328.53     12900.86    86.33    0.86\n","  3    1400       1295.65     10935.07    87.05    0.87\n","  4    1600       1367.49     11325.33    87.13    0.87\n","  4    1800       1255.06      9339.91    87.31    0.87\n","  5    2000       1400.09     10124.44    87.69    0.88\n","  5    2200       1197.78      7916.76    87.62    0.88\n","  6    2400       1405.97      9325.21    87.69    0.88\n","  6    2600       1198.05      7203.29    87.86    0.88\n","  7    2800       1332.82      8003.55    87.93    0.88\n","  7    3000       1137.20      6441.22    87.57    0.88\n","  8    3200       1291.80      7422.26    87.79    0.88\n","  8    3400       1105.23      5994.02    87.74    0.88\n","  9    3600       1247.29      6709.61    87.64    0.88\n","  9    3800       1055.52      5527.48    87.91    0.88\n"," 10    4000       1156.84      6029.90    87.95    0.88\n"," 10    4200       1036.16      5224.77    88.20    0.88\n"," 11    4400       1072.74      5429.28    88.23    0.88\n"," 11    4600        954.46      4654.37    87.94    0.88\n"," 12    4800       1084.28      5350.96    88.04    0.88\n"," 12    5000        891.23      4242.40    88.17    0.88\n"," 13    5200       1036.71      5090.07    88.34    0.88\n"," 13    5400        886.77      4260.89    88.32    0.88\n"," 14    5600        972.73      4605.41    88.55    0.89\n"," 14    5800        865.69      4107.88    88.39    0.88\n"," 15    6000        906.27      4216.71    88.68    0.89\n"," 15    6200        774.92      3613.74    88.36    0.88\n"," 16    6400        916.47      4244.81    88.41    0.88\n"," 16    6600        750.55      3460.90    88.32    0.88\n"," 17    6800        857.67      3993.72    88.66    0.89\n"," 17    7000        713.78      3284.98    88.23    0.88\n"," 18    7200        842.46      3940.32    88.64    0.89\n"," 18    7400        689.83      3147.97    88.98    0.89\n"," 19    7600        786.91      3664.33    88.70    0.89\n"," 19    7800        649.61      3025.20    88.52    0.89\n"," 20    8000        772.75      3564.52    88.61    0.89\n"," 20    8200        628.07      2871.45    88.48    0.88\n"," 21    8400        713.75      3240.79    88.87    0.89\n"," 21    8600        616.04      2801.76    88.78    0.89\n"," 22    8800        719.01      3285.17    88.49    0.88\n"," 22    9000        541.54      2456.54    88.50    0.88\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["### Test\n","\n","En este apartado se alimentaran los etiquetadores entrenados en el apartado anteior con CORPUS que anotarán y guardarán."],"metadata":{"id":"u8XBK5zfp0QY"}},{"cell_type":"markdown","source":["#### JA"],"metadata":{"id":"njIh8dhuqEMW"}},{"cell_type":"code","source":["# Se carga el modelo y se especifican los paths del input y output.\n","nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/Trained/model-best\")\n","input_file = \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/INPUT_RAW.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/1/(b)/JA (GSD)/OUTPUT_RAW.txt\""],"metadata":{"id":"ERF7K26HqRIk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Spacy tiene una limitacion en algunos idiomas (el japonés siendo uno de ellos) en los que el tamaño maximo del texto que se le pasa al modelo no se ajusta al de la documentación de la librería, por lo que hay que separarlo y pasarselo al etiquetador en varias partes.\n","\n","Este problema nace de una de las dependencias de Spacy, no de la propia librería, en el caso del Japones, el problema se localiza en la librería sudachipy.\n","\n","Para poder cortar de forma optima el texto, se cuentan los caracteres del texto tras codificarlos en UTF-8 y se divide la longitud total del texto por la recién obtenida.\n","\n","Para conocer el tamaño maximo permitido solo es necesesario observar el Traceback del error y anotar el valor maximo esperado, que en el caso del japones es 49149 Bytes."],"metadata":{"id":"wPxEkX5ejKvW"}},{"cell_type":"code","source":["# Funciónes obtenida del repositorio de Spacy: https://github.com/explosion/spaCy/issues/13207 por JWittmeyer:\n","\n","def __utf8len(s:str):\n","    return len(s.encode('utf-8'))\n","\n","# splits not after x bytes but ensures that max x bytes are used without destroying the final character\n","def __chunk_text_on_bytes(text: str, max_chunk_size: int = 1_000_000):\n","    factor = len(text) / __utf8len(text)\n","    increase_by = int(max(min(max_chunk_size*.1, 10), 1))\n","    initial_size_guess = int(max(max_chunk_size * factor - 10, 1))\n","    final_list = []\n","    remaining = text\n","    while len(remaining):\n","        part = remaining[:initial_size_guess]\n","        if __utf8len(part) > max_chunk_size:\n","            initial_size_guess = max(initial_size_guess - min(max_chunk_size *.001, 10), 1)\n","            continue\n","        cut_after = initial_size_guess\n","        while __utf8len(part) < max_chunk_size and part != remaining:\n","            cut_after = min(len(remaining), cut_after+increase_by)\n","            part = remaining[:cut_after]\n","\n","        if __utf8len(part) > max_chunk_size:\n","            cut_after-=increase_by\n","        final_list.append(remaining[:cut_after])\n","        remaining = remaining[cut_after:]\n","\n","    return final_list"],"metadata":{"id":"3mKIpJgNhWq7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el input y se le pasa al modelo\n","with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","texts = __chunk_text_on_bytes(t_input, 49149)\n","docs = []\n","for text in texts:\n","  docs.append(nlp(text))"],"metadata":{"id":"ewpYConFgq4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto etiquetado frase a frase en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  for doc in docs:\n","    for token in doc:\n","      of.write(f\"{token.text}({token.pos_}) \")\n","    of.write('\\n')"],"metadata":{"id":"PUBn52mlguni"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### RU"],"metadata":{"id":"lzSGgCkvqBZh"}},{"cell_type":"code","source":["# Se carga el modelo y se especifican los paths del input y output.\n","nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/Trained/model-best\")\n","input_file = \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/INPUT_RAW.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/1/(b)/RU (Taiga)/OUTPUT_RAW.txt\""],"metadata":{"id":"WzGMBmMiqQx-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el input y se le pasa al modelo\n","with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"eqrB9EY1lwFR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto etiquetado frase a frase en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  for token in doc:\n","    of.write(f\"{token.text}({token.tag_}) \")\n","  of.write('\\n')"],"metadata":{"id":"Ca29H6Oyl0TM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### ZH"],"metadata":{"id":"7yAxbQvtCNZ9"}},{"cell_type":"code","source":["# Se carga el modelo y se especifican los paths del input y output.\n","nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/Trained/model-best\")\n","input_file = \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/INPUT_RAW.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/1/(b)/ZH (GSD)/OUTPUT_RAW.txt\""],"metadata":{"id":"cU02LTq7CPZ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se lee el input y se le pasa al modelo\n","with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"qWqjo1QACRL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto etiquetado frase a frase en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  for token in doc:\n","    of.write(f\"{token.text}({token.tag_}) \")\n","  of.write('\\n')"],"metadata":{"id":"nzZBuqxgCRcG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# EJERCICIO 2. ENTRENAMIENTO Y EVALUACIÓN DE PARSERS DE CONSTITUYENTES"],"metadata":{"id":"SIJseqKtCAs4"}},{"cell_type":"markdown","source":["## 2.a. INGLÉS + LENGUA ROMANCE (ELEGIBLE, 1.5 PUNTOS)\n","\n","\n","Buscar y descargar un parser basado en constituyentes de uso libre y, seguidamente, entrenarlo y evaluarlo para dos idiomas: (1) inglés y (2) una lengua romance. Para ello el alumno deberá localizar y descargar treebanks adecuados: de estructura de frase (i.e. phrase structure grammars) y libre acceso.\n","\n","A la hora de evaluar el parser puede ser preciso adaptar el formato del treebank, preprocesar el texto de entrada a analizar o postprocesar la salida del parser, por ejemplo. También puede ser necesario dividir el corpus en dos: un (sub)corpus de entrenamiento y un (sub)corpus de evaluación o gold-standard. A la hora de comparar la salida obtenida con la esperada se puede emplear, por ejemplo, la herramienta de evaluación EVALB.\n","\n","ENTREGABLES:\n","\n","Para cada parser empleado se incluirá en la memoria un apartado en el que se analicen sus características (modelo en el que se basa, etc.), URL de la web donde se obtuvo, si fue necesario preprocesar el texto de entrada/postprocesar la salida y cómo, etc. De forma similar, deberán incluirse sendos apartados describiendo las características de los treebanks empleados, si fue necesario adaptarlos y cómo, etc.\n","\n","Finalmente, para cada idioma se incluirá una tabla(s) y/o gráfica(s) comparativa(s) de los resultados obtenidos con cada parser, así como un breve análisis de dichos resultados, junto con las características de la máquina empleada y los tiempos de entrenamiento requeridos.\n"],"metadata":{"id":"ycAfj-AzCQ7R"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from google.colab import drive"],"metadata":{"id":"JSVf0ECfRtF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"id":"IKLaPst2Ru7G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711639384936,"user_tz":-60,"elapsed":17835,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"654f8f91-9169-4880-942e-0fab0e60c36e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!pip install stanza"],"metadata":{"id":"gK34tKy5Rwgv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711639475577,"user_tz":-60,"elapsed":90647,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"239f9ec3-fe9f-476f-8753-cfc77abd5449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stanza\n","  Downloading stanza-1.8.1-py3-none-any.whl (970 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.4/970.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji (from stanza)\n","  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.25.2)\n","Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.2.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->stanza)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n","Successfully installed emoji-2.11.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 stanza-1.8.1\n"]}]},{"cell_type":"code","source":["import stanza"],"metadata":{"id":"u7YYCf1vRz1O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preparación del entorno de Stanza"],"metadata":{"id":"ek6JOk8SR3Oq"}},{"cell_type":"markdown","source":["Se siguen las instrucciones de https://stanfordnlp.github.io/stanza/new_language_constituency.html para preparar el entorno y poder entrenar modelos empleando Stanza.\n","\n","Los siguientes pasos de la preparacion del entorno solo es necesario realizarlos la primera vez que se prepara el entorno de Stanza"],"metadata":{"id":"27Fz9DtbSAm7"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2 && git clone https://github.com/stanfordnlp/stanza.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iu1VUghLnmHW","executionInfo":{"status":"ok","timestamp":1711203366481,"user_tz":-60,"elapsed":18499,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"b5510b11-483a-4ce2-ce48-88b5a14697d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stanza'...\n","remote: Enumerating objects: 40391, done.\u001b[K\n","remote: Counting objects: 100% (2489/2489), done.\u001b[K\n","remote: Compressing objects: 100% (717/717), done.\u001b[K\n","remote: Total 40391 (delta 1897), reused 2282 (delta 1770), pack-reused 37902\u001b[K\n","Receiving objects: 100% (40391/40391), 83.30 MiB | 11.08 MiB/s, done.\n","Resolving deltas: 100% (30968/30968), done.\n","Updating files: 100% (519/519), done.\n"]}]},{"cell_type":"code","source":["import stanza\n","stanza.install_corenlp(dir=\"/content/gdrive/MyDrive/PLN/2/CoreNLP\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["5970587f545348f2b35b918fbffcf2b5","1277f9a1b517449bbbf05ade931580bb","10db060c4e1b40858db5d7662ac1e8ad","c67b212bf15f46d5aad146041ab0946f","885266e609764cc894c267f6a6c85792","91e60356d4724dd19c9ce1a2344cc344","3e2a12caa34441faaec05ddfd57e4325","9836f24765cf466cb598c9dcbc1532e2","bdb2ab5a4af246e59f469cc279596750","2006d35e13c8446583db94516ea5cb19","2b4da8dc37e04daf965420b6976c943f"]},"id":"ad6tASnQpTkG","executionInfo":{"status":"ok","timestamp":1711303734927,"user_tz":-60,"elapsed":52416,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"b2324822-23b4-4040-c745-ba85f132d813"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Installing CoreNLP package into /content/gdrive/MyDrive/PLN/2/CoreNLP\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/CoreNLP/resolve/main/stanford-corenlp-latest.zip:   0%|        …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5970587f545348f2b35b918fbffcf2b5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /content/gdrive/MyDrive/PLN/2/CoreNLP/corenlp.zip\n","WARNING:stanza:For customized installation location, please set the `CORENLP_HOME` environment variable to the location of the installation. In Unix, this is done with `export CORENLP_HOME=/content/gdrive/MyDrive/PLN/2/CoreNLP`.\n"]}]},{"cell_type":"markdown","source":["### EN"],"metadata":{"id":"1H2RS2yOC3RU"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.constituency.prepare_con_dataset en_masc"],"metadata":{"id":"23wgZGn4C2Rt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711415848813,"user_tz":-60,"elapsed":9253,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f1398040-c73f-4574-e7f1-c771fb4b299c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Read 5201 natural trees\n","Split 5201 trees into 4160 train 520 dev 521 test\n","Total lengths 4160 train 520 dev 521 test\n","Writing 4160 trees to /content/gdrive/MyDrive/PLN/2/constituency/en_masc_train.mrg\n","Writing 520 trees to /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","Writing 521 trees to /content/gdrive/MyDrive/PLN/2/constituency/en_masc_test.mrg\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency en_masc --epochs 20"],"metadata":{"id":"ysrP_Ej7jTT2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4ff90ed-8517-4337-f0c0-8fefbe80f048"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-26 10:26:37 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py en_masc --epochs 100\n","2024-03-26 10:26:37 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-26 10:26:37 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-03-26 10:26:37 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-03-26 10:26:37 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-26 10:26:37 INFO: Expanded save_name: en_masc_charlm_constituency.pt\n","2024-03-26 10:26:37 INFO: Expanded save_name: saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:26:37 INFO: en_masc: saved_models/constituency/en_masc_charlm_constituency.pt does not exist, training new model\n","2024-03-26 10:26:37 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-26 10:26:37 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-03-26 10:26:37 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-03-26 10:26:37 INFO: Running train step with args: ['--train_file', '/content/gdrive/MyDrive/PLN/2/constituency/en_masc_train.mrg', '--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg', '--shorthand', 'en_masc', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--epochs', '100']\n","2024-03-26 10:26:37 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-26 10:26:37 INFO: Expanded save_name: en_masc_charlm_constituency.pt\n","2024-03-26 10:26:37 INFO: Running constituency parser in train mode\n","2024-03-26 10:26:37 DEBUG: Set trainer logging level to DEBUG\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 16.0MB/s]        \n","2024-03-26 10:26:38 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-26 10:26:38 DEBUG: Creating retag pipeline for default package\n","2024-03-26 10:26:38 INFO: Loading these models for language: en (English):\n","===============================\n","| Processor | Package         |\n","-------------------------------\n","| tokenize  | combined        |\n","| pos       | combined_charlm |\n","===============================\n","\n","2024-03-26 10:26:38 INFO: Using device: cuda\n","2024-03-26 10:26:38 INFO: Loading: tokenize\n","2024-03-26 10:26:38 INFO: Loading: pos\n","2024-03-26 10:26:39 INFO: Done loading processors!\n","2024-03-26 10:26:39 INFO: ARGS USED AT TRAINING TIME:\n","additional_oracle_levels: None\n","bert_finetune: False\n","bert_finetune_begin_epoch: None\n","bert_finetune_end_epoch: None\n","bert_finetune_layers: None\n","bert_hidden_layers: 4\n","bert_learning_rate: 0.009\n","bert_model: None\n","bert_weight_decay: 0.0001\n","charlm_backward_file: /root/stanza_resources/en/backward_charlm/1billion.pt\n","charlm_forward_file: /root/stanza_resources/en/forward_charlm/1billion.pt\n","check_valid_states: True\n","checkpoint: True\n","checkpoint_save_name: saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","combined_dummy_embedding: True\n","constituency_composition: ConstituencyComposition.MAX\n","constituent_heads: 8\n","constituent_stack: StackHistory.LSTM\n","data_dir: data/constituency\n","delta_embedding_dim: 100\n","device: cuda\n","epoch_size: 5000\n","epochs: 100\n","eval_batch_size: 50\n","eval_file: /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","finetune: False\n","grad_clipping: None\n","hidden_size: 512\n","lang: en\n","lattn_attention_dropout: 0.2\n","lattn_combine_as_self: False\n","lattn_combined_input: True\n","lattn_d_ff: 2048\n","lattn_d_input_proj: None\n","lattn_d_kv: 64\n","lattn_d_l: 32\n","lattn_d_proj: 64\n","lattn_partitioned: True\n","lattn_pwff: True\n","lattn_q_as_matrix: False\n","lattn_relu_dropout: 0.2\n","lattn_resdrop: True\n","lattn_residual_dropout: 0.2\n","learning_beta2: 0.999\n","learning_eps: 1e-08\n","learning_momentum: None\n","learning_rate: 0.0002\n","learning_rate_cooldown: 10\n","learning_rate_factor: 0.6\n","learning_rate_min_lr: 4.000000000000001e-06\n","learning_rate_patience: 5\n","learning_rate_warmup: 0\n","learning_rho: 0.9\n","learning_weight_decay: 0.05\n","load_name: None\n","load_package: None\n","log_norms: False\n","log_shapes: False\n","lora_alpha: 128\n","lora_dropout: 0.1\n","lora_modules_to_save: []\n","lora_rank: 64\n","lora_target_modules: ['query', 'value', 'output.dense', 'intermediate.dense']\n","loss: cross\n","loss_focal_gamma: 2\n","lstm_input_dropout: 0.2\n","lstm_layer_dropout: 0.0\n","maxout_k: None\n","mode: train\n","multistage: True\n","nonlinearity: relu\n","num_generate: 0\n","num_lstm_layers: 2\n","num_output_layers: 3\n","num_tree_lstm_layers: 1\n","optim: adamw\n","oracle_forced_errors: 0.001\n","oracle_frequency: 0.8\n","oracle_initial_epoch: 1\n","oracle_level: None\n","pattn_attention_dropout: 0.2\n","pattn_bias: False\n","pattn_d_ff: 2048\n","pattn_d_kv: 64\n","pattn_d_model: 1024\n","pattn_encoder_max_len: 512\n","pattn_morpho_emb_dropout: 0.2\n","pattn_num_heads: 8\n","pattn_num_layers: 0\n","pattn_relu_dropout: 0.1\n","pattn_residual_dropout: 0.2\n","pattn_timing: sin\n","predict_dir: .\n","predict_dropout: 0.2\n","predict_file: None\n","predict_format: {:_O}\n","pretrain_max_vocab: 250000\n","rare_word_threshold: 0.02\n","rare_word_unknown_frequency: 0.02\n","reduce_heads: 8\n","reduce_position: 128\n","relearn_structure: False\n","retag_charlm_backward_file: None\n","retag_charlm_forward_file: None\n","retag_method: xpos\n","retag_model_path: None\n","retag_package: default\n","retag_pretrain_path: None\n","retag_xpos: True\n","reversed: False\n","save_dir: saved_models/constituency\n","save_each_frequency: 1\n","save_each_name: saved_models/constituency/en_masc_charlm_constituency_%04d.pt\n","save_each_optimizer: True\n","save_each_start: None\n","save_name: saved_models/constituency/en_masc_charlm_constituency.pt\n","seed: 1234\n","sentence_boundary_vectors: SentenceBoundary.EVERYTHING\n","shorthand: en_masc\n","silver_epoch_size: None\n","silver_file: None\n","silver_remove_duplicates: False\n","stage1_bert_finetune: False\n","stage1_bert_learning_rate: 0.009\n","stage1_learning_rate: 1.0\n","stage1_learning_rate_min_lr: 0.02\n","tag_embedding_dim: 20\n","tag_unknown_frequency: 0.001\n","tokenized_dir: None\n","tokenized_file: None\n","train_batch_size: 30\n","train_file: /content/gdrive/MyDrive/PLN/2/constituency/en_masc_train.mrg\n","transition_embedding_dim: 20\n","transition_heads: 4\n","transition_hidden_size: 20\n","transition_scheme: TransitionScheme.IN_ORDER\n","transition_stack: StackHistory.LSTM\n","use_lattn: False\n","use_peft: False\n","use_silver_words: True\n","wandb: False\n","wandb_name: None\n","wandb_norm_regex: None\n","watch_regex: None\n","word_dropout: 0.2\n","wordvec_dir: extern_data/wordvec\n","wordvec_file: \n","wordvec_pretrain_file: /root/stanza_resources/en/pretrain/conll17.pt\n","\n","2024-03-26 10:26:39 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_train.mrg\n","100% 4158/4158 [00:01<00:00, 3623.61it/s]\n","2024-03-26 10:26:42 INFO: Read 4158 trees for the training set\n","2024-03-26 10:26:43 INFO: Filtered 395 duplicates from train dataset\n","2024-03-26 10:26:43 INFO: Eliminated 1 trees with missing structure\n","2024-03-26 10:26:43 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","2024-03-26 10:26:43 INFO: Read 520 trees for the dev set\n","2024-03-26 10:26:43 INFO: Filtered 26 duplicates from dev dataset\n","2024-03-26 10:26:43 INFO: Retagging trees using the xpos tags from the default package...\n","100% 3762/3762 [00:17<00:00, 216.23it/s]\n","100% 494/494 [00:03<00:00, 147.09it/s]\n","2024-03-26 10:27:04 INFO: Retagging finished\n","2024-03-26 10:27:04 INFO: Unique constituents in training set: ['ADJP', 'ADVP', 'CONJP', 'EDITED', 'FRAG', 'INTJ', 'LST', 'NAC', 'NML', 'NP', 'PP', 'PRN', 'PRT', 'QP', 'ROOT', 'RRC', 'S', 'SBAR', 'SBARQ', 'SINV', 'SQ', 'UCP', 'VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHPP', 'X']\n","2024-03-26 10:27:04 INFO: Constituent node counts: Counter({'NP': 21997, 'VP': 12155, 'S': 8570, 'PP': 6256, 'ROOT': 3762, 'SBAR': 2768, 'ADVP': 1967, 'ADJP': 1171, 'WHNP': 933, 'INTJ': 556, 'SQ': 418, 'WHADVP': 377, 'NML': 369, 'PRT': 240, 'PRN': 188, 'FRAG': 177, 'SBARQ': 125, 'QP': 124, 'EDITED': 68, 'WHPP': 52, 'SINV': 49, 'UCP': 48, 'CONJP': 40, 'WHADJP': 15, 'NAC': 11, 'LST': 10, 'RRC': 7, 'X': 2})\n","2024-03-26 10:27:05 INFO: Unique tags in training set: ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'ADD', 'CC', 'CD', 'DT', 'EX', 'FW', 'HYPH', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NFP', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n","2024-03-26 10:27:05 INFO: Unary limit: 4\n","2024-03-26 10:27:05 INFO: Building training transition sequences\n","100% 3762/3762 [00:00<00:00, 7008.04it/s]\n","2024-03-26 10:27:05 INFO: Building dev transition sequences\n","100% 494/494 [00:00<00:00, 13778.61it/s]\n","2024-03-26 10:27:05 INFO: Total unique transitions in train set: 30\n","2024-03-26 10:27:05 INFO: Unique transitions in training set: [Shift, CloseConstituent, OpenConstituent(('ADJP',)), OpenConstituent(('ADVP',)), OpenConstituent(('CONJP',)), OpenConstituent(('EDITED',)), OpenConstituent(('FRAG',)), OpenConstituent(('INTJ',)), OpenConstituent(('LST',)), OpenConstituent(('NAC',)), OpenConstituent(('NML',)), OpenConstituent(('NP',)), OpenConstituent(('PP',)), OpenConstituent(('PRN',)), OpenConstituent(('PRT',)), OpenConstituent(('QP',)), OpenConstituent(('ROOT',)), OpenConstituent(('RRC',)), OpenConstituent(('S',)), OpenConstituent(('SBAR',)), OpenConstituent(('SBARQ',)), OpenConstituent(('SINV',)), OpenConstituent(('SQ',)), OpenConstituent(('UCP',)), OpenConstituent(('VP',)), OpenConstituent(('WHADJP',)), OpenConstituent(('WHADVP',)), OpenConstituent(('WHNP',)), OpenConstituent(('WHPP',)), OpenConstituent(('X',))]\n","2024-03-26 10:27:05 INFO: Root labels in treebank: ['ROOT']\n","2024-03-26 10:27:05 INFO: Verifying the transition sequences for 3762 trees\n","100% 3762/3762 [00:02<00:00, 1472.57it/s]\n","2024-03-26 10:27:08 INFO: Verifying the transition sequences for 494 trees\n","100% 494/494 [00:00<00:00, 1165.60it/s]\n","2024-03-26 10:27:09 INFO: Using the following open nodes:\n","  ('ADJP',)\n","  ('ADVP',)\n","  ('CONJP',)\n","  ('EDITED',)\n","  ('FRAG',)\n","  ('INTJ',)\n","  ('LST',)\n","  ('NAC',)\n","  ('NML',)\n","  ('NP',)\n","  ('PP',)\n","  ('PRN',)\n","  ('PRT',)\n","  ('QP',)\n","  ('ROOT',)\n","  ('RRC',)\n","  ('S',)\n","  ('SBAR',)\n","  ('SBARQ',)\n","  ('SINV',)\n","  ('SQ',)\n","  ('UCP',)\n","  ('VP',)\n","  ('WHADJP',)\n","  ('WHADVP',)\n","  ('WHNP',)\n","  ('WHPP',)\n","  ('X',)\n","2024-03-26 10:27:09 INFO: Warming up model for 50 iterations using AdaDelta to train the embeddings\n","2024-03-26 10:27:09 DEBUG: Building Adadelta with lr=1.000000, weight_decay=0.02\n","2024-03-26 10:27:09 INFO: Number of words in the training set found in the embedding: 8037 out of 8478\n","2024-03-26 10:27:09 INFO: Building CrossEntropyLoss(sum)\n","2024-03-26 10:27:10 INFO: Starting epoch 1\n","100% 167/167 [04:11<00:00,  1.50s/it, Epoch 1]\n","2024-03-26 10:31:21 INFO: Transitions correct: 134822\n","  Counter({'Shift': 59743, 'Open': 42335, 'Close': 32744})\n","2024-03-26 10:31:21 INFO: Transitions incorrect: 109761\n","  Counter({('Open', 'Shift'): 20608, ('Open', 'Open'): 19825, ('Shift', 'Close'): 17845, ('Close', 'Shift'): 15306, ('Open', 'Close'): 15182, ('Shift', 'Open'): 11942, ('Close', 'Open'): 9053})\n","2024-03-26 10:31:21 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 32080, <RepairType.SHIFT_CLOSE: 8>: 18257, <RepairType.WRONG_OPEN_GENERAL: 4>: 17743, <RepairType.OPEN_SHIFT: 6>: 14435, <RepairType.OPEN_CLOSE: 7>: 7020, <RepairType.MISSED_UNARY: 5>: 3937, <RepairType.CLOSE_SHIFT_NESTED: 9>: 2382, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 781, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 589, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 449})\n","2024-03-26 10:31:21 INFO: Fake transitions used: 43\n","2024-03-26 10:31:21 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 80.39it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [1.2 sec].\n","pcfg LP/LR summary evalb: LP: 57.0 LR: 60.96 F1: 58.92 Exact: 3.03 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 57.0 LR: 60.96 F1: 58.92 Exact: 3.03 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:31:33 INFO: New best dev score: 0.58921 > 0.00000\n","2024-03-26 10:31:33 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:31:33 INFO: Epoch 1 finished\n","  Transitions correct: Counter({'Shift': 59743, 'Open': 42335, 'Close': 32744})\n","  Transitions incorrect: Counter({('Open', 'Shift'): 20608, ('Open', 'Open'): 19825, ('Shift', 'Close'): 17845, ('Close', 'Shift'): 15306, ('Open', 'Close'): 15182, ('Shift', 'Open'): 11942, ('Close', 'Open'): 9053})\n","  Total loss for epoch: 458202.25250\n","  Dev score      (    1): 0.589213\n","  Best dev score (    1): 0.589213\n","2024-03-26 10:31:35 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:31:35 INFO: Starting epoch 2\n","100% 167/167 [04:11<00:00,  1.50s/it, Epoch 2]\n","2024-03-26 10:35:46 INFO: Transitions correct: 208485\n","  Counter({'Shift': 80582, 'Open': 66338, 'Close': 61565})\n","2024-03-26 10:35:46 INFO: Transitions incorrect: 39004\n","  Counter({('Open', 'Open'): 8657, ('Open', 'Close'): 7576, ('Open', 'Shift'): 5744, ('Close', 'Shift'): 5025, ('Shift', 'Close'): 4893, ('Close', 'Open'): 3618, ('Shift', 'Open'): 3491})\n","2024-03-26 10:35:46 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 12252, <RepairType.WRONG_OPEN_GENERAL: 4>: 7212, <RepairType.SHIFT_CLOSE: 8>: 5085, <RepairType.OPEN_CLOSE: 7>: 4784, <RepairType.OPEN_SHIFT: 6>: 4599, <RepairType.MISSED_UNARY: 5>: 2116, <RepairType.CLOSE_SHIFT_NESTED: 9>: 886, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 748, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 366, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 76})\n","2024-03-26 10:35:46 INFO: Fake transitions used: 66\n","2024-03-26 10:35:46 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 80.24it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.5 sec].\n","pcfg LP/LR summary evalb: LP: 70.94 LR: 74.36 F1: 72.61 Exact: 6.88 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 70.94 LR: 74.36 F1: 72.61 Exact: 6.88 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:35:54 INFO: New best dev score: 0.72612 > 0.58921\n","2024-03-26 10:35:54 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:35:54 INFO: Epoch 2 finished\n","  Transitions correct: Counter({'Shift': 80582, 'Open': 66338, 'Close': 61565})\n","  Transitions incorrect: Counter({('Open', 'Open'): 8657, ('Open', 'Close'): 7576, ('Open', 'Shift'): 5744, ('Close', 'Shift'): 5025, ('Shift', 'Close'): 4893, ('Close', 'Open'): 3618, ('Shift', 'Open'): 3491})\n","  Total loss for epoch: 129606.42195\n","  Dev score      (    2): 0.726121\n","  Best dev score (    2): 0.726121\n","2024-03-26 10:35:56 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:35:56 INFO: Starting epoch 3\n","100% 167/167 [04:13<00:00,  1.52s/it, Epoch 3]\n","2024-03-26 10:40:09 INFO: Transitions correct: 217906\n","  Counter({'Shift': 81896, 'Open': 70399, 'Close': 65611})\n","2024-03-26 10:40:09 INFO: Transitions incorrect: 32690\n","  Counter({('Open', 'Open'): 6839, ('Open', 'Close'): 6032, ('Open', 'Shift'): 4920, ('Close', 'Shift'): 4310, ('Shift', 'Close'): 3832, ('Shift', 'Open'): 3489, ('Close', 'Open'): 3268})\n","2024-03-26 10:40:09 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 10450, <RepairType.WRONG_OPEN_GENERAL: 4>: 5736, <RepairType.OPEN_CLOSE: 7>: 4259, <RepairType.SHIFT_CLOSE: 8>: 3974, <RepairType.OPEN_SHIFT: 6>: 3931, <RepairType.MISSED_UNARY: 5>: 1539, <RepairType.CLOSE_SHIFT_NESTED: 9>: 701, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 680, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 295, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 58})\n","2024-03-26 10:40:09 INFO: Fake transitions used: 67\n","2024-03-26 10:40:09 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 74.51it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 78.21 LR: 74.04 F1: 76.07 Exact: 12.55 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 78.21 LR: 74.04 F1: 76.07 Exact: 12.55 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:40:18 INFO: New best dev score: 0.76071 > 0.72612\n","2024-03-26 10:40:18 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:40:18 INFO: Epoch 3 finished\n","  Transitions correct: Counter({'Shift': 81896, 'Open': 70399, 'Close': 65611})\n","  Transitions incorrect: Counter({('Open', 'Open'): 6839, ('Open', 'Close'): 6032, ('Open', 'Shift'): 4920, ('Close', 'Shift'): 4310, ('Shift', 'Close'): 3832, ('Shift', 'Open'): 3489, ('Close', 'Open'): 3268})\n","  Total loss for epoch: 109851.20745\n","  Dev score      (    3): 0.760711\n","  Best dev score (    3): 0.760711\n","2024-03-26 10:40:19 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:40:19 INFO: Starting epoch 4\n","100% 167/167 [04:14<00:00,  1.52s/it, Epoch 4]\n","2024-03-26 10:44:34 INFO: Transitions correct: 226418\n","  Counter({'Shift': 83826, 'Open': 73327, 'Close': 69265})\n","2024-03-26 10:44:34 INFO: Transitions incorrect: 24633\n","  Counter({('Open', 'Open'): 4904, ('Open', 'Close'): 4801, ('Open', 'Shift'): 3944, ('Close', 'Shift'): 3041, ('Shift', 'Close'): 2945, ('Close', 'Open'): 2717, ('Shift', 'Open'): 2281})\n","2024-03-26 10:44:34 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 8115, <RepairType.WRONG_OPEN_GENERAL: 4>: 3881, <RepairType.OPEN_CLOSE: 7>: 3602, <RepairType.OPEN_SHIFT: 6>: 3227, <RepairType.SHIFT_CLOSE: 8>: 3036, <RepairType.MISSED_UNARY: 5>: 1076, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 612, <RepairType.CLOSE_SHIFT_NESTED: 9>: 487, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 245, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 92})\n","2024-03-26 10:44:34 INFO: Fake transitions used: 60\n","2024-03-26 10:44:34 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:05<00:00, 90.90it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 80.2 LR: 79.77 F1: 79.99 Exact: 15.99 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 80.2 LR: 79.77 F1: 79.99 Exact: 15.99 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:44:42 INFO: New best dev score: 0.79992 > 0.76071\n","2024-03-26 10:44:42 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:44:42 INFO: Epoch 4 finished\n","  Transitions correct: Counter({'Shift': 83826, 'Open': 73327, 'Close': 69265})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4904, ('Open', 'Close'): 4801, ('Open', 'Shift'): 3944, ('Close', 'Shift'): 3041, ('Shift', 'Close'): 2945, ('Close', 'Open'): 2717, ('Shift', 'Open'): 2281})\n","  Total loss for epoch: 78048.63896\n","  Dev score      (    4): 0.799917\n","  Best dev score (    4): 0.799917\n","2024-03-26 10:44:43 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:44:43 INFO: Starting epoch 5\n","100% 167/167 [04:14<00:00,  1.53s/it, Epoch 5]\n","2024-03-26 10:48:58 INFO: Transitions correct: 230178\n","  Counter({'Shift': 84284, 'Open': 74442, 'Close': 71452})\n","2024-03-26 10:48:58 INFO: Transitions incorrect: 19470\n","  Counter({('Open', 'Open'): 3940, ('Open', 'Close'): 3796, ('Open', 'Shift'): 3217, ('Close', 'Shift'): 2412, ('Shift', 'Close'): 2146, ('Close', 'Open'): 2024, ('Shift', 'Open'): 1935})\n","2024-03-26 10:48:58 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 6425, <RepairType.WRONG_OPEN_GENERAL: 4>: 3206, <RepairType.OPEN_CLOSE: 7>: 2900, <RepairType.OPEN_SHIFT: 6>: 2621, <RepairType.SHIFT_CLOSE: 8>: 2214, <RepairType.MISSED_UNARY: 5>: 927, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 513, <RepairType.CLOSE_SHIFT_NESTED: 9>: 422, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 216, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 1})\n","2024-03-26 10:48:58 INFO: Fake transitions used: 75\n","2024-03-26 10:48:58 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 80.75it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 82.68 LR: 82.12 F1: 82.4 Exact: 15.18 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.68 LR: 82.12 F1: 82.4 Exact: 15.18 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:49:06 INFO: New best dev score: 0.82405 > 0.79992\n","2024-03-26 10:49:06 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:49:06 INFO: Epoch 5 finished\n","  Transitions correct: Counter({'Shift': 84284, 'Open': 74442, 'Close': 71452})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3940, ('Open', 'Close'): 3796, ('Open', 'Shift'): 3217, ('Close', 'Shift'): 2412, ('Shift', 'Close'): 2146, ('Close', 'Open'): 2024, ('Shift', 'Open'): 1935})\n","  Total loss for epoch: 62467.11730\n","  Dev score      (    5): 0.824052\n","  Best dev score (    5): 0.824052\n","2024-03-26 10:49:08 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:49:08 INFO: Starting epoch 6\n","100% 167/167 [04:23<00:00,  1.58s/it, Epoch 6]\n","2024-03-26 10:53:31 INFO: Transitions correct: 234941\n","  Counter({'Shift': 85858, 'Open': 76000, 'Close': 73083})\n","2024-03-26 10:53:31 INFO: Transitions incorrect: 17514\n","  Counter({('Open', 'Close'): 3651, ('Open', 'Open'): 3348, ('Open', 'Shift'): 3062, ('Close', 'Shift'): 2030, ('Shift', 'Close'): 1853, ('Close', 'Open'): 1851, ('Shift', 'Open'): 1719})\n","2024-03-26 10:53:31 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 5631, <RepairType.OPEN_CLOSE: 7>: 2837, <RepairType.WRONG_OPEN_GENERAL: 4>: 2700, <RepairType.OPEN_SHIFT: 6>: 2505, <RepairType.SHIFT_CLOSE: 8>: 1922, <RepairType.MISSED_UNARY: 5>: 866, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 460, <RepairType.CLOSE_SHIFT_NESTED: 9>: 344, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 184})\n","2024-03-26 10:53:31 INFO: Fake transitions used: 79\n","2024-03-26 10:53:31 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:05<00:00, 83.26it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 84.44 LR: 80.1 F1: 82.21 Exact: 16.8 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.44 LR: 80.1 F1: 82.21 Exact: 16.8 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:53:39 INFO: Epoch 6 finished\n","  Transitions correct: Counter({'Shift': 85858, 'Open': 76000, 'Close': 73083})\n","  Transitions incorrect: Counter({('Open', 'Close'): 3651, ('Open', 'Open'): 3348, ('Open', 'Shift'): 3062, ('Close', 'Shift'): 2030, ('Shift', 'Close'): 1853, ('Close', 'Open'): 1851, ('Shift', 'Open'): 1719})\n","  Total loss for epoch: 57011.17772\n","  Dev score      (    6): 0.822193\n","  Best dev score (    5): 0.824052\n","2024-03-26 10:53:44 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:53:44 INFO: Starting epoch 7\n","100% 167/167 [04:25<00:00,  1.59s/it, Epoch 7]\n","2024-03-26 10:58:09 INFO: Transitions correct: 236895\n","  Counter({'Shift': 86467, 'Open': 76868, 'Close': 73560})\n","2024-03-26 10:58:09 INFO: Transitions incorrect: 20384\n","  Counter({('Open', 'Open'): 4060, ('Open', 'Close'): 3902, ('Shift', 'Close'): 3052, ('Open', 'Shift'): 2978, ('Close', 'Shift'): 2779, ('Close', 'Open'): 1939, ('Shift', 'Open'): 1674})\n","2024-03-26 10:58:09 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 6137, <RepairType.SHIFT_CLOSE: 8>: 3033, <RepairType.OPEN_CLOSE: 7>: 2781, <RepairType.WRONG_OPEN_GENERAL: 4>: 2767, <RepairType.OPEN_SHIFT: 6>: 2254, <RepairType.MISSED_UNARY: 5>: 794, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 440, <RepairType.CLOSE_SHIFT_NESTED: 9>: 395, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 247, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 197})\n","2024-03-26 10:58:09 INFO: Fake transitions used: 79\n","2024-03-26 10:58:09 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 78.11it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 84.26 LR: 82.55 F1: 83.4 Exact: 22.46 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.26 LR: 82.55 F1: 83.4 Exact: 22.46 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 10:58:17 INFO: New best dev score: 0.83404 > 0.82405\n","2024-03-26 10:58:18 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 10:58:18 INFO: Epoch 7 finished\n","  Transitions correct: Counter({'Shift': 86467, 'Open': 76868, 'Close': 73560})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4060, ('Open', 'Close'): 3902, ('Shift', 'Close'): 3052, ('Open', 'Shift'): 2978, ('Close', 'Shift'): 2779, ('Close', 'Open'): 1939, ('Shift', 'Open'): 1674})\n","  Total loss for epoch: 74244.04128\n","  Dev score      (    7): 0.834035\n","  Best dev score (    7): 0.834035\n","2024-03-26 10:58:19 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 10:58:19 INFO: Starting epoch 8\n","100% 167/167 [04:19<00:00,  1.56s/it, Epoch 8]\n","2024-03-26 11:02:39 INFO: Transitions correct: 235526\n","  Counter({'Shift': 85308, 'Open': 76305, 'Close': 73913})\n","2024-03-26 11:02:39 INFO: Transitions incorrect: 14519\n","  Counter({('Open', 'Open'): 2848, ('Open', 'Close'): 2842, ('Open', 'Shift'): 2445, ('Close', 'Shift'): 1857, ('Shift', 'Close'): 1641, ('Close', 'Open'): 1504, ('Shift', 'Open'): 1382})\n","2024-03-26 11:02:39 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4696, <RepairType.WRONG_OPEN_GENERAL: 4>: 2255, <RepairType.OPEN_CLOSE: 7>: 2229, <RepairType.OPEN_SHIFT: 6>: 1994, <RepairType.SHIFT_CLOSE: 8>: 1688, <RepairType.MISSED_UNARY: 5>: 712, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 401, <RepairType.CLOSE_SHIFT_NESTED: 9>: 344, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 186, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 1})\n","2024-03-26 11:02:39 INFO: Fake transitions used: 62\n","2024-03-26 11:02:39 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 75.65it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 75.1 LR: 81.54 F1: 78.19 Exact: 16.39 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 75.1 LR: 81.54 F1: 78.19 Exact: 16.39 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:02:47 INFO: Epoch 8 finished\n","  Transitions correct: Counter({'Shift': 85308, 'Open': 76305, 'Close': 73913})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2848, ('Open', 'Close'): 2842, ('Open', 'Shift'): 2445, ('Close', 'Shift'): 1857, ('Shift', 'Close'): 1641, ('Close', 'Open'): 1504, ('Shift', 'Open'): 1382})\n","  Total loss for epoch: 45655.00643\n","  Dev score      (    8): 0.781952\n","  Best dev score (    7): 0.834035\n","2024-03-26 11:02:48 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:02:48 INFO: Starting epoch 9\n","100% 167/167 [04:23<00:00,  1.58s/it, Epoch 9]\n","2024-03-26 11:07:12 INFO: Transitions correct: 237233\n","  Counter({'Shift': 86020, 'Open': 76915, 'Close': 74298})\n","2024-03-26 11:07:12 INFO: Transitions incorrect: 14312\n","  Counter({('Open', 'Close'): 2906, ('Open', 'Open'): 2745, ('Open', 'Shift'): 2382, ('Close', 'Shift'): 1836, ('Shift', 'Close'): 1585, ('Close', 'Open'): 1550, ('Shift', 'Open'): 1308})\n","2024-03-26 11:07:12 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4689, <RepairType.OPEN_CLOSE: 7>: 2289, <RepairType.WRONG_OPEN_GENERAL: 4>: 2182, <RepairType.OPEN_SHIFT: 6>: 1929, <RepairType.SHIFT_CLOSE: 8>: 1625, <RepairType.MISSED_UNARY: 5>: 677, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 393, <RepairType.CLOSE_SHIFT_NESTED: 9>: 329, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 161, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 4})\n","2024-03-26 11:07:12 INFO: Fake transitions used: 68\n","2024-03-26 11:07:12 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 79.69it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 82.04 LR: 83.51 F1: 82.77 Exact: 21.05 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.04 LR: 83.51 F1: 82.77 Exact: 21.05 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:07:20 INFO: Epoch 9 finished\n","  Transitions correct: Counter({'Shift': 86020, 'Open': 76915, 'Close': 74298})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2906, ('Open', 'Open'): 2745, ('Open', 'Shift'): 2382, ('Close', 'Shift'): 1836, ('Shift', 'Close'): 1585, ('Close', 'Open'): 1550, ('Shift', 'Open'): 1308})\n","  Total loss for epoch: 45322.49489\n","  Dev score      (    9): 0.827738\n","  Best dev score (    7): 0.834035\n","2024-03-26 11:07:23 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:07:23 INFO: Starting epoch 10\n","100% 167/167 [04:24<00:00,  1.58s/it, Epoch 10]\n","2024-03-26 11:11:47 INFO: Transitions correct: 240014\n","  Counter({'Shift': 86639, 'Open': 77713, 'Close': 75662})\n","2024-03-26 11:11:47 INFO: Transitions incorrect: 13017\n","  Counter({('Open', 'Close'): 2660, ('Open', 'Open'): 2567, ('Open', 'Shift'): 2213, ('Close', 'Shift'): 1550, ('Shift', 'Close'): 1503, ('Close', 'Open'): 1286, ('Shift', 'Open'): 1238})\n","2024-03-26 11:11:47 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4074, <RepairType.OPEN_CLOSE: 7>: 2095, <RepairType.WRONG_OPEN_GENERAL: 4>: 2040, <RepairType.OPEN_SHIFT: 6>: 1807, <RepairType.SHIFT_CLOSE: 8>: 1538, <RepairType.MISSED_UNARY: 5>: 636, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 364, <RepairType.CLOSE_SHIFT_NESTED: 9>: 285, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 160, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 1})\n","2024-03-26 11:11:47 INFO: Fake transitions used: 69\n","2024-03-26 11:11:47 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 71.64it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.1 sec].\n","pcfg LP/LR summary evalb: LP: 85.86 LR: 83.0 F1: 84.4 Exact: 23.07 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 85.86 LR: 83.0 F1: 84.4 Exact: 23.07 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:11:56 INFO: New best dev score: 0.84408 > 0.83404\n","2024-03-26 11:11:56 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 11:11:56 INFO: Epoch 10 finished\n","  Transitions correct: Counter({'Shift': 86639, 'Open': 77713, 'Close': 75662})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2660, ('Open', 'Open'): 2567, ('Open', 'Shift'): 2213, ('Close', 'Shift'): 1550, ('Shift', 'Close'): 1503, ('Close', 'Open'): 1286, ('Shift', 'Open'): 1238})\n","  Total loss for epoch: 40961.25864\n","  Dev score      (   10): 0.844084\n","  Best dev score (   10): 0.844084\n","2024-03-26 11:11:57 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:11:57 INFO: Starting epoch 11\n","100% 167/167 [04:21<00:00,  1.57s/it, Epoch 11]\n","2024-03-26 11:16:19 INFO: Transitions correct: 234594\n","  Counter({'Shift': 84987, 'Open': 76391, 'Close': 73216})\n","2024-03-26 11:16:19 INFO: Transitions incorrect: 18808\n","  Counter({('Open', 'Open'): 3879, ('Open', 'Close'): 3355, ('Shift', 'Close'): 2998, ('Open', 'Shift'): 2603, ('Close', 'Shift'): 2535, ('Shift', 'Open'): 1755, ('Close', 'Open'): 1683})\n","2024-03-26 11:16:19 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 5335, <RepairType.WRONG_OPEN_GENERAL: 4>: 3022, <RepairType.SHIFT_CLOSE: 8>: 2985, <RepairType.OPEN_CLOSE: 7>: 2582, <RepairType.OPEN_SHIFT: 6>: 2029, <RepairType.MISSED_UNARY: 5>: 747, <RepairType.CLOSE_SHIFT_NESTED: 9>: 424, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 399, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 180, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 127})\n","2024-03-26 11:16:19 INFO: Fake transitions used: 79\n","2024-03-26 11:16:19 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 75.89it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 80.43 LR: 83.6 F1: 81.99 Exact: 17.0 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 80.43 LR: 83.6 F1: 81.99 Exact: 17.0 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:16:28 INFO: Epoch 11 finished\n","  Transitions correct: Counter({'Shift': 84987, 'Open': 76391, 'Close': 73216})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3879, ('Open', 'Close'): 3355, ('Shift', 'Close'): 2998, ('Open', 'Shift'): 2603, ('Close', 'Shift'): 2535, ('Shift', 'Open'): 1755, ('Close', 'Open'): 1683})\n","  Total loss for epoch: 62054.86722\n","  Dev score      (   11): 0.819912\n","  Best dev score (   10): 0.844084\n","2024-03-26 11:16:29 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:16:29 INFO: Starting epoch 12\n","100% 167/167 [04:27<00:00,  1.60s/it, Epoch 12]\n","2024-03-26 11:20:57 INFO: Transitions correct: 241760\n","  Counter({'Shift': 87192, 'Open': 78335, 'Close': 76233})\n","2024-03-26 11:20:57 INFO: Transitions incorrect: 12223\n","  Counter({('Open', 'Close'): 2535, ('Open', 'Open'): 2391, ('Open', 'Shift'): 2007, ('Shift', 'Close'): 1441, ('Close', 'Shift'): 1430, ('Close', 'Open'): 1285, ('Shift', 'Open'): 1134})\n","2024-03-26 11:20:57 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 3875, <RepairType.OPEN_CLOSE: 7>: 2010, <RepairType.WRONG_OPEN_GENERAL: 4>: 1905, <RepairType.OPEN_SHIFT: 6>: 1629, <RepairType.SHIFT_CLOSE: 8>: 1475, <RepairType.MISSED_UNARY: 5>: 575, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 333, <RepairType.CLOSE_SHIFT_NESTED: 9>: 258, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 145, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 8})\n","2024-03-26 11:20:57 INFO: Fake transitions used: 72\n","2024-03-26 11:20:57 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 75.18it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 77.66 LR: 73.84 F1: 75.7 Exact: 14.37 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 77.66 LR: 73.84 F1: 75.7 Exact: 14.37 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:21:06 INFO: Epoch 12 finished\n","  Transitions correct: Counter({'Shift': 87192, 'Open': 78335, 'Close': 76233})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2535, ('Open', 'Open'): 2391, ('Open', 'Shift'): 2007, ('Shift', 'Close'): 1441, ('Close', 'Shift'): 1430, ('Close', 'Open'): 1285, ('Shift', 'Open'): 1134})\n","  Total loss for epoch: 38612.53253\n","  Dev score      (   12): 0.757099\n","  Best dev score (   10): 0.844084\n","2024-03-26 11:21:07 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:21:07 INFO: Starting epoch 13\n","100% 167/167 [04:20<00:00,  1.56s/it, Epoch 13]\n","2024-03-26 11:25:27 INFO: Transitions correct: 241086\n","  Counter({'Shift': 86683, 'Open': 78209, 'Close': 76194})\n","2024-03-26 11:25:27 INFO: Transitions incorrect: 11120\n","  Counter({('Open', 'Close'): 2509, ('Open', 'Open'): 2057, ('Open', 'Shift'): 1916, ('Shift', 'Close'): 1286, ('Close', 'Shift'): 1256, ('Close', 'Open'): 1094, ('Shift', 'Open'): 1002})\n","2024-03-26 11:25:27 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 3407, <RepairType.OPEN_CLOSE: 7>: 2016, <RepairType.WRONG_OPEN_GENERAL: 4>: 1634, <RepairType.OPEN_SHIFT: 6>: 1571, <RepairType.SHIFT_CLOSE: 8>: 1311, <RepairType.MISSED_UNARY: 5>: 513, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 300, <RepairType.CLOSE_SHIFT_NESTED: 9>: 230, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 121})\n","2024-03-26 11:25:27 INFO: Fake transitions used: 64\n","2024-03-26 11:25:27 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 71.56it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 75.64 LR: 79.9 F1: 77.71 Exact: 15.78 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 75.64 LR: 79.9 F1: 77.71 Exact: 15.78 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:25:36 INFO: Epoch 13 finished\n","  Transitions correct: Counter({'Shift': 86683, 'Open': 78209, 'Close': 76194})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2509, ('Open', 'Open'): 2057, ('Open', 'Shift'): 1916, ('Shift', 'Close'): 1286, ('Close', 'Shift'): 1256, ('Close', 'Open'): 1094, ('Shift', 'Open'): 1002})\n","  Total loss for epoch: 34962.99854\n","  Dev score      (   13): 0.777166\n","  Best dev score (   10): 0.844084\n","2024-03-26 11:25:37 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:25:37 INFO: Starting epoch 14\n","100% 167/167 [04:21<00:00,  1.56s/it, Epoch 14]\n","2024-03-26 11:29:58 INFO: Transitions correct: 246035\n","  Counter({'Shift': 88465, 'Open': 79991, 'Close': 77579})\n","2024-03-26 11:29:58 INFO: Transitions incorrect: 11130\n","  Counter({('Open', 'Close'): 2443, ('Open', 'Open'): 1910, ('Open', 'Shift'): 1746, ('Close', 'Open'): 1350, ('Shift', 'Close'): 1339, ('Close', 'Shift'): 1316, ('Shift', 'Open'): 1026})\n","2024-03-26 11:29:58 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 3639, <RepairType.OPEN_CLOSE: 7>: 1973, <RepairType.WRONG_OPEN_GENERAL: 4>: 1515, <RepairType.OPEN_SHIFT: 6>: 1433, <RepairType.SHIFT_CLOSE: 8>: 1364, <RepairType.MISSED_UNARY: 5>: 546, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 280, <RepairType.CLOSE_SHIFT_NESTED: 9>: 243, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 113})\n","2024-03-26 11:29:58 INFO: Fake transitions used: 69\n","2024-03-26 11:29:58 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 75.93it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 84.07 LR: 84.91 F1: 84.49 Exact: 23.48 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.07 LR: 84.91 F1: 84.49 Exact: 23.48 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:30:06 INFO: New best dev score: 0.84494 > 0.84408\n","2024-03-26 11:30:07 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 11:30:07 INFO: Epoch 14 finished\n","  Transitions correct: Counter({'Shift': 88465, 'Open': 79991, 'Close': 77579})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2443, ('Open', 'Open'): 1910, ('Open', 'Shift'): 1746, ('Close', 'Open'): 1350, ('Shift', 'Close'): 1339, ('Close', 'Shift'): 1316, ('Shift', 'Open'): 1026})\n","  Total loss for epoch: 34433.14778\n","  Dev score      (   14): 0.844936\n","  Best dev score (   14): 0.844936\n","2024-03-26 11:30:08 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:30:08 INFO: Starting epoch 15\n","100% 167/167 [04:16<00:00,  1.54s/it, Epoch 15]\n","2024-03-26 11:34:25 INFO: Transitions correct: 241807\n","  Counter({'Shift': 86641, 'Open': 78501, 'Close': 76665})\n","2024-03-26 11:34:25 INFO: Transitions incorrect: 9700\n","  Counter({('Open', 'Close'): 2058, ('Open', 'Open'): 1839, ('Open', 'Shift'): 1672, ('Shift', 'Close'): 1124, ('Close', 'Shift'): 1113, ('Close', 'Open'): 1030, ('Shift', 'Open'): 864})\n","2024-03-26 11:34:25 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2988, <RepairType.OPEN_CLOSE: 7>: 1633, <RepairType.WRONG_OPEN_GENERAL: 4>: 1461, <RepairType.OPEN_SHIFT: 6>: 1385, <RepairType.SHIFT_CLOSE: 8>: 1155, <RepairType.MISSED_UNARY: 5>: 485, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 240, <RepairType.CLOSE_SHIFT_NESTED: 9>: 194, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 122, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 11})\n","2024-03-26 11:34:25 INFO: Fake transitions used: 79\n","2024-03-26 11:34:25 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 78.20it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 84.74 LR: 84.99 F1: 84.87 Exact: 23.88 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.74 LR: 84.99 F1: 84.87 Exact: 23.88 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:34:33 INFO: New best dev score: 0.84871 > 0.84494\n","2024-03-26 11:34:34 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 11:34:34 INFO: Epoch 15 finished\n","  Transitions correct: Counter({'Shift': 86641, 'Open': 78501, 'Close': 76665})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2058, ('Open', 'Open'): 1839, ('Open', 'Shift'): 1672, ('Shift', 'Close'): 1124, ('Close', 'Shift'): 1113, ('Close', 'Open'): 1030, ('Shift', 'Open'): 864})\n","  Total loss for epoch: 30575.54058\n","  Dev score      (   15): 0.848712\n","  Best dev score (   15): 0.848712\n","2024-03-26 11:34:35 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:34:35 INFO: Starting epoch 16\n","100% 167/167 [04:18<00:00,  1.55s/it, Epoch 16]\n","2024-03-26 11:38:53 INFO: Transitions correct: 243961\n","  Counter({'Shift': 87230, 'Open': 79133, 'Close': 77598})\n","2024-03-26 11:38:53 INFO: Transitions incorrect: 9023\n","  Counter({('Open', 'Close'): 1865, ('Open', 'Open'): 1773, ('Open', 'Shift'): 1503, ('Close', 'Shift'): 1118, ('Shift', 'Close'): 1066, ('Shift', 'Open'): 870, ('Close', 'Open'): 828})\n","2024-03-26 11:38:53 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2757, <RepairType.OPEN_CLOSE: 7>: 1489, <RepairType.WRONG_OPEN_GENERAL: 4>: 1428, <RepairType.OPEN_SHIFT: 6>: 1223, <RepairType.SHIFT_CLOSE: 8>: 1090, <RepairType.MISSED_UNARY: 5>: 465, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 241, <RepairType.CLOSE_SHIFT_NESTED: 9>: 214, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 104})\n","2024-03-26 11:38:53 INFO: Fake transitions used: 76\n","2024-03-26 11:38:53 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 72.84it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 84.45 LR: 84.6 F1: 84.52 Exact: 22.67 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.45 LR: 84.6 F1: 84.52 Exact: 22.67 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:39:02 INFO: Epoch 16 finished\n","  Transitions correct: Counter({'Shift': 87230, 'Open': 79133, 'Close': 77598})\n","  Transitions incorrect: Counter({('Open', 'Close'): 1865, ('Open', 'Open'): 1773, ('Open', 'Shift'): 1503, ('Close', 'Shift'): 1118, ('Shift', 'Close'): 1066, ('Shift', 'Open'): 870, ('Close', 'Open'): 828})\n","  Total loss for epoch: 28734.81870\n","  Dev score      (   16): 0.845283\n","  Best dev score (   15): 0.848712\n","2024-03-26 11:39:03 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:39:03 INFO: Starting epoch 17\n","100% 167/167 [04:20<00:00,  1.56s/it, Epoch 17]\n","2024-03-26 11:43:23 INFO: Transitions correct: 245565\n","  Counter({'Shift': 88131, 'Open': 79723, 'Close': 77711})\n","2024-03-26 11:43:23 INFO: Transitions incorrect: 9545\n","  Counter({('Open', 'Close'): 2142, ('Open', 'Open'): 1686, ('Open', 'Shift'): 1560, ('Close', 'Shift'): 1164, ('Shift', 'Close'): 1126, ('Close', 'Open'): 1051, ('Shift', 'Open'): 816})\n","2024-03-26 11:43:23 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2997, <RepairType.OPEN_CLOSE: 7>: 1714, <RepairType.WRONG_OPEN_GENERAL: 4>: 1305, <RepairType.OPEN_SHIFT: 6>: 1305, <RepairType.SHIFT_CLOSE: 8>: 1155, <RepairType.MISSED_UNARY: 5>: 457, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 285, <RepairType.CLOSE_SHIFT_NESTED: 9>: 208, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 96})\n","2024-03-26 11:43:23 INFO: Fake transitions used: 85\n","2024-03-26 11:43:23 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 75.25it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 81.09 LR: 82.04 F1: 81.56 Exact: 20.85 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 81.09 LR: 82.04 F1: 81.56 Exact: 20.85 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:43:31 INFO: Epoch 17 finished\n","  Transitions correct: Counter({'Shift': 88131, 'Open': 79723, 'Close': 77711})\n","  Transitions incorrect: Counter({('Open', 'Close'): 2142, ('Open', 'Open'): 1686, ('Open', 'Shift'): 1560, ('Close', 'Shift'): 1164, ('Shift', 'Close'): 1126, ('Close', 'Open'): 1051, ('Shift', 'Open'): 816})\n","  Total loss for epoch: 30323.81213\n","  Dev score      (   17): 0.815683\n","  Best dev score (   15): 0.848712\n","2024-03-26 11:43:32 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:43:32 INFO: Starting epoch 18\n","100% 167/167 [04:17<00:00,  1.54s/it, Epoch 18]\n","2024-03-26 11:47:50 INFO: Transitions correct: 244214\n","  Counter({'Shift': 87341, 'Open': 79234, 'Close': 77639})\n","2024-03-26 11:47:50 INFO: Transitions incorrect: 8535\n","  Counter({('Open', 'Close'): 1802, ('Open', 'Open'): 1554, ('Open', 'Shift'): 1467, ('Close', 'Shift'): 1090, ('Shift', 'Close'): 1050, ('Close', 'Open'): 819, ('Shift', 'Open'): 753})\n","2024-03-26 11:47:50 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2628, <RepairType.OPEN_CLOSE: 7>: 1415, <RepairType.OPEN_SHIFT: 6>: 1224, <RepairType.WRONG_OPEN_GENERAL: 4>: 1219, <RepairType.SHIFT_CLOSE: 8>: 1072, <RepairType.MISSED_UNARY: 5>: 421, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 227, <RepairType.CLOSE_SHIFT_NESTED: 9>: 205, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 98, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 6})\n","2024-03-26 11:47:50 INFO: Fake transitions used: 74\n","2024-03-26 11:47:50 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 71.80it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 67.92 LR: 75.22 F1: 71.38 Exact: 12.14 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 67.92 LR: 75.22 F1: 71.38 Exact: 12.14 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:47:59 INFO: Epoch 18 finished\n","  Transitions correct: Counter({'Shift': 87341, 'Open': 79234, 'Close': 77639})\n","  Transitions incorrect: Counter({('Open', 'Close'): 1802, ('Open', 'Open'): 1554, ('Open', 'Shift'): 1467, ('Close', 'Shift'): 1090, ('Shift', 'Close'): 1050, ('Close', 'Open'): 819, ('Shift', 'Open'): 753})\n","  Total loss for epoch: 27299.22590\n","  Dev score      (   18): 0.713895\n","  Best dev score (   15): 0.848712\n","2024-03-26 11:48:00 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:48:00 INFO: Starting epoch 19\n","100% 167/167 [04:19<00:00,  1.56s/it, Epoch 19]\n","2024-03-26 11:52:20 INFO: Transitions correct: 247333\n","  Counter({'Shift': 88372, 'Open': 80388, 'Close': 78573})\n","2024-03-26 11:52:20 INFO: Transitions incorrect: 8174\n","  Counter({('Open', 'Close'): 1815, ('Open', 'Open'): 1487, ('Open', 'Shift'): 1243, ('Shift', 'Close'): 1035, ('Close', 'Shift'): 969, ('Close', 'Open'): 953, ('Shift', 'Open'): 672})\n","2024-03-26 11:52:20 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2538, <RepairType.OPEN_CLOSE: 7>: 1482, <RepairType.WRONG_OPEN_GENERAL: 4>: 1175, <RepairType.SHIFT_CLOSE: 8>: 1056, <RepairType.OPEN_SHIFT: 6>: 1036, <RepairType.MISSED_UNARY: 5>: 381, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 220, <RepairType.CLOSE_SHIFT_NESTED: 9>: 177, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 92})\n","2024-03-26 11:52:20 INFO: Fake transitions used: 73\n","2024-03-26 11:52:20 INFO: Processing 494 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 494/494 [00:06<00:00, 72.48it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 85.12 LR: 85.83 F1: 85.47 Exact: 26.11 N: 494\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 85.12 LR: 85.83 F1: 85.47 Exact: 26.11 N: 494\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 494\n","2024-03-26 11:52:28 INFO: New best dev score: 0.85476 > 0.84871\n","2024-03-26 11:52:28 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency.pt\n","2024-03-26 11:52:28 INFO: Epoch 19 finished\n","  Transitions correct: Counter({'Shift': 88372, 'Open': 80388, 'Close': 78573})\n","  Transitions incorrect: Counter({('Open', 'Close'): 1815, ('Open', 'Open'): 1487, ('Open', 'Shift'): 1243, ('Shift', 'Close'): 1035, ('Close', 'Shift'): 969, ('Close', 'Open'): 953, ('Shift', 'Open'): 672})\n","  Total loss for epoch: 25652.56095\n","  Dev score      (   19): 0.854755\n","  Best dev score (   19): 0.854755\n","2024-03-26 11:52:29 INFO: Model saved to saved_models/constituency/en_masc_charlm_constituency_checkpoint.pt\n","2024-03-26 11:52:29 INFO: Starting epoch 20\n"," 90% 151/167 [03:43<00:25,  1.62s/it, Epoch 20]"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency en_masc --score_dev"],"metadata":{"id":"c9hvveIejYZy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711536727539,"user_tz":-60,"elapsed":81612,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"51965d58-2eec-4448-ab5e-9888537366e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-27 10:51:34 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py en_masc --score_dev\n","2024-03-27 10:51:34 INFO: Default pretrain should be /root/stanza_resources/en/pretrain/conll17.pt  Attempting to download\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 20.6MB/s]        \n","2024-03-27 10:51:34 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:51:34 INFO: Downloading these customized packages for language: en (English)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 107M/107M [00:00<00:00, 245MB/s] \n","2024-03-27 10:51:35 INFO: Downloaded file to /root/stanza_resources/en/pretrain/conll17.pt\n","2024-03-27 10:51:35 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:51:35 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.1MB/s]        \n","2024-03-27 10:51:35 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:51:35 INFO: Downloading these customized packages for language: en (English)...\n","=============================\n","| Processor      | Package  |\n","-----------------------------\n","| forward_charlm | 1billion |\n","=============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/forward_charlm/1billion.pt: 100% 22.7M/22.7M [00:00<00:00, 139MB/s] \n","2024-03-27 10:51:36 INFO: Downloaded file to /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-03-27 10:51:36 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:51:36 INFO: Downloaded model, using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 18.0MB/s]        \n","2024-03-27 10:51:36 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:51:36 INFO: Downloading these customized packages for language: en (English)...\n","==============================\n","| Processor       | Package  |\n","------------------------------\n","| backward_charlm | 1billion |\n","==============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/backward_charlm/1billion.pt: 100% 22.7M/22.7M [00:00<00:00, 161MB/s]\n","2024-03-27 10:51:36 INFO: Downloaded file to /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-03-27 10:51:36 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:51:36 INFO: Downloaded model, using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-03-27 10:51:36 INFO: Running dev step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg', '--shorthand', 'en_masc', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt']\n","2024-03-27 10:51:36 INFO: Expanded save_name: en_masc_charlm_constituency.pt\n","2024-03-27 10:51:37 INFO: Running constituency parser in predict mode\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.3MB/s]        \n","2024-03-27 10:51:37 INFO: Downloaded file to /root/stanza_resources/resources.json\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt: 100% 651k/651k [00:00<00:00, 13.9MB/s]\n","Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pos/combined_charlm.pt: 100% 38.6M/38.6M [00:00<00:00, 163MB/s]\n","2024-03-27 10:51:38 INFO: Loading these models for language: en (English):\n","===============================\n","| Processor | Package         |\n","-------------------------------\n","| tokenize  | combined        |\n","| pos       | combined_charlm |\n","===============================\n","\n","2024-03-27 10:51:38 INFO: Using device: cuda\n","2024-03-27 10:51:38 INFO: Loading: tokenize\n","2024-03-27 10:51:38 INFO: Loading: pos\n","2024-03-27 10:51:40 INFO: Done loading processors!\n","2024-03-27 10:51:43 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","2024-03-27 10:51:44 INFO: Read 520 trees for evaluation\n","2024-03-27 10:51:44 INFO: Retagging trees using the xpos tags from the default package...\n","100% 520/520 [00:04<00:00, 129.94it/s]\n","2024-03-27 10:51:48 INFO: Retagging finished\n","2024-03-27 10:51:48 INFO: Processing 520 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg\n","100% 520/520 [00:07<00:00, 67.46it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.7 sec].\n","pcfg LP/LR summary evalb: LP: 85.26 LR: 85.99 F1: 85.63 Exact: 26.15 N: 520\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 85.26 LR: 85.99 F1: 85.63 Exact: 26.15 N: 520\n","factor Tag summary evalb: LP: 95.07 LR: 95.07 F1: 95.07 Exact: 39.42 N: 520\n","2024-03-27 10:52:04 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/en_masc_dev.mrg: 0.856323\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency en_masc --score_test"],"metadata":{"id":"3PHhmglEjpax","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711536754835,"user_tz":-60,"elapsed":27299,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"942f2161-c926-41dc-e0a2-d2526c48a5b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-27 10:52:10 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py en_masc --score_test\n","2024-03-27 10:52:10 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-27 10:52:10 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-03-27 10:52:10 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-03-27 10:52:10 INFO: Running test step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/en_masc_test.mrg', '--shorthand', 'en_masc', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt']\n","2024-03-27 10:52:10 INFO: Expanded save_name: en_masc_charlm_constituency.pt\n","2024-03-27 10:52:10 INFO: Running constituency parser in predict mode\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 12.4MB/s]        \n","2024-03-27 10:52:10 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:52:11 INFO: Loading these models for language: en (English):\n","===============================\n","| Processor | Package         |\n","-------------------------------\n","| tokenize  | combined        |\n","| pos       | combined_charlm |\n","===============================\n","\n","2024-03-27 10:52:11 INFO: Using device: cuda\n","2024-03-27 10:52:11 INFO: Loading: tokenize\n","2024-03-27 10:52:11 INFO: Loading: pos\n","2024-03-27 10:52:13 INFO: Done loading processors!\n","2024-03-27 10:52:15 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_test.mrg\n","2024-03-27 10:52:16 INFO: Read 521 trees for evaluation\n","2024-03-27 10:52:16 INFO: Retagging trees using the xpos tags from the default package...\n","100% 521/521 [00:07<00:00, 65.13it/s]\n","2024-03-27 10:52:24 INFO: Retagging finished\n","2024-03-27 10:52:24 INFO: Processing 521 trees from /content/gdrive/MyDrive/PLN/2/constituency/en_masc_test.mrg\n","100% 521/521 [00:05<00:00, 89.75it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.6 sec].\n","pcfg LP/LR summary evalb: LP: 84.84 LR: 85.27 F1: 85.05 Exact: 33.58 N: 521\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 84.84 LR: 85.27 F1: 85.05 Exact: 33.58 N: 521\n","factor Tag summary evalb: LP: 95.23 LR: 95.23 F1: 95.23 Exact: 47.6 N: 521\n","2024-03-27 10:52:32 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/en_masc_test.mrg: 0.850585\n"]}]},{"cell_type":"markdown","source":["### PT"],"metadata":{"id":"YlLyrIR8pQB_"}},{"cell_type":"markdown","source":["Se modifica la función read_xml_file del script convert_cintil.py de Stanza para que parsee correctamente el treebank"],"metadata":{"id":"c35GDSE6l1T6"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.constituency.prepare_con_dataset pt_cintil"],"metadata":{"id":"FLgxOyJypR9d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711303280297,"user_tz":-60,"elapsed":145280,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"1d24ec7b-ef59-4b41-cf92-76316c8da1a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Read 785 synthetic trees\n","Read 9948 natural trees\n","Split 9948 trees into 7958 train 995 dev 995 test\n","Total lengths 8743 train 995 dev 995 test\n","Writing 8743 trees to /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_train.mrg\n","Writing 995 trees to /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","Writing 995 trees to /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_test.mrg\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency pt_cintil --epochs 20"],"metadata":{"id":"JkV6SSU0zyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711307900261,"user_tz":-60,"elapsed":4105474,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f75312b3-7c59-4f46-915f-4cf08b462275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-24 18:09:57 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py pt_cintil --epochs 100\n","2024-03-24 18:09:57 INFO: Using default pretrain for language, found in /root/stanza_resources/pt/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-24 18:09:57 INFO: Using model /root/stanza_resources/pt/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-24 18:09:57 INFO: Using model /root/stanza_resources/pt/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-24 18:09:57 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-24 18:09:57 INFO: Expanded save_name: pt_cintil_charlm_constituency.pt\n","2024-03-24 18:09:57 INFO: Expanded save_name: saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:09:57 INFO: pt_cintil: saved_models/constituency/pt_cintil_charlm_constituency.pt does not exist, training new model\n","2024-03-24 18:09:57 INFO: Using default pretrain for language, found in /root/stanza_resources/pt/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-24 18:09:57 INFO: Using model /root/stanza_resources/pt/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-24 18:09:57 INFO: Using model /root/stanza_resources/pt/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-24 18:09:57 INFO: Running train step with args: ['--train_file', '/content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_train.mrg', '--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg', '--shorthand', 'pt_cintil', '--mode', 'train', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/pt/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/pt/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/pt/backward_charlm/oscar2023.pt', '--epochs', '100']\n","2024-03-24 18:09:57 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-24 18:09:57 INFO: Expanded save_name: pt_cintil_charlm_constituency.pt\n","2024-03-24 18:09:58 INFO: Running constituency parser in train mode\n","2024-03-24 18:09:58 DEBUG: Set trainer logging level to DEBUG\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 20.0MB/s]        \n","2024-03-24 18:09:58 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-24 18:09:58 DEBUG: Creating retag pipeline for default package\n","2024-03-24 18:09:58 INFO: Loading these models for language: pt (Portuguese):\n","=============================\n","| Processor | Package       |\n","-----------------------------\n","| tokenize  | bosque        |\n","| pos       | bosque_charlm |\n","=============================\n","\n","2024-03-24 18:09:58 INFO: Using device: cuda\n","2024-03-24 18:09:58 INFO: Loading: tokenize\n","2024-03-24 18:09:58 INFO: Loading: pos\n","2024-03-24 18:10:00 INFO: Done loading processors!\n","2024-03-24 18:10:00 INFO: ARGS USED AT TRAINING TIME:\n","additional_oracle_levels: None\n","bert_finetune: False\n","bert_finetune_begin_epoch: None\n","bert_finetune_end_epoch: None\n","bert_finetune_layers: None\n","bert_hidden_layers: 4\n","bert_learning_rate: 0.009\n","bert_model: None\n","bert_weight_decay: 0.0001\n","charlm_backward_file: /root/stanza_resources/pt/backward_charlm/oscar2023.pt\n","charlm_forward_file: /root/stanza_resources/pt/forward_charlm/oscar2023.pt\n","check_valid_states: True\n","checkpoint: True\n","checkpoint_save_name: saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","combined_dummy_embedding: True\n","constituency_composition: ConstituencyComposition.MAX\n","constituent_heads: 8\n","constituent_stack: StackHistory.LSTM\n","data_dir: data/constituency\n","delta_embedding_dim: 100\n","device: cuda\n","epoch_size: 5000\n","epochs: 100\n","eval_batch_size: 50\n","eval_file: /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","finetune: False\n","grad_clipping: None\n","hidden_size: 512\n","lang: pt\n","lattn_attention_dropout: 0.2\n","lattn_combine_as_self: False\n","lattn_combined_input: True\n","lattn_d_ff: 2048\n","lattn_d_input_proj: None\n","lattn_d_kv: 64\n","lattn_d_l: 32\n","lattn_d_proj: 64\n","lattn_partitioned: True\n","lattn_pwff: True\n","lattn_q_as_matrix: False\n","lattn_relu_dropout: 0.2\n","lattn_resdrop: True\n","lattn_residual_dropout: 0.2\n","learning_beta2: 0.999\n","learning_eps: 1e-08\n","learning_momentum: None\n","learning_rate: 0.0002\n","learning_rate_cooldown: 10\n","learning_rate_factor: 0.6\n","learning_rate_min_lr: 4.000000000000001e-06\n","learning_rate_patience: 5\n","learning_rate_warmup: 0\n","learning_rho: 0.9\n","learning_weight_decay: 0.05\n","load_name: None\n","load_package: None\n","log_norms: False\n","log_shapes: False\n","lora_alpha: 128\n","lora_dropout: 0.1\n","lora_modules_to_save: []\n","lora_rank: 64\n","lora_target_modules: ['query', 'value', 'output.dense', 'intermediate.dense']\n","loss: cross\n","loss_focal_gamma: 2\n","lstm_input_dropout: 0.2\n","lstm_layer_dropout: 0.0\n","maxout_k: None\n","mode: train\n","multistage: True\n","nonlinearity: relu\n","num_generate: 0\n","num_lstm_layers: 2\n","num_output_layers: 3\n","num_tree_lstm_layers: 1\n","optim: adamw\n","oracle_forced_errors: 0.001\n","oracle_frequency: 0.8\n","oracle_initial_epoch: 1\n","oracle_level: None\n","pattn_attention_dropout: 0.2\n","pattn_bias: False\n","pattn_d_ff: 2048\n","pattn_d_kv: 64\n","pattn_d_model: 1024\n","pattn_encoder_max_len: 512\n","pattn_morpho_emb_dropout: 0.2\n","pattn_num_heads: 8\n","pattn_num_layers: 0\n","pattn_relu_dropout: 0.1\n","pattn_residual_dropout: 0.2\n","pattn_timing: sin\n","predict_dir: .\n","predict_dropout: 0.2\n","predict_file: None\n","predict_format: {:_O}\n","pretrain_max_vocab: 250000\n","rare_word_threshold: 0.02\n","rare_word_unknown_frequency: 0.02\n","reduce_heads: 8\n","reduce_position: 128\n","relearn_structure: False\n","retag_charlm_backward_file: None\n","retag_charlm_forward_file: None\n","retag_method: upos\n","retag_model_path: None\n","retag_package: default\n","retag_pretrain_path: None\n","retag_xpos: False\n","reversed: False\n","save_dir: saved_models/constituency\n","save_each_frequency: 1\n","save_each_name: saved_models/constituency/pt_cintil_charlm_constituency_%04d.pt\n","save_each_optimizer: True\n","save_each_start: None\n","save_name: saved_models/constituency/pt_cintil_charlm_constituency.pt\n","seed: 1234\n","sentence_boundary_vectors: SentenceBoundary.EVERYTHING\n","shorthand: pt_cintil\n","silver_epoch_size: None\n","silver_file: None\n","silver_remove_duplicates: False\n","stage1_bert_finetune: False\n","stage1_bert_learning_rate: 0.009\n","stage1_learning_rate: 1.0\n","stage1_learning_rate_min_lr: 0.02\n","tag_embedding_dim: 20\n","tag_unknown_frequency: 0.001\n","tokenized_dir: None\n","tokenized_file: None\n","train_batch_size: 30\n","train_file: /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_train.mrg\n","transition_embedding_dim: 20\n","transition_heads: 4\n","transition_hidden_size: 20\n","transition_scheme: TransitionScheme.IN_ORDER\n","transition_stack: StackHistory.LSTM\n","use_lattn: False\n","use_peft: False\n","use_silver_words: True\n","wandb: False\n","wandb_name: None\n","wandb_norm_regex: None\n","watch_regex: None\n","word_dropout: 0.2\n","wordvec_dir: extern_data/wordvec\n","wordvec_file: \n","wordvec_pretrain_file: /root/stanza_resources/pt/pretrain/conll17.pt\n","\n","2024-03-24 18:10:00 INFO: Directory saved_models/constituency does not exist; creating...\n","2024-03-24 18:10:00 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_train.mrg\n","100% 8743/8743 [00:01<00:00, 4743.96it/s]\n","2024-03-24 18:10:03 INFO: Read 8743 trees for the training set\n","2024-03-24 18:10:04 INFO: Filtered 101 duplicates from train dataset\n","2024-03-24 18:10:04 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","2024-03-24 18:10:04 INFO: Read 995 trees for the dev set\n","2024-03-24 18:10:05 INFO: Filtered 1 duplicates from dev dataset\n","2024-03-24 18:10:05 INFO: Retagging trees using the upos tags from the default package...\n","100% 8642/8642 [00:24<00:00, 349.13it/s]\n","100% 994/994 [00:03<00:00, 287.30it/s]\n","2024-03-24 18:10:33 INFO: Retagging finished\n","2024-03-24 18:10:33 INFO: Unique constituents in training set: [\"A'\", \"ADV'\", 'ADVP', 'AP', \"ART'\", \"C'\", \"CARD'\", \"CONJ'\", 'CONJP', 'CP', \"ITJ'\", \"N'\", 'NP', \"P'\", \"PERCENT'\", 'PERCENTP', \"POSS'\", 'PP', \"QNT'\", 'ROOT', 'S', \"V'\", 'VP']\n","2024-03-24 18:10:33 INFO: Constituent node counts: Counter({'NP': 27314, 'S': 20890, \"N'\": 15070, 'VP': 13038, 'PP': 12962, 'ROOT': 8642, \"V'\": 2317, 'AP': 1232, 'CP': 1219, \"ADV'\": 763, 'CONJP': 522, \"CARD'\": 433, 'ADVP': 354, \"P'\": 286, \"A'\": 96, \"CONJ'\": 78, \"PERCENT'\": 70, 'PERCENTP': 32, \"QNT'\": 15, \"POSS'\": 10, \"ITJ'\": 3, \"C'\": 2, \"ART'\": 1})\n","2024-03-24 18:10:34 INFO: Unique tags in training set: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n","2024-03-24 18:10:34 INFO: Unary limit: 4\n","2024-03-24 18:10:34 INFO: Building training transition sequences\n","100% 8642/8642 [00:00<00:00, 11906.55it/s]\n","2024-03-24 18:10:35 INFO: Building dev transition sequences\n","100% 994/994 [00:00<00:00, 22176.62it/s]\n","2024-03-24 18:10:35 INFO: Total unique transitions in train set: 25\n","2024-03-24 18:10:35 INFO: Unique transitions in training set: [Shift, CloseConstituent, OpenConstituent((\"A'\",)), OpenConstituent((\"ADV'\",)), OpenConstituent((\"ART'\",)), OpenConstituent((\"C'\",)), OpenConstituent((\"CARD'\",)), OpenConstituent((\"CONJ'\",)), OpenConstituent((\"ITJ'\",)), OpenConstituent((\"N'\",)), OpenConstituent((\"P'\",)), OpenConstituent((\"PERCENT'\",)), OpenConstituent((\"POSS'\",)), OpenConstituent((\"QNT'\",)), OpenConstituent((\"V'\",)), OpenConstituent(('ADVP',)), OpenConstituent(('AP',)), OpenConstituent(('CONJP',)), OpenConstituent(('CP',)), OpenConstituent(('NP',)), OpenConstituent(('PERCENTP',)), OpenConstituent(('PP',)), OpenConstituent(('ROOT',)), OpenConstituent(('S',)), OpenConstituent(('VP',))]\n","2024-03-24 18:10:35 INFO: Root labels in treebank: ['ROOT']\n","2024-03-24 18:10:35 INFO: Verifying the transition sequences for 8642 trees\n","100% 8642/8642 [00:04<00:00, 1931.14it/s]\n","2024-03-24 18:10:39 INFO: Verifying the transition sequences for 994 trees\n","100% 994/994 [00:00<00:00, 1917.58it/s]\n","2024-03-24 18:10:40 INFO: Using the following open nodes:\n","  (\"A'\",)\n","  (\"ADV'\",)\n","  ('ADVP',)\n","  ('AP',)\n","  (\"ART'\",)\n","  (\"C'\",)\n","  (\"CARD'\",)\n","  (\"CONJ'\",)\n","  ('CONJP',)\n","  ('CP',)\n","  (\"ITJ'\",)\n","  (\"N'\",)\n","  ('NP',)\n","  (\"P'\",)\n","  (\"PERCENT'\",)\n","  ('PERCENTP',)\n","  (\"POSS'\",)\n","  ('PP',)\n","  (\"QNT'\",)\n","  ('ROOT',)\n","  ('S',)\n","  (\"V'\",)\n","  ('VP',)\n","2024-03-24 18:10:40 INFO: Warming up model for 50 iterations using AdaDelta to train the embeddings\n","2024-03-24 18:10:41 DEBUG: Building Adadelta with lr=1.000000, weight_decay=0.02\n","2024-03-24 18:10:41 INFO: Number of words in the training set found in the embedding: 14427 out of 15504\n","2024-03-24 18:10:41 INFO: Building CrossEntropyLoss(sum)\n","2024-03-24 18:10:42 INFO: Starting epoch 1\n","100% 167/167 [03:05<00:00,  1.11s/it, Epoch 1]\n","2024-03-24 18:13:47 INFO: Transitions correct: 105122\n","  Counter({'Shift': 44429, 'Close': 30711, 'Open': 29982})\n","2024-03-24 18:13:47 INFO: Transitions incorrect: 61487\n","  Counter({('Open', 'Close'): 15430, ('Open', 'Open'): 15346, ('Close', 'Open'): 7280, ('Shift', 'Close'): 6988, ('Open', 'Shift'): 6881, ('Close', 'Shift'): 5586, ('Shift', 'Open'): 3976})\n","2024-03-24 18:13:47 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 15177, <RepairType.WRONG_OPEN_GENERAL: 4>: 10854, <RepairType.OPEN_CLOSE: 7>: 7691, <RepairType.SHIFT_CLOSE: 8>: 6710, <RepairType.OPEN_SHIFT: 6>: 4386, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 2922, <RepairType.MISSED_UNARY: 5>: 2340, <RepairType.CLOSE_SHIFT_NESTED: 9>: 1292, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 642, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 569})\n","2024-03-24 18:13:47 INFO: Fake transitions used: 30\n","2024-03-24 18:13:47 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:07<00:00, 126.02it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.7 sec].\n","pcfg LP/LR summary evalb: LP: 69.95 LR: 67.78 F1: 68.85 Exact: 9.45 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 69.95 LR: 67.78 F1: 68.85 Exact: 9.45 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:13:57 INFO: New best dev score: 0.68853 > 0.00000\n","2024-03-24 18:13:58 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:13:58 INFO: Epoch 1 finished\n","  Transitions correct: Counter({'Shift': 44429, 'Close': 30711, 'Open': 29982})\n","  Transitions incorrect: Counter({('Open', 'Close'): 15430, ('Open', 'Open'): 15346, ('Close', 'Open'): 7280, ('Shift', 'Close'): 6988, ('Open', 'Shift'): 6881, ('Close', 'Shift'): 5586, ('Shift', 'Open'): 3976})\n","  Total loss for epoch: 229513.27110\n","  Dev score      (    1): 0.688531\n","  Best dev score (    1): 0.688531\n","2024-03-24 18:13:59 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:13:59 INFO: Starting epoch 2\n","100% 167/167 [03:07<00:00,  1.13s/it, Epoch 2]\n","2024-03-24 18:17:07 INFO: Transitions correct: 145806\n","  Counter({'Shift': 51498, 'Open': 48128, 'Close': 46180})\n","2024-03-24 18:17:07 INFO: Transitions incorrect: 24592\n","  Counter({('Open', 'Open'): 7643, ('Open', 'Close'): 6743, ('Close', 'Open'): 3365, ('Shift', 'Close'): 2369, ('Close', 'Shift'): 2291, ('Shift', 'Open'): 1398, ('Open', 'Shift'): 783})\n","2024-03-24 18:17:07 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 6532, <RepairType.OPEN_CLOSE: 7>: 4385, <RepairType.WRONG_OPEN_GENERAL: 4>: 4200, <RepairType.SHIFT_CLOSE: 8>: 2352, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 2145, <RepairType.MISSED_UNARY: 5>: 1605, <RepairType.CLOSE_SHIFT_NESTED: 9>: 748, <RepairType.OPEN_SHIFT: 6>: 648, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 417, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 390})\n","2024-03-24 18:17:07 INFO: Fake transitions used: 42\n","2024-03-24 18:17:07 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:07<00:00, 124.50it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 77.58 LR: 76.78 F1: 77.18 Exact: 24.14 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 77.58 LR: 76.78 F1: 77.18 Exact: 24.14 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:17:17 INFO: New best dev score: 0.77181 > 0.68853\n","2024-03-24 18:17:18 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:17:18 INFO: Epoch 2 finished\n","  Transitions correct: Counter({'Shift': 51498, 'Open': 48128, 'Close': 46180})\n","  Transitions incorrect: Counter({('Open', 'Open'): 7643, ('Open', 'Close'): 6743, ('Close', 'Open'): 3365, ('Shift', 'Close'): 2369, ('Close', 'Shift'): 2291, ('Shift', 'Open'): 1398, ('Open', 'Shift'): 783})\n","  Total loss for epoch: 81937.27681\n","  Dev score      (    2): 0.771815\n","  Best dev score (    2): 0.771815\n","2024-03-24 18:17:20 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:17:20 INFO: Starting epoch 3\n","100% 167/167 [03:06<00:00,  1.12s/it, Epoch 3]\n","2024-03-24 18:20:27 INFO: Transitions correct: 155653\n","  Counter({'Shift': 52517, 'Open': 52326, 'Close': 50810})\n","2024-03-24 18:20:27 INFO: Transitions incorrect: 16236\n","  Counter({('Open', 'Open'): 5170, ('Open', 'Close'): 4186, ('Close', 'Open'): 2532, ('Close', 'Shift'): 1552, ('Shift', 'Close'): 1517, ('Shift', 'Open'): 774, ('Open', 'Shift'): 505})\n","2024-03-24 18:20:27 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4677, <RepairType.WRONG_OPEN_GENERAL: 4>: 3222, <RepairType.OPEN_CLOSE: 7>: 2842, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1593, <RepairType.SHIFT_CLOSE: 8>: 1524, <RepairType.MISSED_UNARY: 5>: 1005, <RepairType.CLOSE_SHIFT_NESTED: 9>: 550, <RepairType.OPEN_SHIFT: 6>: 402, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 255, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 97})\n","2024-03-24 18:20:27 INFO: Fake transitions used: 52\n","2024-03-24 18:20:27 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 112.90it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 82.83 LR: 79.19 F1: 80.97 Exact: 34.3 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.83 LR: 79.19 F1: 80.97 Exact: 34.3 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:20:37 INFO: New best dev score: 0.80973 > 0.77181\n","2024-03-24 18:20:37 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:20:37 INFO: Epoch 3 finished\n","  Transitions correct: Counter({'Shift': 52517, 'Open': 52326, 'Close': 50810})\n","  Transitions incorrect: Counter({('Open', 'Open'): 5170, ('Open', 'Close'): 4186, ('Close', 'Open'): 2532, ('Close', 'Shift'): 1552, ('Shift', 'Close'): 1517, ('Shift', 'Open'): 774, ('Open', 'Shift'): 505})\n","  Total loss for epoch: 51259.68271\n","  Dev score      (    3): 0.809731\n","  Best dev score (    3): 0.809731\n","2024-03-24 18:20:39 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:20:39 INFO: Starting epoch 4\n","100% 167/167 [03:09<00:00,  1.14s/it, Epoch 4]\n","2024-03-24 18:23:49 INFO: Transitions correct: 160980\n","  Counter({'Open': 54391, 'Shift': 53419, 'Close': 53170})\n","2024-03-24 18:23:49 INFO: Transitions incorrect: 12673\n","  Counter({('Open', 'Open'): 4068, ('Open', 'Close'): 3354, ('Close', 'Open'): 2002, ('Shift', 'Close'): 1137, ('Close', 'Shift'): 1109, ('Shift', 'Open'): 593, ('Open', 'Shift'): 410})\n","2024-03-24 18:23:49 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 3540, <RepairType.WRONG_OPEN_GENERAL: 4>: 2570, <RepairType.OPEN_CLOSE: 7>: 2360, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1259, <RepairType.SHIFT_CLOSE: 8>: 1153, <RepairType.MISSED_UNARY: 5>: 766, <RepairType.CLOSE_SHIFT_NESTED: 9>: 408, <RepairType.OPEN_SHIFT: 6>: 335, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 187, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 51})\n","2024-03-24 18:23:49 INFO: Fake transitions used: 59\n","2024-03-24 18:23:49 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 122.87it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.6 sec].\n","pcfg LP/LR summary evalb: LP: 87.62 LR: 86.17 F1: 86.89 Exact: 43.86 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 87.62 LR: 86.17 F1: 86.89 Exact: 43.86 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:23:59 INFO: New best dev score: 0.86896 > 0.80973\n","2024-03-24 18:23:59 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:23:59 INFO: Epoch 4 finished\n","  Transitions correct: Counter({'Open': 54391, 'Shift': 53419, 'Close': 53170})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4068, ('Open', 'Close'): 3354, ('Close', 'Open'): 2002, ('Shift', 'Close'): 1137, ('Close', 'Shift'): 1109, ('Shift', 'Open'): 593, ('Open', 'Shift'): 410})\n","  Total loss for epoch: 41073.48949\n","  Dev score      (    4): 0.868961\n","  Best dev score (    4): 0.868961\n","2024-03-24 18:24:01 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:24:01 INFO: Starting epoch 5\n","100% 167/167 [03:11<00:00,  1.15s/it, Epoch 5]\n","2024-03-24 18:27:13 INFO: Transitions correct: 163017\n","  Counter({'Open': 55099, 'Close': 54442, 'Shift': 53476})\n","2024-03-24 18:27:13 INFO: Transitions incorrect: 12639\n","  Counter({('Open', 'Open'): 4098, ('Open', 'Close'): 3102, ('Close', 'Open'): 1839, ('Shift', 'Close'): 1410, ('Close', 'Shift'): 1338, ('Shift', 'Open'): 509, ('Open', 'Shift'): 343})\n","2024-03-24 18:27:13 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 3166, <RepairType.WRONG_OPEN_GENERAL: 4>: 2189, <RepairType.OPEN_CLOSE: 7>: 1854, <RepairType.SHIFT_CLOSE: 8>: 1382, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1098, <RepairType.MISSED_UNARY: 5>: 662, <RepairType.CLOSE_SHIFT_NESTED: 9>: 410, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 409, <RepairType.OPEN_SHIFT: 6>: 277, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 208})\n","2024-03-24 18:27:13 INFO: Fake transitions used: 67\n","2024-03-24 18:27:13 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 119.17it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 89.19 LR: 87.88 F1: 88.53 Exact: 48.39 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 89.19 LR: 87.88 F1: 88.53 Exact: 48.39 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:27:22 INFO: New best dev score: 0.88535 > 0.86896\n","2024-03-24 18:27:22 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:27:22 INFO: Epoch 5 finished\n","  Transitions correct: Counter({'Open': 55099, 'Close': 54442, 'Shift': 53476})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4098, ('Open', 'Close'): 3102, ('Close', 'Open'): 1839, ('Shift', 'Close'): 1410, ('Close', 'Shift'): 1338, ('Shift', 'Open'): 509, ('Open', 'Shift'): 343})\n","  Total loss for epoch: 41512.19645\n","  Dev score      (    5): 0.885349\n","  Best dev score (    5): 0.885349\n","2024-03-24 18:27:23 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:27:23 INFO: Starting epoch 6\n","100% 167/167 [03:11<00:00,  1.15s/it, Epoch 6]\n","2024-03-24 18:30:35 INFO: Transitions correct: 164612\n","  Counter({'Open': 55965, 'Close': 54864, 'Shift': 53783})\n","2024-03-24 18:30:35 INFO: Transitions incorrect: 10225\n","  Counter({('Open', 'Open'): 3249, ('Open', 'Close'): 2669, ('Close', 'Open'): 1772, ('Close', 'Shift'): 926, ('Shift', 'Close'): 914, ('Shift', 'Open'): 418, ('Open', 'Shift'): 277})\n","2024-03-24 18:30:35 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2988, <RepairType.WRONG_OPEN_GENERAL: 4>: 1949, <RepairType.OPEN_CLOSE: 7>: 1835, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1112, <RepairType.SHIFT_CLOSE: 8>: 927, <RepairType.MISSED_UNARY: 5>: 645, <RepairType.CLOSE_SHIFT_NESTED: 9>: 348, <RepairType.OPEN_SHIFT: 6>: 217, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 154, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 34})\n","2024-03-24 18:30:35 INFO: Fake transitions used: 65\n","2024-03-24 18:30:35 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 120.30it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 85.38 LR: 81.34 F1: 83.31 Exact: 42.15 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 85.38 LR: 81.34 F1: 83.31 Exact: 42.15 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:30:44 INFO: Epoch 6 finished\n","  Transitions correct: Counter({'Open': 55965, 'Close': 54864, 'Shift': 53783})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3249, ('Open', 'Close'): 2669, ('Close', 'Open'): 1772, ('Close', 'Shift'): 926, ('Shift', 'Close'): 914, ('Shift', 'Open'): 418, ('Open', 'Shift'): 277})\n","  Total loss for epoch: 33264.19904\n","  Dev score      (    6): 0.833148\n","  Best dev score (    5): 0.885349\n","2024-03-24 18:30:45 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:30:45 INFO: Starting epoch 7\n","100% 167/167 [03:07<00:00,  1.12s/it, Epoch 7]\n","2024-03-24 18:33:53 INFO: Transitions correct: 163725\n","  Counter({'Open': 55518, 'Close': 54941, 'Shift': 53266})\n","2024-03-24 18:33:53 INFO: Transitions incorrect: 9092\n","  Counter({('Open', 'Open'): 3062, ('Open', 'Close'): 2286, ('Close', 'Open'): 1406, ('Shift', 'Close'): 847, ('Close', 'Shift'): 803, ('Shift', 'Open'): 380, ('Open', 'Shift'): 308})\n","2024-03-24 18:33:53 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2482, <RepairType.WRONG_OPEN_GENERAL: 4>: 1921, <RepairType.OPEN_CLOSE: 7>: 1578, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 957, <RepairType.SHIFT_CLOSE: 8>: 855, <RepairType.MISSED_UNARY: 5>: 546, <RepairType.CLOSE_SHIFT_NESTED: 9>: 298, <RepairType.OPEN_SHIFT: 6>: 249, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 139, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 45})\n","2024-03-24 18:33:53 INFO: Fake transitions used: 58\n","2024-03-24 18:33:53 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 114.15it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 89.08 LR: 87.78 F1: 88.43 Exact: 52.31 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 89.08 LR: 87.78 F1: 88.43 Exact: 52.31 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:34:03 INFO: Epoch 7 finished\n","  Transitions correct: Counter({'Open': 55518, 'Close': 54941, 'Shift': 53266})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3062, ('Open', 'Close'): 2286, ('Close', 'Open'): 1406, ('Shift', 'Close'): 847, ('Close', 'Shift'): 803, ('Shift', 'Open'): 380, ('Open', 'Shift'): 308})\n","  Total loss for epoch: 29387.29547\n","  Dev score      (    7): 0.884303\n","  Best dev score (    5): 0.885349\n","2024-03-24 18:34:04 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:34:04 INFO: Starting epoch 8\n","100% 167/167 [03:07<00:00,  1.12s/it, Epoch 8]\n","2024-03-24 18:37:11 INFO: Transitions correct: 166777\n","  Counter({'Open': 56667, 'Close': 56059, 'Shift': 54051})\n","2024-03-24 18:37:11 INFO: Transitions incorrect: 8437\n","  Counter({('Open', 'Open'): 2842, ('Open', 'Close'): 2132, ('Close', 'Open'): 1322, ('Shift', 'Close'): 805, ('Close', 'Shift'): 778, ('Shift', 'Open'): 308, ('Open', 'Shift'): 250})\n","2024-03-24 18:37:11 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2305, <RepairType.WRONG_OPEN_GENERAL: 4>: 1783, <RepairType.OPEN_CLOSE: 7>: 1450, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 887, <RepairType.SHIFT_CLOSE: 8>: 808, <RepairType.MISSED_UNARY: 5>: 528, <RepairType.CLOSE_SHIFT_NESTED: 9>: 290, <RepairType.OPEN_SHIFT: 6>: 204, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 137, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 35})\n","2024-03-24 18:37:11 INFO: Fake transitions used: 49\n","2024-03-24 18:37:11 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 119.35it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 88.68 LR: 86.09 F1: 87.37 Exact: 49.89 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 88.68 LR: 86.09 F1: 87.37 Exact: 49.89 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:37:21 INFO: Epoch 8 finished\n","  Transitions correct: Counter({'Open': 56667, 'Close': 56059, 'Shift': 54051})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2842, ('Open', 'Close'): 2132, ('Close', 'Open'): 1322, ('Shift', 'Close'): 805, ('Close', 'Shift'): 778, ('Shift', 'Open'): 308, ('Open', 'Shift'): 250})\n","  Total loss for epoch: 27433.76813\n","  Dev score      (    8): 0.873719\n","  Best dev score (    5): 0.885349\n","2024-03-24 18:37:23 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:37:23 INFO: Starting epoch 9\n","100% 167/167 [03:10<00:00,  1.14s/it, Epoch 9]\n","2024-03-24 18:40:34 INFO: Transitions correct: 164102\n","  Counter({'Open': 55724, 'Close': 55272, 'Shift': 53106})\n","2024-03-24 18:40:34 INFO: Transitions incorrect: 9844\n","  Counter({('Open', 'Open'): 3331, ('Open', 'Close'): 2371, ('Close', 'Open'): 1427, ('Shift', 'Close'): 1234, ('Close', 'Shift'): 953, ('Shift', 'Open'): 295, ('Open', 'Shift'): 233})\n","2024-03-24 18:40:34 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2295, <RepairType.WRONG_OPEN_GENERAL: 4>: 1747, <RepairType.OPEN_CLOSE: 7>: 1458, <RepairType.SHIFT_CLOSE: 8>: 1190, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 859, <RepairType.MISSED_UNARY: 5>: 493, <RepairType.CLOSE_SHIFT_NESTED: 9>: 300, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 264, <RepairType.OPEN_SHIFT: 6>: 173, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 147})\n","2024-03-24 18:40:34 INFO: Fake transitions used: 55\n","2024-03-24 18:40:34 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 116.09it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 89.44 LR: 88.17 F1: 88.8 Exact: 51.71 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 89.44 LR: 88.17 F1: 88.8 Exact: 51.71 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:40:43 INFO: New best dev score: 0.88809 > 0.88535\n","2024-03-24 18:40:44 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:40:44 INFO: Epoch 9 finished\n","  Transitions correct: Counter({'Open': 55724, 'Close': 55272, 'Shift': 53106})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3331, ('Open', 'Close'): 2371, ('Close', 'Open'): 1427, ('Shift', 'Close'): 1234, ('Close', 'Shift'): 953, ('Shift', 'Open'): 295, ('Open', 'Shift'): 233})\n","  Total loss for epoch: 36078.59110\n","  Dev score      (    9): 0.888086\n","  Best dev score (    9): 0.888086\n","2024-03-24 18:40:45 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:40:45 INFO: Starting epoch 10\n","100% 167/167 [03:11<00:00,  1.15s/it, Epoch 10]\n","2024-03-24 18:43:56 INFO: Transitions correct: 166747\n","  Counter({'Open': 56787, 'Close': 56067, 'Shift': 53893})\n","2024-03-24 18:43:56 INFO: Transitions incorrect: 8238\n","  Counter({('Open', 'Open'): 2693, ('Open', 'Close'): 2124, ('Close', 'Open'): 1304, ('Shift', 'Close'): 817, ('Close', 'Shift'): 752, ('Shift', 'Open'): 316, ('Open', 'Shift'): 232})\n","2024-03-24 18:43:56 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2223, <RepairType.WRONG_OPEN_GENERAL: 4>: 1618, <RepairType.OPEN_CLOSE: 7>: 1493, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 900, <RepairType.SHIFT_CLOSE: 8>: 821, <RepairType.MISSED_UNARY: 5>: 486, <RepairType.CLOSE_SHIFT_NESTED: 9>: 308, <RepairType.OPEN_SHIFT: 6>: 202, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 131, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 43})\n","2024-03-24 18:43:56 INFO: Fake transitions used: 60\n","2024-03-24 18:43:56 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:07<00:00, 129.60it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 90.02 LR: 88.79 F1: 89.4 Exact: 48.99 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 90.02 LR: 88.79 F1: 89.4 Exact: 48.99 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:44:05 INFO: New best dev score: 0.89405 > 0.88809\n","2024-03-24 18:44:06 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:44:06 INFO: Epoch 10 finished\n","  Transitions correct: Counter({'Open': 56787, 'Close': 56067, 'Shift': 53893})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2693, ('Open', 'Close'): 2124, ('Close', 'Open'): 1304, ('Shift', 'Close'): 817, ('Close', 'Shift'): 752, ('Shift', 'Open'): 316, ('Open', 'Shift'): 232})\n","  Total loss for epoch: 26090.49163\n","  Dev score      (   10): 0.894054\n","  Best dev score (   10): 0.894054\n","2024-03-24 18:44:11 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:44:11 INFO: Starting epoch 11\n","100% 167/167 [03:12<00:00,  1.15s/it, Epoch 11]\n","2024-03-24 18:47:24 INFO: Transitions correct: 167990\n","  Counter({'Open': 57289, 'Close': 56512, 'Shift': 54189})\n","2024-03-24 18:47:24 INFO: Transitions incorrect: 7391\n","  Counter({('Open', 'Open'): 2397, ('Open', 'Close'): 1988, ('Close', 'Open'): 1193, ('Shift', 'Close'): 749, ('Close', 'Shift'): 656, ('Shift', 'Open'): 241, ('Open', 'Shift'): 167})\n","2024-03-24 18:47:24 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2003, <RepairType.WRONG_OPEN_GENERAL: 4>: 1486, <RepairType.OPEN_CLOSE: 7>: 1413, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 769, <RepairType.SHIFT_CLOSE: 8>: 760, <RepairType.MISSED_UNARY: 5>: 446, <RepairType.CLOSE_SHIFT_NESTED: 9>: 235, <RepairType.OPEN_SHIFT: 6>: 131, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 117, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 25})\n","2024-03-24 18:47:24 INFO: Fake transitions used: 57\n","2024-03-24 18:47:24 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 122.63it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 89.2 LR: 89.16 F1: 89.18 Exact: 51.6 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 89.2 LR: 89.16 F1: 89.18 Exact: 51.6 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:47:33 INFO: Epoch 11 finished\n","  Transitions correct: Counter({'Open': 57289, 'Close': 56512, 'Shift': 54189})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2397, ('Open', 'Close'): 1988, ('Close', 'Open'): 1193, ('Shift', 'Close'): 749, ('Close', 'Shift'): 656, ('Shift', 'Open'): 241, ('Open', 'Shift'): 167})\n","  Total loss for epoch: 23881.51911\n","  Dev score      (   11): 0.891827\n","  Best dev score (   10): 0.894054\n","2024-03-24 18:47:34 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:47:34 INFO: Starting epoch 12\n","100% 167/167 [03:12<00:00,  1.15s/it, Epoch 12]\n","2024-03-24 18:50:47 INFO: Transitions correct: 166413\n","  Counter({'Open': 56789, 'Close': 56207, 'Shift': 53417})\n","2024-03-24 18:50:47 INFO: Transitions incorrect: 7168\n","  Counter({('Open', 'Open'): 2421, ('Open', 'Close'): 1791, ('Close', 'Open'): 1162, ('Shift', 'Close'): 699, ('Close', 'Shift'): 622, ('Shift', 'Open'): 272, ('Open', 'Shift'): 201})\n","2024-03-24 18:50:47 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1942, <RepairType.WRONG_OPEN_GENERAL: 4>: 1484, <RepairType.OPEN_CLOSE: 7>: 1248, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 782, <RepairType.SHIFT_CLOSE: 8>: 701, <RepairType.MISSED_UNARY: 5>: 452, <RepairType.CLOSE_SHIFT_NESTED: 9>: 235, <RepairType.OPEN_SHIFT: 6>: 157, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 125, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 30})\n","2024-03-24 18:50:47 INFO: Fake transitions used: 45\n","2024-03-24 18:50:47 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 110.52it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 89.87 LR: 88.44 F1: 89.15 Exact: 51.71 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 89.87 LR: 88.44 F1: 89.15 Exact: 51.71 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:50:57 INFO: Epoch 12 finished\n","  Transitions correct: Counter({'Open': 56789, 'Close': 56207, 'Shift': 53417})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2421, ('Open', 'Close'): 1791, ('Close', 'Open'): 1162, ('Shift', 'Close'): 699, ('Close', 'Shift'): 622, ('Shift', 'Open'): 272, ('Open', 'Shift'): 201})\n","  Total loss for epoch: 22926.84088\n","  Dev score      (   12): 0.891554\n","  Best dev score (   10): 0.894054\n","2024-03-24 18:51:00 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:51:00 INFO: Starting epoch 13\n","100% 167/167 [03:12<00:00,  1.15s/it, Epoch 13]\n","2024-03-24 18:54:12 INFO: Transitions correct: 166873\n","  Counter({'Open': 56863, 'Close': 56310, 'Shift': 53700})\n","2024-03-24 18:54:12 INFO: Transitions incorrect: 9450\n","  Counter({('Open', 'Open'): 3017, ('Open', 'Close'): 2125, ('Shift', 'Close'): 1543, ('Close', 'Open'): 1208, ('Close', 'Shift'): 917, ('Shift', 'Open'): 350, ('Open', 'Shift'): 290})\n","2024-03-24 18:54:12 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 2115, <RepairType.WRONG_OPEN_GENERAL: 4>: 1492, <RepairType.SHIFT_CLOSE: 8>: 1489, <RepairType.OPEN_CLOSE: 7>: 1338, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 737, <RepairType.MISSED_UNARY: 5>: 417, <RepairType.CLOSE_SHIFT_NESTED: 9>: 309, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 256, <RepairType.OPEN_SHIFT: 6>: 200, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 125})\n","2024-03-24 18:54:12 INFO: Fake transitions used: 64\n","2024-03-24 18:54:12 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 122.98it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 91.98 LR: 91.45 F1: 91.71 Exact: 59.75 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 91.98 LR: 91.45 F1: 91.71 Exact: 59.75 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:54:22 INFO: New best dev score: 0.91720 > 0.89405\n","2024-03-24 18:54:22 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 18:54:22 INFO: Epoch 13 finished\n","  Transitions correct: Counter({'Open': 56863, 'Close': 56310, 'Shift': 53700})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3017, ('Open', 'Close'): 2125, ('Shift', 'Close'): 1543, ('Close', 'Open'): 1208, ('Close', 'Shift'): 917, ('Shift', 'Open'): 350, ('Open', 'Shift'): 290})\n","  Total loss for epoch: 33059.55314\n","  Dev score      (   13): 0.917199\n","  Best dev score (   13): 0.917199\n","2024-03-24 18:54:23 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:54:23 INFO: Starting epoch 14\n","100% 167/167 [03:10<00:00,  1.14s/it, Epoch 14]\n","2024-03-24 18:57:34 INFO: Transitions correct: 168448\n","  Counter({'Open': 57537, 'Close': 56957, 'Shift': 53954})\n","2024-03-24 18:57:34 INFO: Transitions incorrect: 6777\n","  Counter({('Open', 'Open'): 2243, ('Open', 'Close'): 1708, ('Close', 'Open'): 1136, ('Shift', 'Close'): 652, ('Close', 'Shift'): 600, ('Shift', 'Open'): 233, ('Open', 'Shift'): 205})\n","2024-03-24 18:57:34 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1857, <RepairType.WRONG_OPEN_GENERAL: 4>: 1393, <RepairType.OPEN_CLOSE: 7>: 1196, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 722, <RepairType.SHIFT_CLOSE: 8>: 657, <RepairType.MISSED_UNARY: 5>: 415, <RepairType.CLOSE_SHIFT_NESTED: 9>: 233, <RepairType.OPEN_SHIFT: 6>: 170, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 106, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 21})\n","2024-03-24 18:57:34 INFO: Fake transitions used: 53\n","2024-03-24 18:57:34 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 112.41it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 88.63 LR: 86.62 F1: 87.61 Exact: 46.07 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 88.63 LR: 86.62 F1: 87.61 Exact: 46.07 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 18:57:44 INFO: Epoch 14 finished\n","  Transitions correct: Counter({'Open': 57537, 'Close': 56957, 'Shift': 53954})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2243, ('Open', 'Close'): 1708, ('Close', 'Open'): 1136, ('Shift', 'Close'): 652, ('Close', 'Shift'): 600, ('Shift', 'Open'): 233, ('Open', 'Shift'): 205})\n","  Total loss for epoch: 21598.53517\n","  Dev score      (   14): 0.876146\n","  Best dev score (   13): 0.917199\n","2024-03-24 18:57:45 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 18:57:45 INFO: Starting epoch 15\n","100% 167/167 [03:11<00:00,  1.15s/it, Epoch 15]\n","2024-03-24 19:00:56 INFO: Transitions correct: 167962\n","  Counter({'Open': 57441, 'Close': 56764, 'Shift': 53757})\n","2024-03-24 19:00:56 INFO: Transitions incorrect: 6478\n","  Counter({('Open', 'Open'): 2102, ('Open', 'Close'): 1687, ('Close', 'Open'): 1048, ('Shift', 'Close'): 657, ('Close', 'Shift'): 553, ('Shift', 'Open'): 246, ('Open', 'Shift'): 185})\n","2024-03-24 19:00:56 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1762, <RepairType.WRONG_OPEN_GENERAL: 4>: 1227, <RepairType.OPEN_CLOSE: 7>: 1142, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 720, <RepairType.SHIFT_CLOSE: 8>: 661, <RepairType.MISSED_UNARY: 5>: 420, <RepairType.CLOSE_SHIFT_NESTED: 9>: 225, <RepairType.OPEN_SHIFT: 6>: 160, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 118, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 37})\n","2024-03-24 19:00:56 INFO: Fake transitions used: 50\n","2024-03-24 19:00:56 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:09<00:00, 109.79it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 90.64 LR: 89.49 F1: 90.06 Exact: 54.22 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 90.64 LR: 89.49 F1: 90.06 Exact: 54.22 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:01:07 INFO: Epoch 15 finished\n","  Transitions correct: Counter({'Open': 57441, 'Close': 56764, 'Shift': 53757})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2102, ('Open', 'Close'): 1687, ('Close', 'Open'): 1048, ('Shift', 'Close'): 657, ('Close', 'Shift'): 553, ('Shift', 'Open'): 246, ('Open', 'Shift'): 185})\n","  Total loss for epoch: 20678.47822\n","  Dev score      (   15): 0.900660\n","  Best dev score (   13): 0.917199\n","2024-03-24 19:01:08 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:01:08 INFO: Starting epoch 16\n","100% 167/167 [03:09<00:00,  1.13s/it, Epoch 16]\n","2024-03-24 19:04:17 INFO: Transitions correct: 167611\n","  Counter({'Open': 57225, 'Close': 56580, 'Shift': 53806})\n","2024-03-24 19:04:17 INFO: Transitions incorrect: 6601\n","  Counter({('Open', 'Open'): 2153, ('Open', 'Close'): 1701, ('Close', 'Open'): 1160, ('Shift', 'Close'): 598, ('Close', 'Shift'): 552, ('Shift', 'Open'): 247, ('Open', 'Shift'): 190})\n","2024-03-24 19:04:17 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1890, <RepairType.WRONG_OPEN_GENERAL: 4>: 1327, <RepairType.OPEN_CLOSE: 7>: 1178, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 701, <RepairType.SHIFT_CLOSE: 8>: 603, <RepairType.MISSED_UNARY: 5>: 411, <RepairType.CLOSE_SHIFT_NESTED: 9>: 199, <RepairType.OPEN_SHIFT: 6>: 159, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 103, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 22})\n","2024-03-24 19:04:17 INFO: Fake transitions used: 66\n","2024-03-24 19:04:17 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 116.84it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 90.81 LR: 90.03 F1: 90.42 Exact: 55.23 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 90.81 LR: 90.03 F1: 90.42 Exact: 55.23 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:04:27 INFO: Epoch 16 finished\n","  Transitions correct: Counter({'Open': 57225, 'Close': 56580, 'Shift': 53806})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2153, ('Open', 'Close'): 1701, ('Close', 'Open'): 1160, ('Shift', 'Close'): 598, ('Close', 'Shift'): 552, ('Shift', 'Open'): 247, ('Open', 'Shift'): 190})\n","  Total loss for epoch: 21595.75851\n","  Dev score      (   16): 0.904229\n","  Best dev score (   13): 0.917199\n","2024-03-24 19:04:28 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:04:28 INFO: Starting epoch 17\n","100% 167/167 [03:14<00:00,  1.16s/it, Epoch 17]\n","2024-03-24 19:07:43 INFO: Transitions correct: 169634\n","  Counter({'Open': 58015, 'Close': 57305, 'Shift': 54314})\n","2024-03-24 19:07:43 INFO: Transitions incorrect: 6254\n","  Counter({('Open', 'Open'): 1987, ('Open', 'Close'): 1643, ('Close', 'Open'): 1060, ('Shift', 'Close'): 603, ('Close', 'Shift'): 555, ('Shift', 'Open'): 228, ('Open', 'Shift'): 178})\n","2024-03-24 19:07:43 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1767, <RepairType.WRONG_OPEN_GENERAL: 4>: 1175, <RepairType.OPEN_CLOSE: 7>: 1171, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 662, <RepairType.SHIFT_CLOSE: 8>: 605, <RepairType.MISSED_UNARY: 5>: 365, <RepairType.CLOSE_SHIFT_NESTED: 9>: 201, <RepairType.OPEN_SHIFT: 6>: 145, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 124, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 26})\n","2024-03-24 19:07:43 INFO: Fake transitions used: 63\n","2024-03-24 19:07:43 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:09<00:00, 108.80it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 91.41 LR: 90.62 F1: 91.01 Exact: 57.54 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 91.41 LR: 90.62 F1: 91.01 Exact: 57.54 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:07:53 INFO: Epoch 17 finished\n","  Transitions correct: Counter({'Open': 58015, 'Close': 57305, 'Shift': 54314})\n","  Transitions incorrect: Counter({('Open', 'Open'): 1987, ('Open', 'Close'): 1643, ('Close', 'Open'): 1060, ('Shift', 'Close'): 603, ('Close', 'Shift'): 555, ('Shift', 'Open'): 228, ('Open', 'Shift'): 178})\n","  Total loss for epoch: 19723.71143\n","  Dev score      (   17): 0.910160\n","  Best dev score (   13): 0.917199\n","2024-03-24 19:07:54 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:07:54 INFO: Starting epoch 18\n","100% 167/167 [03:13<00:00,  1.16s/it, Epoch 18]\n","2024-03-24 19:11:07 INFO: Transitions correct: 167581\n","  Counter({'Open': 57315, 'Close': 56644, 'Shift': 53622})\n","2024-03-24 19:11:07 INFO: Transitions incorrect: 6571\n","  Counter({('Open', 'Open'): 2113, ('Open', 'Close'): 1640, ('Close', 'Open'): 1068, ('Shift', 'Close'): 666, ('Close', 'Shift'): 654, ('Shift', 'Open'): 242, ('Open', 'Shift'): 188})\n","2024-03-24 19:11:07 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1835, <RepairType.WRONG_OPEN_GENERAL: 4>: 1277, <RepairType.OPEN_CLOSE: 7>: 1158, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 671, <RepairType.SHIFT_CLOSE: 8>: 668, <RepairType.MISSED_UNARY: 5>: 375, <RepairType.CLOSE_SHIFT_NESTED: 9>: 247, <RepairType.OPEN_SHIFT: 6>: 157, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 111, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 49})\n","2024-03-24 19:11:07 INFO: Fake transitions used: 40\n","2024-03-24 19:11:07 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 115.32it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 92.24 LR: 91.72 F1: 91.98 Exact: 62.47 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 92.24 LR: 91.72 F1: 91.98 Exact: 62.47 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:11:18 INFO: New best dev score: 0.91986 > 0.91720\n","2024-03-24 19:11:18 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency.pt\n","2024-03-24 19:11:18 INFO: Epoch 18 finished\n","  Transitions correct: Counter({'Open': 57315, 'Close': 56644, 'Shift': 53622})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2113, ('Open', 'Close'): 1640, ('Close', 'Open'): 1068, ('Shift', 'Close'): 666, ('Close', 'Shift'): 654, ('Shift', 'Open'): 242, ('Open', 'Shift'): 188})\n","  Total loss for epoch: 21287.66731\n","  Dev score      (   18): 0.919858\n","  Best dev score (   18): 0.919858\n","2024-03-24 19:11:19 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:11:19 INFO: Starting epoch 19\n","100% 167/167 [03:12<00:00,  1.16s/it, Epoch 19]\n","2024-03-24 19:14:32 INFO: Transitions correct: 169569\n","  Counter({'Open': 58010, 'Close': 57363, 'Shift': 54196})\n","2024-03-24 19:14:32 INFO: Transitions incorrect: 6012\n","  Counter({('Open', 'Open'): 1937, ('Open', 'Close'): 1616, ('Close', 'Open'): 1052, ('Shift', 'Close'): 555, ('Close', 'Shift'): 526, ('Shift', 'Open'): 197, ('Open', 'Shift'): 129})\n","2024-03-24 19:14:32 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1700, <RepairType.WRONG_OPEN_GENERAL: 4>: 1187, <RepairType.OPEN_CLOSE: 7>: 1159, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 642, <RepairType.SHIFT_CLOSE: 8>: 558, <RepairType.MISSED_UNARY: 5>: 348, <RepairType.CLOSE_SHIFT_NESTED: 9>: 200, <RepairType.OPEN_SHIFT: 6>: 106, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 92, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 16})\n","2024-03-24 19:14:32 INFO: Fake transitions used: 43\n","2024-03-24 19:14:32 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:07<00:00, 125.49it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.2 sec].\n","pcfg LP/LR summary evalb: LP: 91.15 LR: 91.38 F1: 91.27 Exact: 57.54 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 91.15 LR: 91.38 F1: 91.27 Exact: 57.54 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:14:41 INFO: Epoch 19 finished\n","  Transitions correct: Counter({'Open': 58010, 'Close': 57363, 'Shift': 54196})\n","  Transitions incorrect: Counter({('Open', 'Open'): 1937, ('Open', 'Close'): 1616, ('Close', 'Open'): 1052, ('Shift', 'Close'): 555, ('Close', 'Shift'): 526, ('Shift', 'Open'): 197, ('Open', 'Shift'): 129})\n","  Total loss for epoch: 19015.39156\n","  Dev score      (   19): 0.912734\n","  Best dev score (   18): 0.919858\n","2024-03-24 19:14:43 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:14:43 INFO: Starting epoch 20\n","100% 167/167 [03:14<00:00,  1.17s/it, Epoch 20]\n","2024-03-24 19:17:57 INFO: Transitions correct: 168488\n","  Counter({'Open': 57680, 'Close': 57016, 'Shift': 53792})\n","2024-03-24 19:17:57 INFO: Transitions incorrect: 5687\n","  Counter({('Open', 'Open'): 1823, ('Open', 'Close'): 1527, ('Close', 'Open'): 957, ('Shift', 'Close'): 553, ('Close', 'Shift'): 509, ('Shift', 'Open'): 165, ('Open', 'Shift'): 153})\n","2024-03-24 19:17:57 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 1552, <RepairType.WRONG_OPEN_GENERAL: 4>: 1102, <RepairType.OPEN_CLOSE: 7>: 1075, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 617, <RepairType.SHIFT_CLOSE: 8>: 559, <RepairType.MISSED_UNARY: 5>: 359, <RepairType.CLOSE_SHIFT_NESTED: 9>: 186, <RepairType.OPEN_SHIFT: 6>: 129, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 87, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 17})\n","2024-03-24 19:17:57 INFO: Fake transitions used: 46\n","2024-03-24 19:17:57 INFO: Processing 994 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 994/994 [00:08<00:00, 115.57it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.3 sec].\n","pcfg LP/LR summary evalb: LP: 90.92 LR: 90.68 F1: 90.8 Exact: 58.55 N: 994\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 90.92 LR: 90.68 F1: 90.8 Exact: 58.55 N: 994\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 994\n","2024-03-24 19:18:08 INFO: Epoch 20 finished\n","  Transitions correct: Counter({'Open': 57680, 'Close': 57016, 'Shift': 53792})\n","  Transitions incorrect: Counter({('Open', 'Open'): 1823, ('Open', 'Close'): 1527, ('Close', 'Open'): 957, ('Shift', 'Close'): 553, ('Close', 'Shift'): 509, ('Shift', 'Open'): 165, ('Open', 'Shift'): 153})\n","  Total loss for epoch: 18150.91966\n","  Dev score      (   20): 0.908017\n","  Best dev score (   18): 0.919858\n","2024-03-24 19:18:09 INFO: Model saved to saved_models/constituency/pt_cintil_charlm_constituency_checkpoint.pt\n","2024-03-24 19:18:09 INFO: Starting epoch 21\n","  4% 7/167 [00:07<02:59,  1.12s/it, Epoch 21]\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py\", line 124, in <module>\n","    main()\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py\", line 121, in main\n","    common.main(run_treebank, \"constituency\", \"constituency\", add_constituency_args, sub_argparse=constituency_parser.build_argparse(), build_model_filename=build_model_filename)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/common.py\", line 183, in main\n","    run_treebank(mode, paths, treebank, short_name,\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py\", line 95, in run_treebank\n","    constituency_parser.main(train_args)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/models/constituency_parser.py\", line 851, in main\n","    trainer.train(args, model_load_file, retag_pipeline)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/models/constituency/trainer.py\", line 707, in train\n","    trainer = iterate_training(args, trainer, train_trees, train_sequences, train_transitions, dev_trees, silver_trees, silver_sequences, foundation_cache, evaluator)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/models/constituency/trainer.py\", line 867, in iterate_training\n","    epoch_stats = train_model_one_epoch(trainer.epochs_trained, trainer, transition_tensors, process_outputs, model_loss_function, epoch_data, oracle, args)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/models/constituency/trainer.py\", line 959, in train_model_one_epoch\n","    batch_stats = train_model_one_batch(epoch, batch_idx, model, batch, transition_tensors, process_outputs, model_loss_function, oracle, args)\n","  File \"/content/gdrive/MyDrive/PLN/2/stanza/stanza/models/constituency/trainer.py\", line 1083, in train_model_one_batch\n","    tree_loss.backward()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency pt_cintil --score_dev"],"metadata":{"id":"0JN-RyYV4LW1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711307930833,"user_tz":-60,"elapsed":24076,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"dde35f28-ddbd-4195-cf2b-f1d9a053f993"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-24 19:18:30 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py pt_cintil --score_dev\n","2024-03-24 19:18:30 INFO: Using default pretrain for language, found in /root/stanza_resources/pt/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-24 19:18:30 INFO: Using model /root/stanza_resources/pt/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-24 19:18:30 INFO: Using model /root/stanza_resources/pt/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-24 19:18:30 INFO: Running dev step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg', '--shorthand', 'pt_cintil', '--mode', 'predict', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/pt/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/pt/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/pt/backward_charlm/oscar2023.pt']\n","2024-03-24 19:18:30 INFO: Expanded save_name: pt_cintil_charlm_constituency.pt\n","2024-03-24 19:18:30 INFO: Running constituency parser in predict mode\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.5MB/s]        \n","2024-03-24 19:18:30 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-24 19:18:30 INFO: Loading these models for language: pt (Portuguese):\n","=============================\n","| Processor | Package       |\n","-----------------------------\n","| tokenize  | bosque        |\n","| pos       | bosque_charlm |\n","=============================\n","\n","2024-03-24 19:18:30 INFO: Using device: cuda\n","2024-03-24 19:18:30 INFO: Loading: tokenize\n","2024-03-24 19:18:30 INFO: Loading: pos\n","2024-03-24 19:18:32 INFO: Done loading processors!\n","2024-03-24 19:18:33 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","2024-03-24 19:18:33 INFO: Read 995 trees for evaluation\n","2024-03-24 19:18:33 INFO: Retagging trees using the upos tags from the default package...\n","100% 995/995 [00:03<00:00, 284.57it/s]\n","2024-03-24 19:18:37 INFO: Retagging finished\n","2024-03-24 19:18:37 INFO: Processing 995 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg\n","100% 995/995 [00:08<00:00, 118.36it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.6 sec].\n","pcfg LP/LR summary evalb: LP: 92.24 LR: 91.73 F1: 91.99 Exact: 62.51 N: 995\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 92.24 LR: 91.73 F1: 91.99 Exact: 62.51 N: 995\n","factor Tag summary evalb: LP: 4.16 LR: 4.16 F1: 4.16 Exact: 0.0 N: 995\n","2024-03-24 19:18:48 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_dev.mrg: 0.919911\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency pt_cintil --score_test"],"metadata":{"id":"GYxpJMaw4Lpk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711307959208,"user_tz":-60,"elapsed":23985,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"06896f93-9e5c-4f87-ccac-e63d6acad620"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-24 19:18:57 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py pt_cintil --score_test\n","2024-03-24 19:18:57 INFO: Using default pretrain for language, found in /root/stanza_resources/pt/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-24 19:18:57 INFO: Using model /root/stanza_resources/pt/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-24 19:18:57 INFO: Using model /root/stanza_resources/pt/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-24 19:18:57 INFO: Running test step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_test.mrg', '--shorthand', 'pt_cintil', '--mode', 'predict', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/pt/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/pt/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/pt/backward_charlm/oscar2023.pt']\n","2024-03-24 19:18:57 INFO: Expanded save_name: pt_cintil_charlm_constituency.pt\n","2024-03-24 19:18:57 INFO: Running constituency parser in predict mode\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 15.9MB/s]        \n","2024-03-24 19:18:57 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-24 19:18:58 INFO: Loading these models for language: pt (Portuguese):\n","=============================\n","| Processor | Package       |\n","-----------------------------\n","| tokenize  | bosque        |\n","| pos       | bosque_charlm |\n","=============================\n","\n","2024-03-24 19:18:58 INFO: Using device: cuda\n","2024-03-24 19:18:58 INFO: Loading: tokenize\n","2024-03-24 19:18:58 INFO: Loading: pos\n","2024-03-24 19:18:59 INFO: Done loading processors!\n","2024-03-24 19:19:00 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_test.mrg\n","2024-03-24 19:19:01 INFO: Read 995 trees for evaluation\n","2024-03-24 19:19:01 INFO: Retagging trees using the upos tags from the default package...\n","100% 995/995 [00:03<00:00, 281.32it/s]\n","2024-03-24 19:19:04 INFO: Retagging finished\n","2024-03-24 19:19:04 INFO: Processing 995 trees from /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_test.mrg\n","100% 995/995 [00:09<00:00, 108.45it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.7 sec].\n","pcfg LP/LR summary evalb: LP: 90.31 LR: 90.11 F1: 90.21 Exact: 55.77 N: 995\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 90.31 LR: 90.11 F1: 90.21 Exact: 55.77 N: 995\n","factor Tag summary evalb: LP: 4.07 LR: 4.07 F1: 4.07 Exact: 0.0 N: 995\n","2024-03-24 19:19:16 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/pt_cintil_test.mrg: 0.902165\n"]}]},{"cell_type":"markdown","source":["## 2.b. OTROS PARSERS Y/O IDIOMAS (OPTATIVO, HASTA 3 PUNTOS)\n","\n","Al igual que con el Apartado 1.b, se trataría de ampliar nuestro estudio a más parsers y, sobre todo, más idiomas. Otra vez se valorarán especialmente (de menos a más): lenguas no latinas, lenguas no indo-europeas y lenguas con alfabeto diferente al latino. De nuevo se tendrá en cuenta positivamente la variedad tanto del conjunto de idiomas como la variedad del tipo de parsers empleados.\n"],"metadata":{"id":"V6RuitqlCdOq"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","from google.colab import drive"],"metadata":{"id":"_qjOHGq_hFI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wN7xkxPyhIh1","executionInfo":{"status":"ok","timestamp":1712595787160,"user_tz":-120,"elapsed":23698,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"363bb00f-6053-4991-c019-89d3135f3c96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["!pip install stanza"],"metadata":{"id":"3ZfaIctfhKoP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### JA"],"metadata":{"id":"ZcraIbcu4iup"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.constituency.prepare_con_dataset ja_alt"],"metadata":{"id":"A1o3jcYw4iur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711365225030,"user_tz":-60,"elapsed":58458,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"33297bf5-829c-435d-c005-4564a5cf6325"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Eliminated 9 trees for having wide spaces in it\n","Eliminated 19 trees for not being correctly encoded\n","Writing 17195 trees to /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_train.mrg\n","Writing 934 trees to /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","Writing 931 trees to /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_test.mrg\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency ja_alt --epochs 20"],"metadata":{"id":"DuO6zNwY4iur","colab":{"base_uri":"https://localhost:8080/"},"outputId":"013ec4d3-cc25-43d8-d9ff-9c916caa64d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-27 10:52:54 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py ja_alt --epochs 20\n","2024-03-27 10:52:54 INFO: Default pretrain should be /root/stanza_resources/ja/pretrain/conll17.pt  Attempting to download\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 17.9MB/s]        \n","2024-03-27 10:52:54 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:52:54 INFO: Downloading these customized packages for language: ja (Japanese)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 107M/107M [00:01<00:00, 106MB/s] \n","2024-03-27 10:52:56 INFO: Downloaded file to /root/stanza_resources/ja/pretrain/conll17.pt\n","2024-03-27 10:52:56 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:52:56 INFO: Using default pretrain for language, found in /root/stanza_resources/ja/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.0MB/s]        \n","2024-03-27 10:52:56 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:52:56 INFO: Downloading these customized packages for language: ja (Japanese)...\n","============================\n","| Processor      | Package |\n","----------------------------\n","| forward_charlm | conll17 |\n","============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/forward_charlm/conll17.pt: 100% 42.6M/42.6M [00:00<00:00, 62.3MB/s]\n","2024-03-27 10:52:58 INFO: Downloaded file to /root/stanza_resources/ja/forward_charlm/conll17.pt\n","2024-03-27 10:52:58 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:52:58 INFO: Downloaded model, using model /root/stanza_resources/ja/forward_charlm/conll17.pt for forward charlm\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.6MB/s]        \n","2024-03-27 10:52:58 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:52:58 INFO: Downloading these customized packages for language: ja (Japanese)...\n","=============================\n","| Processor       | Package |\n","-----------------------------\n","| backward_charlm | conll17 |\n","=============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/backward_charlm/conll17.pt: 100% 42.6M/42.6M [00:00<00:00, 129MB/s]\n","2024-03-27 10:52:59 INFO: Downloaded file to /root/stanza_resources/ja/backward_charlm/conll17.pt\n","2024-03-27 10:52:59 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-27 10:52:59 INFO: Downloaded model, using model /root/stanza_resources/ja/backward_charlm/conll17.pt for backward charlm\n","2024-03-27 10:52:59 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-27 10:52:59 INFO: Expanded save_name: ja_alt_charlm_constituency.pt\n","2024-03-27 10:52:59 INFO: Expanded save_name: saved_models/constituency/ja_alt_charlm_constituency.pt\n","2024-03-27 10:52:59 INFO: ja_alt: saved_models/constituency/ja_alt_charlm_constituency.pt does not exist, training new model\n","2024-03-27 10:52:59 INFO: Using default pretrain for language, found in /root/stanza_resources/ja/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-27 10:52:59 INFO: Using model /root/stanza_resources/ja/forward_charlm/conll17.pt for forward charlm\n","2024-03-27 10:52:59 INFO: Using model /root/stanza_resources/ja/backward_charlm/conll17.pt for backward charlm\n","2024-03-27 10:52:59 INFO: Running train step with args: ['--train_file', '/content/gdrive/MyDrive/PLN/2/constituency/ja_alt_train.mrg', '--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg', '--shorthand', 'ja_alt', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/ja/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/ja/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/ja/backward_charlm/conll17.pt', '--epochs', '20']\n","2024-03-27 10:52:59 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-27 10:52:59 INFO: Expanded save_name: ja_alt_charlm_constituency.pt\n","2024-03-27 10:52:59 INFO: Running constituency parser in train mode\n","2024-03-27 10:52:59 DEBUG: Set trainer logging level to DEBUG\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 13.9MB/s]        \n","2024-03-27 10:52:59 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-27 10:52:59 DEBUG: Creating retag pipeline for default package\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/tokenize/gsd.pt: 100% 1.49M/1.49M [00:00<00:00, 22.4MB/s]\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/pos/gsd_charlm.pt: 100% 32.7M/32.7M [00:00<00:00, 50.4MB/s]\n","2024-03-27 10:53:01 INFO: Loading these models for language: ja (Japanese):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-27 10:53:01 INFO: Using device: cuda\n","2024-03-27 10:53:01 INFO: Loading: tokenize\n","2024-03-27 10:53:01 INFO: Loading: pos\n","2024-03-27 10:53:03 INFO: Done loading processors!\n","2024-03-27 10:53:03 WARNING: XPOS for the default tagger is empty.  Switching to UPOS\n","2024-03-27 10:53:03 INFO: ARGS USED AT TRAINING TIME:\n","additional_oracle_levels: None\n","bert_finetune: False\n","bert_finetune_begin_epoch: None\n","bert_finetune_end_epoch: None\n","bert_finetune_layers: None\n","bert_hidden_layers: 4\n","bert_learning_rate: 0.009\n","bert_model: None\n","bert_weight_decay: 0.0001\n","charlm_backward_file: /root/stanza_resources/ja/backward_charlm/conll17.pt\n","charlm_forward_file: /root/stanza_resources/ja/forward_charlm/conll17.pt\n","check_valid_states: True\n","checkpoint: True\n","checkpoint_save_name: saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","combined_dummy_embedding: True\n","constituency_composition: ConstituencyComposition.MAX\n","constituent_heads: 8\n","constituent_stack: StackHistory.LSTM\n","data_dir: data/constituency\n","delta_embedding_dim: 100\n","device: cuda\n","epoch_size: 5000\n","epochs: 20\n","eval_batch_size: 50\n","eval_file: /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","finetune: False\n","grad_clipping: None\n","hidden_size: 512\n","lang: ja\n","lattn_attention_dropout: 0.2\n","lattn_combine_as_self: False\n","lattn_combined_input: True\n","lattn_d_ff: 2048\n","lattn_d_input_proj: None\n","lattn_d_kv: 64\n","lattn_d_l: 32\n","lattn_d_proj: 64\n","lattn_partitioned: True\n","lattn_pwff: True\n","lattn_q_as_matrix: False\n","lattn_relu_dropout: 0.2\n","lattn_resdrop: True\n","lattn_residual_dropout: 0.2\n","learning_beta2: 0.999\n","learning_eps: 1e-08\n","learning_momentum: None\n","learning_rate: 0.0002\n","learning_rate_cooldown: 10\n","learning_rate_factor: 0.6\n","learning_rate_min_lr: 4.000000000000001e-06\n","learning_rate_patience: 5\n","learning_rate_warmup: 0\n","learning_rho: 0.9\n","learning_weight_decay: 0.05\n","load_name: None\n","load_package: None\n","log_norms: False\n","log_shapes: False\n","lora_alpha: 128\n","lora_dropout: 0.1\n","lora_modules_to_save: []\n","lora_rank: 64\n","lora_target_modules: ['query', 'value', 'output.dense', 'intermediate.dense']\n","loss: cross\n","loss_focal_gamma: 2\n","lstm_input_dropout: 0.2\n","lstm_layer_dropout: 0.0\n","maxout_k: None\n","mode: train\n","multistage: True\n","nonlinearity: relu\n","num_generate: 0\n","num_lstm_layers: 2\n","num_output_layers: 3\n","num_tree_lstm_layers: 1\n","optim: adamw\n","oracle_forced_errors: 0.001\n","oracle_frequency: 0.8\n","oracle_initial_epoch: 1\n","oracle_level: None\n","pattn_attention_dropout: 0.2\n","pattn_bias: False\n","pattn_d_ff: 2048\n","pattn_d_kv: 64\n","pattn_d_model: 1024\n","pattn_encoder_max_len: 512\n","pattn_morpho_emb_dropout: 0.2\n","pattn_num_heads: 8\n","pattn_num_layers: 0\n","pattn_relu_dropout: 0.1\n","pattn_residual_dropout: 0.2\n","pattn_timing: sin\n","predict_dir: .\n","predict_dropout: 0.2\n","predict_file: None\n","predict_format: {:_O}\n","pretrain_max_vocab: 250000\n","rare_word_threshold: 0.02\n","rare_word_unknown_frequency: 0.02\n","reduce_heads: 8\n","reduce_position: 128\n","relearn_structure: False\n","retag_charlm_backward_file: None\n","retag_charlm_forward_file: None\n","retag_method: upos\n","retag_model_path: None\n","retag_package: default\n","retag_pretrain_path: None\n","retag_xpos: False\n","reversed: False\n","save_dir: saved_models/constituency\n","save_each_frequency: 1\n","save_each_name: saved_models/constituency/ja_alt_charlm_constituency_%04d.pt\n","save_each_optimizer: True\n","save_each_start: None\n","save_name: saved_models/constituency/ja_alt_charlm_constituency.pt\n","seed: 1234\n","sentence_boundary_vectors: SentenceBoundary.EVERYTHING\n","shorthand: ja_alt\n","silver_epoch_size: None\n","silver_file: None\n","silver_remove_duplicates: False\n","stage1_bert_finetune: False\n","stage1_bert_learning_rate: 0.009\n","stage1_learning_rate: 1.0\n","stage1_learning_rate_min_lr: 0.02\n","tag_embedding_dim: 20\n","tag_unknown_frequency: 0.001\n","tokenized_dir: None\n","tokenized_file: None\n","train_batch_size: 30\n","train_file: /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_train.mrg\n","transition_embedding_dim: 20\n","transition_heads: 4\n","transition_hidden_size: 20\n","transition_scheme: TransitionScheme.IN_ORDER\n","transition_stack: StackHistory.LSTM\n","use_lattn: False\n","use_peft: False\n","use_silver_words: True\n","wandb: False\n","wandb_name: None\n","wandb_norm_regex: None\n","watch_regex: None\n","word_dropout: 0.2\n","wordvec_dir: extern_data/wordvec\n","wordvec_file: \n","wordvec_pretrain_file: /root/stanza_resources/ja/pretrain/conll17.pt\n","\n","2024-03-27 10:53:03 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_train.mrg\n","100% 17195/17195 [00:10<00:00, 1620.79it/s]\n","2024-03-27 10:53:24 INFO: Read 17195 trees for the training set\n","2024-03-27 10:53:27 INFO: Filtered 3 duplicates from train dataset\n","2024-03-27 10:53:27 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","2024-03-27 10:53:28 INFO: Read 934 trees for the dev set\n","2024-03-27 10:53:28 INFO: Retagging trees using the upos tags from the default package...\n","100% 17192/17192 [02:09<00:00, 132.90it/s]\n","100% 934/934 [00:06<00:00, 147.94it/s]\n","2024-03-27 10:55:44 INFO: Retagging finished\n","2024-03-27 10:55:45 INFO: Unique constituents in training set: ['ADJP', 'ADVP', 'BASENP', 'CONJP', 'FRAG', 'INP', 'INPH', 'INTJ', 'JJV', 'LST', 'MDP', 'NN', 'NNP', 'NP', 'PP', 'PRN', 'QP', 'QT', 'QTC', 'QTL', 'QTR', 'ROOT', 'S', 'SBAR', 'SBARQ', 'SINV', 'SQ', 'UCP', 'VB', 'VP']\n","2024-03-27 10:55:48 INFO: Constituent node counts: Counter({'VP': 174422, 'PP': 125169, 'BASENP': 104301, 'S': 90996, 'NP': 65968, 'SBAR': 17574, 'ROOT': 17192, 'ADJP': 8507, 'ADVP': 6408, 'QT': 4653, 'MDP': 2282, 'PRN': 2223, 'INP': 1483, 'CONJP': 1058, 'QP': 1012, 'QTC': 866, 'UCP': 408, 'QTR': 168, 'QTL': 167, 'FRAG': 123, 'SBARQ': 113, 'SQ': 63, 'INTJ': 42, 'LST': 27, 'INPH': 13, 'NN': 3, 'JJV': 1, 'SINV': 1, 'NNP': 1, 'VB': 1})\n","2024-03-27 10:55:49 INFO: Unique tags in training set: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB']\n","2024-03-27 10:55:51 INFO: Unary limit: 4\n","2024-03-27 10:55:51 INFO: Building training transition sequences\n","100% 17192/17192 [00:05<00:00, 3093.53it/s]\n","2024-03-27 10:55:57 INFO: Building dev transition sequences\n","100% 934/934 [00:00<00:00, 7279.19it/s]\n","2024-03-27 10:55:57 INFO: Total unique transitions in train set: 32\n","2024-03-27 10:55:57 INFO: Unique transitions in training set: [Shift, CloseConstituent, OpenConstituent(('ADJP',)), OpenConstituent(('ADVP',)), OpenConstituent(('BASENP',)), OpenConstituent(('CONJP',)), OpenConstituent(('FRAG',)), OpenConstituent(('INP',)), OpenConstituent(('INPH',)), OpenConstituent(('INTJ',)), OpenConstituent(('JJV',)), OpenConstituent(('LST',)), OpenConstituent(('MDP',)), OpenConstituent(('NN',)), OpenConstituent(('NNP',)), OpenConstituent(('NP',)), OpenConstituent(('PP',)), OpenConstituent(('PRN',)), OpenConstituent(('QP',)), OpenConstituent(('QT',)), OpenConstituent(('QTC',)), OpenConstituent(('QTL',)), OpenConstituent(('QTR',)), OpenConstituent(('ROOT',)), OpenConstituent(('S',)), OpenConstituent(('SBAR',)), OpenConstituent(('SBARQ',)), OpenConstituent(('SINV',)), OpenConstituent(('SQ',)), OpenConstituent(('UCP',)), OpenConstituent(('VB',)), OpenConstituent(('VP',))]\n","2024-03-27 10:55:57 INFO: Root labels in treebank: ['ROOT']\n","2024-03-27 10:55:57 INFO: Verifying the transition sequences for 17192 trees\n","100% 17192/17192 [00:29<00:00, 576.89it/s]\n","2024-03-27 10:56:27 INFO: Verifying the transition sequences for 934 trees\n","100% 934/934 [00:01<00:00, 563.21it/s]\n","2024-03-27 10:56:34 INFO: Using the following open nodes:\n","  ('ADJP',)\n","  ('ADVP',)\n","  ('BASENP',)\n","  ('CONJP',)\n","  ('FRAG',)\n","  ('INP',)\n","  ('INPH',)\n","  ('INTJ',)\n","  ('JJV',)\n","  ('LST',)\n","  ('MDP',)\n","  ('NN',)\n","  ('NNP',)\n","  ('NP',)\n","  ('PP',)\n","  ('PRN',)\n","  ('QP',)\n","  ('QT',)\n","  ('QTC',)\n","  ('QTL',)\n","  ('QTR',)\n","  ('ROOT',)\n","  ('S',)\n","  ('SBAR',)\n","  ('SBARQ',)\n","  ('SINV',)\n","  ('SQ',)\n","  ('UCP',)\n","  ('VB',)\n","  ('VP',)\n","2024-03-27 10:56:34 INFO: Warming up model for 10 iterations using AdaDelta to train the embeddings\n","2024-03-27 10:56:34 DEBUG: Building Adadelta with lr=1.000000, weight_decay=0.02\n","2024-03-27 10:56:34 INFO: Number of words in the training set found in the embedding: 18099 out of 27435\n","2024-03-27 10:56:34 INFO: Building CrossEntropyLoss(sum)\n","2024-03-27 10:56:38 INFO: Starting epoch 1\n","100% 167/167 [09:44<00:00,  3.50s/it, Epoch 1]\n","2024-03-27 11:06:22 INFO: Transitions correct: 354698\n","  Counter({'Shift': 149757, 'Close': 103255, 'Open': 101686})\n","2024-03-27 11:06:22 INFO: Transitions incorrect: 196475\n","  Counter({('Open', 'Close'): 44975, ('Open', 'Open'): 41794, ('Shift', 'Close'): 33680, ('Close', 'Shift'): 26798, ('Close', 'Open'): 23429, ('Open', 'Shift'): 18121, ('Shift', 'Open'): 7678})\n","2024-03-27 11:06:22 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 86872, <RepairType.SHIFT_CLOSE: 8>: 33486, <RepairType.WRONG_OPEN_GENERAL: 4>: 30695, <RepairType.OPEN_CLOSE: 7>: 9286, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 8987, <RepairType.MISSED_UNARY: 5>: 5567, <RepairType.OPEN_SHIFT: 6>: 4795, <RepairType.CLOSE_SHIFT_NESTED: 9>: 1623, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 1002, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 778})\n","2024-03-27 11:06:22 INFO: Fake transitions used: 85\n","2024-03-27 11:06:22 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:18<00:00, 49.28it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [2.4 sec].\n","pcfg LP/LR summary evalb: LP: 75.73 LR: 73.77 F1: 74.74 Exact: 4.38 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 75.73 LR: 73.77 F1: 74.74 Exact: 4.38 N: 934\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 934\n","2024-03-27 11:06:47 INFO: New best dev score: 0.74743 > 0.00000\n","2024-03-27 11:06:48 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency.pt\n","2024-03-27 11:06:48 INFO: Epoch 1 finished\n","  Transitions correct: Counter({'Shift': 149757, 'Close': 103255, 'Open': 101686})\n","  Transitions incorrect: Counter({('Open', 'Close'): 44975, ('Open', 'Open'): 41794, ('Shift', 'Close'): 33680, ('Close', 'Shift'): 26798, ('Close', 'Open'): 23429, ('Open', 'Shift'): 18121, ('Shift', 'Open'): 7678})\n","  Total loss for epoch: 841047.78732\n","  Dev score      (    1): 0.747429\n","  Best dev score (    1): 0.747429\n","2024-03-27 11:06:49 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","2024-03-27 11:06:49 INFO: Starting epoch 2\n","100% 167/167 [09:21<00:00,  3.36s/it, Epoch 2]\n","2024-03-27 11:16:11 INFO: Transitions correct: 483897\n","  Counter({'Shift': 166415, 'Close': 160487, 'Open': 156995})\n","2024-03-27 11:16:11 INFO: Transitions incorrect: 45834\n","  Counter({('Open', 'Open'): 15141, ('Open', 'Close'): 11889, ('Close', 'Open'): 7239, ('Shift', 'Close'): 5154, ('Close', 'Shift'): 4118, ('Shift', 'Open'): 1176, ('Open', 'Shift'): 1117})\n","2024-03-27 11:16:11 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 18654, <RepairType.WRONG_OPEN_GENERAL: 4>: 11596, <RepairType.SHIFT_CLOSE: 8>: 5177, <RepairType.OPEN_CLOSE: 7>: 3041, <RepairType.MISSED_UNARY: 5>: 2467, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1737, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 1549, <RepairType.OPEN_SHIFT: 6>: 607, <RepairType.CLOSE_SHIFT_NESTED: 9>: 197, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 165})\n","2024-03-27 11:16:11 INFO: Fake transitions used: 175\n","2024-03-27 11:16:11 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:19<00:00, 47.66it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [1.0 sec].\n","pcfg LP/LR summary evalb: LP: 82.4 LR: 80.62 F1: 81.5 Exact: 8.77 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.4 LR: 80.62 F1: 81.5 Exact: 8.77 N: 934\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 934\n","2024-03-27 11:16:34 INFO: New best dev score: 0.81501 > 0.74743\n","2024-03-27 11:16:34 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency.pt\n","2024-03-27 11:16:34 INFO: Epoch 2 finished\n","  Transitions correct: Counter({'Shift': 166415, 'Close': 160487, 'Open': 156995})\n","  Transitions incorrect: Counter({('Open', 'Open'): 15141, ('Open', 'Close'): 11889, ('Close', 'Open'): 7239, ('Shift', 'Close'): 5154, ('Close', 'Shift'): 4118, ('Shift', 'Open'): 1176, ('Open', 'Shift'): 1117})\n","  Total loss for epoch: 149904.06607\n","  Dev score      (    2): 0.815007\n","  Best dev score (    2): 0.815007\n","2024-03-27 11:16:38 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","2024-03-27 11:16:38 INFO: Starting epoch 3\n","100% 167/167 [09:23<00:00,  3.37s/it, Epoch 3]\n","2024-03-27 11:26:01 INFO: Transitions correct: 497532\n","  Counter({'Shift': 167058, 'Close': 166519, 'Open': 163955})\n","2024-03-27 11:26:01 INFO: Transitions incorrect: 32625\n","  Counter({('Open', 'Open'): 10718, ('Open', 'Close'): 8788, ('Close', 'Open'): 5702, ('Shift', 'Close'): 3145, ('Close', 'Shift'): 2761, ('Shift', 'Open'): 818, ('Open', 'Shift'): 693})\n","2024-03-27 11:26:01 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 13776, <RepairType.WRONG_OPEN_GENERAL: 4>: 8299, <RepairType.SHIFT_CLOSE: 8>: 3159, <RepairType.MISSED_UNARY: 5>: 2104, <RepairType.OPEN_CLOSE: 7>: 1947, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1251, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 1029, <RepairType.OPEN_SHIFT: 6>: 332, <RepairType.CLOSE_SHIFT_NESTED: 9>: 166, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 72})\n","2024-03-27 11:26:01 INFO: Fake transitions used: 162\n","2024-03-27 11:26:01 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:19<00:00, 47.44it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.8 sec].\n","pcfg LP/LR summary evalb: LP: 86.8 LR: 85.05 F1: 85.92 Exact: 16.05 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 86.8 LR: 85.05 F1: 85.92 Exact: 16.05 N: 934\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 934\n","2024-03-27 11:26:24 INFO: New best dev score: 0.85922 > 0.81501\n","2024-03-27 11:26:24 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency.pt\n","2024-03-27 11:26:24 INFO: Epoch 3 finished\n","  Transitions correct: Counter({'Shift': 167058, 'Close': 166519, 'Open': 163955})\n","  Transitions incorrect: Counter({('Open', 'Open'): 10718, ('Open', 'Close'): 8788, ('Close', 'Open'): 5702, ('Shift', 'Close'): 3145, ('Close', 'Shift'): 2761, ('Shift', 'Open'): 818, ('Open', 'Shift'): 693})\n","  Total loss for epoch: 107621.64493\n","  Dev score      (    3): 0.859222\n","  Best dev score (    3): 0.859222\n","2024-03-27 11:26:25 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","2024-03-27 11:26:25 INFO: Starting epoch 4\n","100% 167/167 [09:13<00:00,  3.31s/it, Epoch 4]\n","2024-03-27 11:35:39 INFO: Transitions correct: 500036\n","  Counter({'Close': 167792, 'Shift': 166569, 'Open': 165675})\n","2024-03-27 11:35:39 INFO: Transitions incorrect: 25262\n","  Counter({('Open', 'Open'): 8456, ('Open', 'Close'): 7231, ('Close', 'Open'): 4985, ('Shift', 'Close'): 1899, ('Close', 'Shift'): 1797, ('Shift', 'Open'): 481, ('Open', 'Shift'): 413})\n","2024-03-27 11:35:39 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 10951, <RepairType.WRONG_OPEN_GENERAL: 4>: 6690, <RepairType.SHIFT_CLOSE: 8>: 1917, <RepairType.MISSED_UNARY: 5>: 1885, <RepairType.OPEN_CLOSE: 7>: 1703, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1050, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 706, <RepairType.OPEN_SHIFT: 6>: 148, <RepairType.CLOSE_SHIFT_NESTED: 9>: 145})\n","2024-03-27 11:35:39 INFO: Fake transitions used: 140\n","2024-03-27 11:35:39 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:18<00:00, 49.59it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.6 sec].\n","pcfg LP/LR summary evalb: LP: 86.27 LR: 85.07 F1: 85.67 Exact: 15.95 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 86.27 LR: 85.07 F1: 85.67 Exact: 15.95 N: 934\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 934\n","2024-03-27 11:36:01 INFO: Epoch 4 finished\n","  Transitions correct: Counter({'Close': 167792, 'Shift': 166569, 'Open': 165675})\n","  Transitions incorrect: Counter({('Open', 'Open'): 8456, ('Open', 'Close'): 7231, ('Close', 'Open'): 4985, ('Shift', 'Close'): 1899, ('Close', 'Shift'): 1797, ('Shift', 'Open'): 481, ('Open', 'Shift'): 413})\n","  Total loss for epoch: 85337.92059\n","  Dev score      (    4): 0.856726\n","  Best dev score (    3): 0.859222\n","2024-03-27 11:36:02 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","2024-03-27 11:36:02 INFO: Starting epoch 5\n","100% 167/167 [09:04<00:00,  3.26s/it, Epoch 5]\n","2024-03-27 11:45:07 INFO: Transitions correct: 505653\n","  Counter({'Close': 170150, 'Open': 167838, 'Shift': 167665})\n","2024-03-27 11:45:07 INFO: Transitions incorrect: 21929\n","  Counter({('Open', 'Open'): 7418, ('Open', 'Close'): 6414, ('Close', 'Open'): 4317, ('Shift', 'Close'): 1572, ('Close', 'Shift'): 1305, ('Shift', 'Open'): 493, ('Open', 'Shift'): 410})\n","2024-03-27 11:45:07 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 9505, <RepairType.WRONG_OPEN_GENERAL: 4>: 5770, <RepairType.MISSED_UNARY: 5>: 1738, <RepairType.SHIFT_CLOSE: 8>: 1581, <RepairType.OPEN_CLOSE: 7>: 1410, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 994, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 650, <RepairType.OPEN_SHIFT: 6>: 148, <RepairType.CLOSE_SHIFT_NESTED: 9>: 115, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 1})\n","2024-03-27 11:45:07 INFO: Fake transitions used: 160\n","2024-03-27 11:45:07 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:22<00:00, 42.18it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.7 sec].\n","pcfg LP/LR summary evalb: LP: 87.57 LR: 85.65 F1: 86.6 Exact: 19.37 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 87.57 LR: 85.65 F1: 86.6 Exact: 19.37 N: 934\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 934\n","2024-03-27 11:45:32 INFO: New best dev score: 0.86602 > 0.85922\n","2024-03-27 11:45:33 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency.pt\n","2024-03-27 11:45:33 INFO: Epoch 5 finished\n","  Transitions correct: Counter({'Close': 170150, 'Open': 167838, 'Shift': 167665})\n","  Transitions incorrect: Counter({('Open', 'Open'): 7418, ('Open', 'Close'): 6414, ('Close', 'Open'): 4317, ('Shift', 'Close'): 1572, ('Close', 'Shift'): 1305, ('Shift', 'Open'): 493, ('Open', 'Shift'): 410})\n","  Total loss for epoch: 72802.51090\n","  Dev score      (    5): 0.866017\n","  Best dev score (    5): 0.866017\n","2024-03-27 11:45:34 INFO: Model saved to saved_models/constituency/ja_alt_charlm_constituency_checkpoint.pt\n","2024-03-27 11:45:34 INFO: Starting epoch 6\n","  7% 12/167 [00:42<08:55,  3.46s/it, Epoch 6]"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency ja_alt --score_dev"],"metadata":{"id":"xu6lBDfw4iur","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711636022773,"user_tz":-60,"elapsed":100211,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"97960c8b-c54f-41cd-fe2c-a0745d240fd0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-28 14:26:15 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py ja_alt --score_dev\n","2024-03-28 14:26:15 INFO: Default pretrain should be /root/stanza_resources/ja/pretrain/conll17.pt  Attempting to download\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.0MB/s]        \n","2024-03-28 14:26:15 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:26:15 INFO: Downloading these customized packages for language: ja (Japanese)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 107M/107M [00:00<00:00, 211MB/s]\n","2024-03-28 14:26:16 INFO: Downloaded file to /root/stanza_resources/ja/pretrain/conll17.pt\n","2024-03-28 14:26:16 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:26:16 INFO: Using default pretrain for language, found in /root/stanza_resources/ja/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.1MB/s]        \n","2024-03-28 14:26:16 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:26:16 INFO: Downloading these customized packages for language: ja (Japanese)...\n","============================\n","| Processor      | Package |\n","----------------------------\n","| forward_charlm | conll17 |\n","============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/forward_charlm/conll17.pt: 100% 42.6M/42.6M [00:00<00:00, 155MB/s]\n","2024-03-28 14:26:17 INFO: Downloaded file to /root/stanza_resources/ja/forward_charlm/conll17.pt\n","2024-03-28 14:26:17 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:26:17 INFO: Downloaded model, using model /root/stanza_resources/ja/forward_charlm/conll17.pt for forward charlm\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.4MB/s]        \n","2024-03-28 14:26:17 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:26:17 INFO: Downloading these customized packages for language: ja (Japanese)...\n","=============================\n","| Processor       | Package |\n","-----------------------------\n","| backward_charlm | conll17 |\n","=============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/backward_charlm/conll17.pt: 100% 42.6M/42.6M [00:00<00:00, 113MB/s]\n","2024-03-28 14:26:18 INFO: Downloaded file to /root/stanza_resources/ja/backward_charlm/conll17.pt\n","2024-03-28 14:26:18 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:26:18 INFO: Downloaded model, using model /root/stanza_resources/ja/backward_charlm/conll17.pt for backward charlm\n","2024-03-28 14:26:18 INFO: Running dev step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg', '--shorthand', 'ja_alt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/ja/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/ja/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/ja/backward_charlm/conll17.pt']\n","2024-03-28 14:26:18 INFO: Expanded save_name: ja_alt_charlm_constituency.pt\n","2024-03-28 14:26:19 INFO: Running constituency parser in predict mode\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.8MB/s]        \n","2024-03-28 14:26:19 INFO: Downloaded file to /root/stanza_resources/resources.json\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/tokenize/gsd.pt: 100% 1.49M/1.49M [00:00<00:00, 25.4MB/s]\n","Downloading https://huggingface.co/stanfordnlp/stanza-ja/resolve/v1.8.0/models/pos/gsd_charlm.pt: 100% 32.7M/32.7M [00:00<00:00, 94.5MB/s]\n","2024-03-28 14:26:21 INFO: Loading these models for language: ja (Japanese):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-28 14:26:21 INFO: Using device: cuda\n","2024-03-28 14:26:21 INFO: Loading: tokenize\n","2024-03-28 14:26:21 INFO: Loading: pos\n","2024-03-28 14:26:23 INFO: Done loading processors!\n","2024-03-28 14:26:23 WARNING: XPOS for the default tagger is empty.  Switching to UPOS\n","2024-03-28 14:26:26 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","2024-03-28 14:26:27 INFO: Read 934 trees for evaluation\n","2024-03-28 14:26:27 INFO: Retagging trees using the upos tags from the default package...\n","100% 934/934 [00:07<00:00, 126.68it/s]\n","2024-03-28 14:26:34 INFO: Retagging finished\n","2024-03-28 14:26:34 INFO: Processing 934 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg\n","100% 934/934 [00:18<00:00, 49.41it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [2.1 sec].\n","pcfg LP/LR summary evalb: LP: 87.57 LR: 85.65 F1: 86.6 Exact: 19.37 N: 934\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 87.57 LR: 85.65 F1: 86.6 Exact: 19.37 N: 934\n","factor Tag summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 934\n","2024-03-28 14:27:00 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_dev.mrg: 0.866017\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency ja_alt --score_test"],"metadata":{"id":"S1eJQxUR4ius","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711636068730,"user_tz":-60,"elapsed":45961,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"40b2daf6-2f37-482e-eff4-4eeace2f2417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-28 14:27:04 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py ja_alt --score_test\n","2024-03-28 14:27:04 INFO: Using default pretrain for language, found in /root/stanza_resources/ja/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-28 14:27:04 INFO: Using model /root/stanza_resources/ja/forward_charlm/conll17.pt for forward charlm\n","2024-03-28 14:27:04 INFO: Using model /root/stanza_resources/ja/backward_charlm/conll17.pt for backward charlm\n","2024-03-28 14:27:04 INFO: Running test step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/ja_alt_test.mrg', '--shorthand', 'ja_alt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/ja/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/ja/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/ja/backward_charlm/conll17.pt']\n","2024-03-28 14:27:04 INFO: Expanded save_name: ja_alt_charlm_constituency.pt\n","2024-03-28 14:27:04 INFO: Running constituency parser in predict mode\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 18.2MB/s]        \n","2024-03-28 14:27:05 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:27:05 INFO: Loading these models for language: ja (Japanese):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-28 14:27:05 INFO: Using device: cuda\n","2024-03-28 14:27:05 INFO: Loading: tokenize\n","2024-03-28 14:27:05 INFO: Loading: pos\n","2024-03-28 14:27:08 INFO: Done loading processors!\n","2024-03-28 14:27:08 WARNING: XPOS for the default tagger is empty.  Switching to UPOS\n","2024-03-28 14:27:10 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_test.mrg\n","2024-03-28 14:27:14 INFO: Read 931 trees for evaluation\n","2024-03-28 14:27:14 INFO: Retagging trees using the upos tags from the default package...\n","100% 931/931 [00:08<00:00, 113.12it/s]\n","2024-03-28 14:27:22 INFO: Retagging finished\n","2024-03-28 14:27:22 INFO: Processing 931 trees from /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_test.mrg\n","100% 931/931 [00:19<00:00, 48.28it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [1.4 sec].\n","pcfg LP/LR summary evalb: LP: 87.29 LR: 85.03 F1: 86.15 Exact: 17.61 N: 931\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 87.29 LR: 85.03 F1: 86.15 Exact: 17.61 N: 931\n","factor Tag summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 931\n","2024-03-28 14:27:46 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/ja_alt_test.mrg: 0.861515\n"]}]},{"cell_type":"markdown","source":["### ID"],"metadata":{"id":"UNcUWTAh6g9e"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.constituency.prepare_con_dataset id_icon"],"metadata":{"id":"0JEAET8f6g9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711365279500,"user_tz":-60,"elapsed":14150,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a1217842-9c52-43c6-a7df-8bdb9e7039c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["100% 8000/8000 [00:03<00:00, 2118.25it/s]\n","Writing 8000 trees to /content/gdrive/MyDrive/PLN/2/constituency/id_icon_train.mrg\n","Writing 1000 trees to /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","Writing 1000 trees to /content/gdrive/MyDrive/PLN/2/constituency/id_icon_test.mrg\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency id_icon --epochs 20"],"metadata":{"id":"KIlRLsb16g9i","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ea00c70-7275-4003-f782-177e2a53fc16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-28 14:28:22 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py id_icon --epochs 20\n","2024-03-28 14:28:22 INFO: Default pretrain should be /root/stanza_resources/id/pretrain/conll17.pt  Attempting to download\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.5MB/s]        \n","2024-03-28 14:28:22 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:28:22 INFO: Downloading these customized packages for language: id (Indonesian)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 107M/107M [00:01<00:00, 68.4MB/s]\n","2024-03-28 14:28:24 INFO: Downloaded file to /root/stanza_resources/id/pretrain/conll17.pt\n","2024-03-28 14:28:24 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:28:24 INFO: Using default pretrain for language, found in /root/stanza_resources/id/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 19.0MB/s]        \n","2024-03-28 14:28:24 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:28:24 INFO: Downloading these customized packages for language: id (Indonesian)...\n","==============================\n","| Processor      | Package   |\n","------------------------------\n","| forward_charlm | oscar2023 |\n","==============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/forward_charlm/oscar2023.pt: 100% 22.3M/22.3M [00:00<00:00, 26.1MB/s]\n","2024-03-28 14:28:26 INFO: Downloaded file to /root/stanza_resources/id/forward_charlm/oscar2023.pt\n","2024-03-28 14:28:26 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:28:26 INFO: Downloaded model, using model /root/stanza_resources/id/forward_charlm/oscar2023.pt for forward charlm\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 13.5MB/s]        \n","2024-03-28 14:28:26 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:28:26 INFO: Downloading these customized packages for language: id (Indonesian)...\n","===============================\n","| Processor       | Package   |\n","-------------------------------\n","| backward_charlm | oscar2023 |\n","===============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/backward_charlm/oscar2023.pt: 100% 22.3M/22.3M [00:00<00:00, 48.9MB/s]\n","2024-03-28 14:28:27 INFO: Downloaded file to /root/stanza_resources/id/backward_charlm/oscar2023.pt\n","2024-03-28 14:28:27 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 14:28:27 INFO: Downloaded model, using model /root/stanza_resources/id/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-28 14:28:27 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-28 14:28:27 INFO: Expanded save_name: id_icon_charlm_constituency.pt\n","2024-03-28 14:28:27 INFO: Expanded save_name: saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:28:27 INFO: id_icon: saved_models/constituency/id_icon_charlm_constituency.pt does not exist, training new model\n","2024-03-28 14:28:27 INFO: Using default pretrain for language, found in /root/stanza_resources/id/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-28 14:28:27 INFO: Using model /root/stanza_resources/id/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-28 14:28:27 INFO: Using model /root/stanza_resources/id/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-28 14:28:27 INFO: Running train step with args: ['--train_file', '/content/gdrive/MyDrive/PLN/2/constituency/id_icon_train.mrg', '--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg', '--shorthand', 'id_icon', '--mode', 'train', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/id/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/id/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/id/backward_charlm/oscar2023.pt', '--epochs', '20']\n","2024-03-28 14:28:27 WARNING: Multistage training is set.  Best models are with MADGRAD, but it is not installed.  Will use AdamW for the second stage optimizer.  Consider installing MADGRAD\n","2024-03-28 14:28:27 INFO: Expanded save_name: id_icon_charlm_constituency.pt\n","2024-03-28 14:28:27 INFO: Running constituency parser in train mode\n","2024-03-28 14:28:27 DEBUG: Set trainer logging level to DEBUG\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 18.7MB/s]        \n","2024-03-28 14:28:27 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 14:28:27 DEBUG: Creating retag pipeline for default package\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/tokenize/gsd.pt: 100% 659k/659k [00:00<00:00, 10.4MB/s]\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/pos/gsd_charlm.pt: 100% 32.5M/32.5M [00:00<00:00, 69.5MB/s]\n","2024-03-28 14:28:29 INFO: Loading these models for language: id (Indonesian):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-28 14:28:29 INFO: Using device: cuda\n","2024-03-28 14:28:29 INFO: Loading: tokenize\n","2024-03-28 14:28:29 INFO: Loading: pos\n","2024-03-28 14:28:30 INFO: Done loading processors!\n","2024-03-28 14:28:30 INFO: ARGS USED AT TRAINING TIME:\n","additional_oracle_levels: None\n","bert_finetune: False\n","bert_finetune_begin_epoch: None\n","bert_finetune_end_epoch: None\n","bert_finetune_layers: None\n","bert_hidden_layers: 4\n","bert_learning_rate: 0.009\n","bert_model: None\n","bert_weight_decay: 0.0001\n","charlm_backward_file: /root/stanza_resources/id/backward_charlm/oscar2023.pt\n","charlm_forward_file: /root/stanza_resources/id/forward_charlm/oscar2023.pt\n","check_valid_states: True\n","checkpoint: True\n","checkpoint_save_name: saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","combined_dummy_embedding: True\n","constituency_composition: ConstituencyComposition.MAX\n","constituent_heads: 8\n","constituent_stack: StackHistory.LSTM\n","data_dir: data/constituency\n","delta_embedding_dim: 100\n","device: cuda\n","epoch_size: 5000\n","epochs: 20\n","eval_batch_size: 50\n","eval_file: /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","finetune: False\n","grad_clipping: None\n","hidden_size: 512\n","lang: id\n","lattn_attention_dropout: 0.2\n","lattn_combine_as_self: False\n","lattn_combined_input: True\n","lattn_d_ff: 2048\n","lattn_d_input_proj: None\n","lattn_d_kv: 64\n","lattn_d_l: 32\n","lattn_d_proj: 64\n","lattn_partitioned: True\n","lattn_pwff: True\n","lattn_q_as_matrix: False\n","lattn_relu_dropout: 0.2\n","lattn_resdrop: True\n","lattn_residual_dropout: 0.2\n","learning_beta2: 0.999\n","learning_eps: 1e-08\n","learning_momentum: None\n","learning_rate: 0.0002\n","learning_rate_cooldown: 10\n","learning_rate_factor: 0.6\n","learning_rate_min_lr: 4.000000000000001e-06\n","learning_rate_patience: 5\n","learning_rate_warmup: 0\n","learning_rho: 0.9\n","learning_weight_decay: 0.05\n","load_name: None\n","load_package: None\n","log_norms: False\n","log_shapes: False\n","lora_alpha: 128\n","lora_dropout: 0.1\n","lora_modules_to_save: []\n","lora_rank: 64\n","lora_target_modules: ['query', 'value', 'output.dense', 'intermediate.dense']\n","loss: cross\n","loss_focal_gamma: 2\n","lstm_input_dropout: 0.2\n","lstm_layer_dropout: 0.0\n","maxout_k: None\n","mode: train\n","multistage: True\n","nonlinearity: relu\n","num_generate: 0\n","num_lstm_layers: 2\n","num_output_layers: 3\n","num_tree_lstm_layers: 1\n","optim: adamw\n","oracle_forced_errors: 0.001\n","oracle_frequency: 0.8\n","oracle_initial_epoch: 1\n","oracle_level: None\n","pattn_attention_dropout: 0.2\n","pattn_bias: False\n","pattn_d_ff: 2048\n","pattn_d_kv: 64\n","pattn_d_model: 1024\n","pattn_encoder_max_len: 512\n","pattn_morpho_emb_dropout: 0.2\n","pattn_num_heads: 8\n","pattn_num_layers: 0\n","pattn_relu_dropout: 0.1\n","pattn_residual_dropout: 0.2\n","pattn_timing: sin\n","predict_dir: .\n","predict_dropout: 0.2\n","predict_file: None\n","predict_format: {:_O}\n","pretrain_max_vocab: 250000\n","rare_word_threshold: 0.02\n","rare_word_unknown_frequency: 0.02\n","reduce_heads: 8\n","reduce_position: 128\n","relearn_structure: False\n","retag_charlm_backward_file: None\n","retag_charlm_forward_file: None\n","retag_method: upos\n","retag_model_path: None\n","retag_package: default\n","retag_pretrain_path: None\n","retag_xpos: False\n","reversed: False\n","save_dir: saved_models/constituency\n","save_each_frequency: 1\n","save_each_name: saved_models/constituency/id_icon_charlm_constituency_%04d.pt\n","save_each_optimizer: True\n","save_each_start: None\n","save_name: saved_models/constituency/id_icon_charlm_constituency.pt\n","seed: 1234\n","sentence_boundary_vectors: SentenceBoundary.EVERYTHING\n","shorthand: id_icon\n","silver_epoch_size: None\n","silver_file: None\n","silver_remove_duplicates: False\n","stage1_bert_finetune: False\n","stage1_bert_learning_rate: 0.009\n","stage1_learning_rate: 1.0\n","stage1_learning_rate_min_lr: 0.02\n","tag_embedding_dim: 20\n","tag_unknown_frequency: 0.001\n","tokenized_dir: None\n","tokenized_file: None\n","train_batch_size: 30\n","train_file: /content/gdrive/MyDrive/PLN/2/constituency/id_icon_train.mrg\n","transition_embedding_dim: 20\n","transition_heads: 4\n","transition_hidden_size: 20\n","transition_scheme: TransitionScheme.IN_ORDER\n","transition_stack: StackHistory.LSTM\n","use_lattn: False\n","use_peft: False\n","use_silver_words: True\n","wandb: False\n","wandb_name: None\n","wandb_norm_regex: None\n","watch_regex: None\n","word_dropout: 0.2\n","wordvec_dir: extern_data/wordvec\n","wordvec_file: \n","wordvec_pretrain_file: /root/stanza_resources/id/pretrain/conll17.pt\n","\n","2024-03-28 14:28:30 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_train.mrg\n","100% 8000/8000 [00:02<00:00, 3914.04it/s]\n","2024-03-28 14:28:35 INFO: Read 8000 trees for the training set\n","2024-03-28 14:28:35 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","2024-03-28 14:28:36 INFO: Read 1000 trees for the dev set\n","2024-03-28 14:28:36 INFO: Retagging trees using the upos tags from the default package...\n","100% 8000/8000 [00:35<00:00, 223.31it/s]\n","100% 1000/1000 [00:03<00:00, 263.96it/s]\n","2024-03-28 14:29:16 INFO: Retagging finished\n","2024-03-28 14:29:16 INFO: Unique constituents in training set: ['ADJP', 'ADVP', 'CONJP', 'CP', 'FRAG', 'INTJ', 'NP', 'PP', 'PRN', 'QP', 'ROOT', 'RPN', 'S', 'SBAR', 'SBARQ', 'SINV', 'SQ', 'UCP', 'VP', 'WHADJP', 'WHADVP', 'WHNP', 'WHPP']\n","2024-03-28 14:29:17 INFO: Constituent node counts: Counter({'NP': 44678, 'VP': 21379, 'PP': 11746, 'S': 9557, 'ROOT': 8000, 'CP': 3238, 'RPN': 3193, 'ADJP': 2429, 'SINV': 1042, 'ADVP': 751, 'QP': 584, 'CONJP': 192, 'UCP': 179, 'WHADVP': 116, 'INTJ': 85, 'WHNP': 80, 'PRN': 70, 'FRAG': 63, 'SBARQ': 51, 'SBAR': 6, 'WHADJP': 3, 'SQ': 3, 'WHPP': 2})\n","2024-03-28 14:29:17 INFO: Unique tags in training set: ['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X']\n","2024-03-28 14:29:18 INFO: Unary limit: 2\n","2024-03-28 14:29:18 INFO: Building training transition sequences\n","100% 8000/8000 [00:01<00:00, 4413.61it/s]\n","2024-03-28 14:29:19 INFO: Building dev transition sequences\n","100% 1000/1000 [00:00<00:00, 19699.24it/s]\n","2024-03-28 14:29:20 INFO: Total unique transitions in train set: 25\n","2024-03-28 14:29:20 INFO: Unique transitions in training set: [Shift, CloseConstituent, OpenConstituent(('ADJP',)), OpenConstituent(('ADVP',)), OpenConstituent(('CONJP',)), OpenConstituent(('CP',)), OpenConstituent(('FRAG',)), OpenConstituent(('INTJ',)), OpenConstituent(('NP',)), OpenConstituent(('PP',)), OpenConstituent(('PRN',)), OpenConstituent(('QP',)), OpenConstituent(('ROOT',)), OpenConstituent(('RPN',)), OpenConstituent(('S',)), OpenConstituent(('SBAR',)), OpenConstituent(('SBARQ',)), OpenConstituent(('SINV',)), OpenConstituent(('SQ',)), OpenConstituent(('UCP',)), OpenConstituent(('VP',)), OpenConstituent(('WHADJP',)), OpenConstituent(('WHADVP',)), OpenConstituent(('WHNP',)), OpenConstituent(('WHPP',))]\n","2024-03-28 14:29:20 INFO: Root labels in treebank: ['ROOT']\n","2024-03-28 14:29:20 INFO: Verifying the transition sequences for 8000 trees\n","100% 8000/8000 [00:04<00:00, 1628.85it/s]\n","2024-03-28 14:29:24 INFO: Verifying the transition sequences for 1000 trees\n","100% 1000/1000 [00:00<00:00, 1621.69it/s]\n","2024-03-28 14:29:26 INFO: Using the following open nodes:\n","  ('ADJP',)\n","  ('ADVP',)\n","  ('CONJP',)\n","  ('CP',)\n","  ('FRAG',)\n","  ('INTJ',)\n","  ('NP',)\n","  ('PP',)\n","  ('PRN',)\n","  ('QP',)\n","  ('ROOT',)\n","  ('RPN',)\n","  ('S',)\n","  ('SBAR',)\n","  ('SBARQ',)\n","  ('SINV',)\n","  ('SQ',)\n","  ('UCP',)\n","  ('VP',)\n","  ('WHADJP',)\n","  ('WHADVP',)\n","  ('WHNP',)\n","  ('WHPP',)\n","2024-03-28 14:29:26 INFO: Warming up model for 10 iterations using AdaDelta to train the embeddings\n","2024-03-28 14:29:27 DEBUG: Building Adadelta with lr=1.000000, weight_decay=0.02\n","2024-03-28 14:29:27 INFO: Number of words in the training set found in the embedding: 15985 out of 17102\n","2024-03-28 14:29:27 INFO: Building CrossEntropyLoss(sum)\n","2024-03-28 14:29:28 INFO: Starting epoch 1\n","100% 167/167 [03:31<00:00,  1.26s/it, Epoch 1]\n","2024-03-28 14:32:59 INFO: Transitions correct: 94814\n","  Counter({'Shift': 57673, 'Close': 18738, 'Open': 18403})\n","2024-03-28 14:32:59 INFO: Transitions incorrect: 100728\n","  Counter({('Open', 'Shift'): 29878, ('Open', 'Close'): 14515, ('Open', 'Open'): 14257, ('Close', 'Shift'): 13021, ('Shift', 'Open'): 10260, ('Shift', 'Close'): 9916, ('Close', 'Open'): 8881})\n","2024-03-28 14:32:59 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 32245, <RepairType.OPEN_SHIFT: 6>: 20931, <RepairType.WRONG_OPEN_GENERAL: 4>: 12600, <RepairType.SHIFT_CLOSE: 8>: 9696, <RepairType.OPEN_CLOSE: 7>: 7800, <RepairType.CLOSE_SHIFT_NESTED: 9>: 3400, <RepairType.MISSED_UNARY: 5>: 1872, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 935, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 416, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 37})\n","2024-03-28 14:32:59 INFO: Fake transitions used: 15\n","2024-03-28 14:32:59 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:08<00:00, 117.66it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [1.2 sec].\n","pcfg LP/LR summary evalb: LP: 17.03 LR: 12.53 F1: 14.44 Exact: 0.0 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 17.03 LR: 12.53 F1: 14.44 Exact: 0.0 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:33:11 INFO: New best dev score: 0.14443 > 0.00000\n","2024-03-28 14:33:11 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:33:11 INFO: Epoch 1 finished\n","  Transitions correct: Counter({'Shift': 57673, 'Close': 18738, 'Open': 18403})\n","  Transitions incorrect: Counter({('Open', 'Shift'): 29878, ('Open', 'Close'): 14515, ('Open', 'Open'): 14257, ('Close', 'Shift'): 13021, ('Shift', 'Open'): 10260, ('Shift', 'Close'): 9916, ('Close', 'Open'): 8881})\n","  Total loss for epoch: 352243.71640\n","  Dev score      (    1): 0.144431\n","  Best dev score (    1): 0.144431\n","2024-03-28 14:33:13 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:33:13 INFO: Starting epoch 2\n","100% 167/167 [03:32<00:00,  1.27s/it, Epoch 2]\n","2024-03-28 14:36:45 INFO: Transitions correct: 120732\n","  Counter({'Shift': 65125, 'Close': 27978, 'Open': 27629})\n","2024-03-28 14:36:45 INFO: Transitions incorrect: 79424\n","  Counter({('Open', 'Shift'): 19538, ('Open', 'Open'): 18023, ('Close', 'Shift'): 11450, ('Shift', 'Open'): 8633, ('Open', 'Close'): 8499, ('Close', 'Open'): 7130, ('Shift', 'Close'): 6151})\n","2024-03-28 14:36:45 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 27574, <RepairType.OPEN_SHIFT: 6>: 15954, <RepairType.WRONG_OPEN_GENERAL: 4>: 15765, <RepairType.SHIFT_CLOSE: 8>: 6216, <RepairType.OPEN_CLOSE: 7>: 6171, <RepairType.CLOSE_SHIFT_NESTED: 9>: 2789, <RepairType.MISSED_UNARY: 5>: 1293, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1188, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 641, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 18})\n","2024-03-28 14:36:45 INFO: Fake transitions used: 36\n","2024-03-28 14:36:45 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:11<00:00, 87.54it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.6 sec].\n","pcfg LP/LR summary evalb: LP: 45.71 LR: 52.65 F1: 48.93 Exact: 2.6 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 45.71 LR: 52.65 F1: 48.93 Exact: 2.6 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:36:58 INFO: New best dev score: 0.48939 > 0.14443\n","2024-03-28 14:36:59 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:36:59 INFO: Epoch 2 finished\n","  Transitions correct: Counter({'Shift': 65125, 'Close': 27978, 'Open': 27629})\n","  Transitions incorrect: Counter({('Open', 'Shift'): 19538, ('Open', 'Open'): 18023, ('Close', 'Shift'): 11450, ('Shift', 'Open'): 8633, ('Open', 'Close'): 8499, ('Close', 'Open'): 7130, ('Shift', 'Close'): 6151})\n","  Total loss for epoch: 221776.72690\n","  Dev score      (    2): 0.489389\n","  Best dev score (    2): 0.489389\n","2024-03-28 14:37:00 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:37:00 INFO: Starting epoch 3\n","100% 167/167 [03:46<00:00,  1.36s/it, Epoch 3]\n","2024-03-28 14:40:46 INFO: Transitions correct: 172224\n","  Counter({'Shift': 78700, 'Close': 46886, 'Open': 46638})\n","2024-03-28 14:40:46 INFO: Transitions incorrect: 43851\n","  Counter({('Open', 'Open'): 11731, ('Open', 'Shift'): 7864, ('Open', 'Close'): 5770, ('Shift', 'Open'): 5503, ('Close', 'Open'): 5305, ('Close', 'Shift'): 3915, ('Shift', 'Close'): 3763})\n","2024-03-28 14:40:46 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 14744, <RepairType.WRONG_OPEN_GENERAL: 4>: 9798, <RepairType.OPEN_SHIFT: 6>: 6552, <RepairType.OPEN_CLOSE: 7>: 4494, <RepairType.SHIFT_CLOSE: 8>: 3801, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 1077, <RepairType.CLOSE_SHIFT_NESTED: 9>: 886, <RepairType.MISSED_UNARY: 5>: 642, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 225, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 39})\n","2024-03-28 14:40:46 INFO: Fake transitions used: 43\n","2024-03-28 14:40:46 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 94.68it/s] \n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.5 sec].\n","pcfg LP/LR summary evalb: LP: 66.42 LR: 62.64 F1: 64.48 Exact: 7.7 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 66.42 LR: 62.64 F1: 64.48 Exact: 7.7 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:40:58 INFO: New best dev score: 0.64483 > 0.48939\n","2024-03-28 14:40:59 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:40:59 INFO: Epoch 3 finished\n","  Transitions correct: Counter({'Shift': 78700, 'Close': 46886, 'Open': 46638})\n","  Transitions incorrect: Counter({('Open', 'Open'): 11731, ('Open', 'Shift'): 7864, ('Open', 'Close'): 5770, ('Shift', 'Open'): 5503, ('Close', 'Open'): 5305, ('Close', 'Shift'): 3915, ('Shift', 'Close'): 3763})\n","  Total loss for epoch: 138162.72281\n","  Dev score      (    3): 0.644826\n","  Best dev score (    3): 0.644826\n","2024-03-28 14:41:00 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:41:00 INFO: Starting epoch 4\n","100% 167/167 [03:51<00:00,  1.38s/it, Epoch 4]\n","2024-03-28 14:44:51 INFO: Transitions correct: 194074\n","  Counter({'Shift': 84048, 'Open': 56213, 'Close': 53813})\n","2024-03-28 14:44:51 INFO: Transitions incorrect: 25861\n","  Counter({('Open', 'Open'): 6214, ('Open', 'Close'): 4080, ('Open', 'Shift'): 3657, ('Close', 'Open'): 3655, ('Shift', 'Open'): 3340, ('Close', 'Shift'): 2769, ('Shift', 'Close'): 2146})\n","2024-03-28 14:44:51 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 9639, <RepairType.WRONG_OPEN_GENERAL: 4>: 5368, <RepairType.OPEN_CLOSE: 7>: 3453, <RepairType.OPEN_SHIFT: 6>: 3061, <RepairType.SHIFT_CLOSE: 8>: 2238, <RepairType.CLOSE_SHIFT_NESTED: 9>: 821, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 776, <RepairType.MISSED_UNARY: 5>: 387, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 39, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 17})\n","2024-03-28 14:44:51 INFO: Fake transitions used: 61\n","2024-03-28 14:44:51 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 93.42it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.5 sec].\n","pcfg LP/LR summary evalb: LP: 74.67 LR: 64.23 F1: 69.06 Exact: 9.0 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 74.67 LR: 64.23 F1: 69.06 Exact: 9.0 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:45:03 INFO: New best dev score: 0.69064 > 0.64483\n","2024-03-28 14:45:03 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:45:03 INFO: Epoch 4 finished\n","  Transitions correct: Counter({'Shift': 84048, 'Open': 56213, 'Close': 53813})\n","  Transitions incorrect: Counter({('Open', 'Open'): 6214, ('Open', 'Close'): 4080, ('Open', 'Shift'): 3657, ('Close', 'Open'): 3655, ('Shift', 'Open'): 3340, ('Close', 'Shift'): 2769, ('Shift', 'Close'): 2146})\n","  Total loss for epoch: 81591.80621\n","  Dev score      (    4): 0.690636\n","  Best dev score (    4): 0.690636\n","2024-03-28 14:45:04 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:45:04 INFO: Starting epoch 5\n","100% 167/167 [03:59<00:00,  1.44s/it, Epoch 5]\n","2024-03-28 14:49:04 INFO: Transitions correct: 199878\n","  Counter({'Shift': 85794, 'Open': 58208, 'Close': 55876})\n","2024-03-28 14:49:04 INFO: Transitions incorrect: 23578\n","  Counter({('Open', 'Open'): 5649, ('Open', 'Close'): 3842, ('Close', 'Open'): 3225, ('Open', 'Shift'): 3062, ('Shift', 'Open'): 2772, ('Close', 'Shift'): 2700, ('Shift', 'Close'): 2328})\n","2024-03-28 14:49:04 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 8378, <RepairType.WRONG_OPEN_GENERAL: 4>: 4430, <RepairType.OPEN_CLOSE: 7>: 3237, <RepairType.OPEN_SHIFT: 6>: 2465, <RepairType.SHIFT_CLOSE: 8>: 2377, <RepairType.CLOSE_SHIFT_NESTED: 9>: 811, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 696, <RepairType.MISSED_UNARY: 5>: 325, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 271, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 35})\n","2024-03-28 14:49:04 INFO: Fake transitions used: 69\n","2024-03-28 14:49:04 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 94.75it/s] \n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 74.27 LR: 77.67 F1: 75.93 Exact: 15.9 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 74.27 LR: 77.67 F1: 75.93 Exact: 15.9 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:49:16 INFO: New best dev score: 0.75940 > 0.69064\n","2024-03-28 14:49:16 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:49:16 INFO: Epoch 5 finished\n","  Transitions correct: Counter({'Shift': 85794, 'Open': 58208, 'Close': 55876})\n","  Transitions incorrect: Counter({('Open', 'Open'): 5649, ('Open', 'Close'): 3842, ('Close', 'Open'): 3225, ('Open', 'Shift'): 3062, ('Shift', 'Open'): 2772, ('Close', 'Shift'): 2700, ('Shift', 'Close'): 2328})\n","  Total loss for epoch: 77207.94203\n","  Dev score      (    5): 0.759396\n","  Best dev score (    5): 0.759396\n","2024-03-28 14:49:18 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:49:18 INFO: Starting epoch 6\n","100% 167/167 [03:58<00:00,  1.43s/it, Epoch 6]\n","2024-03-28 14:53:16 INFO: Transitions correct: 201180\n","  Counter({'Shift': 85280, 'Open': 59004, 'Close': 56896})\n","2024-03-28 14:53:16 INFO: Transitions incorrect: 19741\n","  Counter({('Open', 'Open'): 4399, ('Open', 'Close'): 3443, ('Close', 'Open'): 2732, ('Open', 'Shift'): 2711, ('Shift', 'Open'): 2636, ('Close', 'Shift'): 1961, ('Shift', 'Close'): 1859})\n","2024-03-28 14:53:16 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 7211, <RepairType.WRONG_OPEN_GENERAL: 4>: 3806, <RepairType.OPEN_CLOSE: 7>: 2905, <RepairType.OPEN_SHIFT: 6>: 2227, <RepairType.SHIFT_CLOSE: 8>: 1930, <RepairType.CLOSE_SHIFT_NESTED: 9>: 719, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 548, <RepairType.MISSED_UNARY: 5>: 324, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 40, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 4})\n","2024-03-28 14:53:16 INFO: Fake transitions used: 53\n","2024-03-28 14:53:16 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 99.67it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 78.0 LR: 79.22 F1: 78.61 Exact: 17.0 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 78.0 LR: 79.22 F1: 78.61 Exact: 17.0 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:53:28 INFO: New best dev score: 0.78610 > 0.75940\n","2024-03-28 14:53:28 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:53:28 INFO: Epoch 6 finished\n","  Transitions correct: Counter({'Shift': 85280, 'Open': 59004, 'Close': 56896})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4399, ('Open', 'Close'): 3443, ('Close', 'Open'): 2732, ('Open', 'Shift'): 2711, ('Shift', 'Open'): 2636, ('Close', 'Shift'): 1961, ('Shift', 'Close'): 1859})\n","  Total loss for epoch: 62591.98727\n","  Dev score      (    6): 0.786103\n","  Best dev score (    6): 0.786103\n","2024-03-28 14:53:32 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:53:32 INFO: Starting epoch 7\n","100% 167/167 [03:56<00:00,  1.41s/it, Epoch 7]\n","2024-03-28 14:57:28 INFO: Transitions correct: 207062\n","  Counter({'Shift': 87269, 'Open': 60880, 'Close': 58913})\n","2024-03-28 14:57:28 INFO: Transitions incorrect: 18779\n","  Counter({('Open', 'Open'): 4250, ('Open', 'Close'): 3228, ('Close', 'Open'): 2536, ('Open', 'Shift'): 2505, ('Shift', 'Open'): 2419, ('Shift', 'Close'): 1970, ('Close', 'Shift'): 1871})\n","2024-03-28 14:57:28 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 6614, <RepairType.WRONG_OPEN_GENERAL: 4>: 3706, <RepairType.OPEN_CLOSE: 7>: 2749, <RepairType.OPEN_SHIFT: 6>: 2064, <RepairType.SHIFT_CLOSE: 8>: 2028, <RepairType.CLOSE_SHIFT_NESTED: 9>: 754, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 507, <RepairType.MISSED_UNARY: 5>: 311, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 37})\n","2024-03-28 14:57:28 INFO: Fake transitions used: 68\n","2024-03-28 14:57:28 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 93.70it/s] \n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 78.99 LR: 80.49 F1: 79.73 Exact: 19.9 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 78.99 LR: 80.49 F1: 79.73 Exact: 19.9 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 14:57:40 INFO: New best dev score: 0.79736 > 0.78610\n","2024-03-28 14:57:40 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 14:57:40 INFO: Epoch 7 finished\n","  Transitions correct: Counter({'Shift': 87269, 'Open': 60880, 'Close': 58913})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4250, ('Open', 'Close'): 3228, ('Close', 'Open'): 2536, ('Open', 'Shift'): 2505, ('Shift', 'Open'): 2419, ('Shift', 'Close'): 1970, ('Close', 'Shift'): 1871})\n","  Total loss for epoch: 58792.69826\n","  Dev score      (    7): 0.797363\n","  Best dev score (    7): 0.797363\n","2024-03-28 14:57:45 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 14:57:45 INFO: Starting epoch 8\n","100% 167/167 [03:47<00:00,  1.36s/it, Epoch 8]\n","2024-03-28 15:01:32 INFO: Transitions correct: 202950\n","  Counter({'Shift': 85455, 'Open': 59652, 'Close': 57843})\n","2024-03-28 15:01:32 INFO: Transitions incorrect: 18032\n","  Counter({('Open', 'Open'): 4124, ('Open', 'Close'): 2916, ('Close', 'Open'): 2462, ('Shift', 'Open'): 2336, ('Open', 'Shift'): 2302, ('Shift', 'Close'): 2002, ('Close', 'Shift'): 1890})\n","2024-03-28 15:01:32 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 6214, <RepairType.WRONG_OPEN_GENERAL: 4>: 3297, <RepairType.OPEN_CLOSE: 7>: 2457, <RepairType.SHIFT_CLOSE: 8>: 2023, <RepairType.OPEN_SHIFT: 6>: 1848, <RepairType.CLOSE_SHIFT_NESTED: 9>: 694, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 446, <RepairType.MISSED_UNARY: 5>: 258, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 210, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 24})\n","2024-03-28 15:01:32 INFO: Fake transitions used: 59\n","2024-03-28 15:01:32 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:10<00:00, 94.23it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 80.36 LR: 81.66 F1: 81.0 Exact: 22.1 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 80.36 LR: 81.66 F1: 81.0 Exact: 22.1 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 15:01:44 INFO: New best dev score: 0.81008 > 0.79736\n","2024-03-28 15:01:44 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 15:01:44 INFO: Epoch 8 finished\n","  Transitions correct: Counter({'Shift': 85455, 'Open': 59652, 'Close': 57843})\n","  Transitions incorrect: Counter({('Open', 'Open'): 4124, ('Open', 'Close'): 2916, ('Close', 'Open'): 2462, ('Shift', 'Open'): 2336, ('Open', 'Shift'): 2302, ('Shift', 'Close'): 2002, ('Close', 'Shift'): 1890})\n","  Total loss for epoch: 59355.50534\n","  Dev score      (    8): 0.810084\n","  Best dev score (    8): 0.810084\n","2024-03-28 15:01:48 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 15:01:48 INFO: Starting epoch 9\n","100% 167/167 [03:54<00:00,  1.40s/it, Epoch 9]\n","2024-03-28 15:05:42 INFO: Transitions correct: 208017\n","  Counter({'Shift': 87329, 'Open': 61269, 'Close': 59419})\n","2024-03-28 15:05:42 INFO: Transitions incorrect: 16458\n","  Counter({('Open', 'Open'): 3655, ('Open', 'Close'): 2758, ('Close', 'Open'): 2245, ('Shift', 'Open'): 2204, ('Open', 'Shift'): 2131, ('Shift', 'Close'): 1746, ('Close', 'Shift'): 1719})\n","2024-03-28 15:05:42 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 5892, <RepairType.WRONG_OPEN_GENERAL: 4>: 3221, <RepairType.OPEN_CLOSE: 7>: 2350, <RepairType.SHIFT_CLOSE: 8>: 1790, <RepairType.OPEN_SHIFT: 6>: 1751, <RepairType.CLOSE_SHIFT_NESTED: 9>: 741, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 410, <RepairType.MISSED_UNARY: 5>: 269, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 24})\n","2024-03-28 15:05:42 INFO: Fake transitions used: 64\n","2024-03-28 15:05:42 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:09<00:00, 100.99it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 80.19 LR: 78.15 F1: 79.15 Exact: 20.5 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 80.19 LR: 78.15 F1: 79.15 Exact: 20.5 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 15:05:53 INFO: Epoch 9 finished\n","  Transitions correct: Counter({'Shift': 87329, 'Open': 61269, 'Close': 59419})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3655, ('Open', 'Close'): 2758, ('Close', 'Open'): 2245, ('Shift', 'Open'): 2204, ('Open', 'Shift'): 2131, ('Shift', 'Close'): 1746, ('Close', 'Shift'): 1719})\n","  Total loss for epoch: 51925.68137\n","  Dev score      (    9): 0.791583\n","  Best dev score (    8): 0.810084\n","2024-03-28 15:05:54 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 15:05:54 INFO: Starting epoch 10\n","100% 167/167 [03:57<00:00,  1.42s/it, Epoch 10]\n","2024-03-28 15:09:52 INFO: Transitions correct: 204375\n","  Counter({'Shift': 85500, 'Open': 60366, 'Close': 58509})\n","2024-03-28 15:09:52 INFO: Transitions incorrect: 15935\n","  Counter({('Open', 'Open'): 3614, ('Open', 'Close'): 2667, ('Close', 'Open'): 2187, ('Shift', 'Open'): 2105, ('Open', 'Shift'): 2048, ('Shift', 'Close'): 1742, ('Close', 'Shift'): 1572})\n","2024-03-28 15:09:52 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 5547, <RepairType.WRONG_OPEN_GENERAL: 4>: 2952, <RepairType.OPEN_CLOSE: 7>: 2261, <RepairType.SHIFT_CLOSE: 8>: 1765, <RepairType.OPEN_SHIFT: 6>: 1691, <RepairType.CLOSE_SHIFT_NESTED: 9>: 610, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 417, <RepairType.MISSED_UNARY: 5>: 264, <RepairType.WRONG_OPEN_ROOT_ERROR: 1>: 141, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 34})\n","2024-03-28 15:09:52 INFO: Fake transitions used: 66\n","2024-03-28 15:09:52 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:11<00:00, 88.04it/s] \n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 82.97 LR: 82.63 F1: 82.8 Exact: 25.0 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.97 LR: 82.63 F1: 82.8 Exact: 25.0 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 15:10:05 INFO: New best dev score: 0.82804 > 0.81008\n","2024-03-28 15:10:05 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 15:10:05 INFO: Epoch 10 finished\n","  Transitions correct: Counter({'Shift': 85500, 'Open': 60366, 'Close': 58509})\n","  Transitions incorrect: Counter({('Open', 'Open'): 3614, ('Open', 'Close'): 2667, ('Close', 'Open'): 2187, ('Shift', 'Open'): 2105, ('Open', 'Shift'): 2048, ('Shift', 'Close'): 1742, ('Close', 'Shift'): 1572})\n","  Total loss for epoch: 52313.15057\n","  Dev score      (   10): 0.828038\n","  Best dev score (   10): 0.828038\n","2024-03-28 15:10:06 INFO: Finished stage at epoch 10.  Restarting optimizer\n","2024-03-28 15:10:06 INFO: Previous best model was at epoch 10\n","2024-03-28 15:10:06 INFO: Switching to a model with 0 pattn layers and NO lattn\n","2024-03-28 15:10:06 DEBUG: Building AdamW with lr=0.000200, betas=(0.9, 0.999), eps=0.000000, weight_decay=0.05\n","2024-03-28 15:10:07 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 15:10:07 INFO: Starting epoch 11\n","100% 167/167 [04:14<00:00,  1.53s/it, Epoch 11]\n","2024-03-28 15:14:22 INFO: Transitions correct: 211868\n","  Counter({'Shift': 87907, 'Open': 62701, 'Close': 61260})\n","2024-03-28 15:14:22 INFO: Transitions incorrect: 12917\n","  Counter({('Open', 'Open'): 2812, ('Open', 'Close'): 2126, ('Shift', 'Open'): 1848, ('Open', 'Shift'): 1692, ('Close', 'Open'): 1643, ('Shift', 'Close'): 1424, ('Close', 'Shift'): 1372})\n","2024-03-28 15:14:22 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4565, <RepairType.WRONG_OPEN_GENERAL: 4>: 2460, <RepairType.OPEN_CLOSE: 7>: 1832, <RepairType.SHIFT_CLOSE: 8>: 1455, <RepairType.OPEN_SHIFT: 6>: 1393, <RepairType.CLOSE_SHIFT_NESTED: 9>: 654, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 332, <RepairType.MISSED_UNARY: 5>: 205, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 19})\n","2024-03-28 15:14:22 INFO: Fake transitions used: 43\n","2024-03-28 15:14:22 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:12<00:00, 80.80it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.4 sec].\n","pcfg LP/LR summary evalb: LP: 83.16 LR: 84.72 F1: 83.93 Exact: 26.4 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 83.16 LR: 84.72 F1: 83.93 Exact: 26.4 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 15:14:35 INFO: New best dev score: 0.83939 > 0.82804\n","2024-03-28 15:14:36 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 15:14:36 INFO: Epoch 11 finished\n","  Transitions correct: Counter({'Shift': 87907, 'Open': 62701, 'Close': 61260})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2812, ('Open', 'Close'): 2126, ('Shift', 'Open'): 1848, ('Open', 'Shift'): 1692, ('Close', 'Open'): 1643, ('Shift', 'Close'): 1424, ('Close', 'Shift'): 1372})\n","  Total loss for epoch: 39437.60664\n","  Dev score      (   11): 0.839388\n","  Best dev score (   11): 0.839388\n","2024-03-28 15:14:41 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 15:14:41 INFO: Starting epoch 12\n","100% 167/167 [04:22<00:00,  1.57s/it, Epoch 12]\n","2024-03-28 15:19:03 INFO: Transitions correct: 211774\n","  Counter({'Shift': 87657, 'Open': 62755, 'Close': 61362})\n","2024-03-28 15:19:03 INFO: Transitions incorrect: 11834\n","  Counter({('Open', 'Open'): 2458, ('Open', 'Close'): 1986, ('Shift', 'Open'): 1715, ('Open', 'Shift'): 1605, ('Close', 'Open'): 1487, ('Shift', 'Close'): 1344, ('Close', 'Shift'): 1239})\n","2024-03-28 15:19:03 INFO: Oracle repairs:\n","  Counter({<RepairType.UNKNOWN: 11>: 4179, <RepairType.WRONG_OPEN_GENERAL: 4>: 2138, <RepairType.OPEN_CLOSE: 7>: 1715, <RepairType.SHIFT_CLOSE: 8>: 1374, <RepairType.OPEN_SHIFT: 6>: 1331, <RepairType.CLOSE_SHIFT_NESTED: 9>: 592, <RepairType.WRONG_OPEN_STUFF_UNARY: 3>: 300, <RepairType.MISSED_UNARY: 5>: 184, <RepairType.WRONG_OPEN_UNARY_CHAIN: 2>: 20})\n","2024-03-28 15:19:03 INFO: Fake transitions used: 61\n","2024-03-28 15:19:03 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [00:12<00:00, 80.15it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.5 sec].\n","pcfg LP/LR summary evalb: LP: 83.5 LR: 84.96 F1: 84.22 Exact: 26.9 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 83.5 LR: 84.96 F1: 84.22 Exact: 26.9 N: 1000\n","factor Tag summary evalb: LP: 100.0 LR: 100.0 F1: 100.0 Exact: 100.0 N: 1000\n","2024-03-28 15:19:17 INFO: New best dev score: 0.84228 > 0.83939\n","2024-03-28 15:19:17 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency.pt\n","2024-03-28 15:19:17 INFO: Epoch 12 finished\n","  Transitions correct: Counter({'Shift': 87657, 'Open': 62755, 'Close': 61362})\n","  Transitions incorrect: Counter({('Open', 'Open'): 2458, ('Open', 'Close'): 1986, ('Shift', 'Open'): 1715, ('Open', 'Shift'): 1605, ('Close', 'Open'): 1487, ('Shift', 'Close'): 1344, ('Close', 'Shift'): 1239})\n","  Total loss for epoch: 35774.30552\n","  Dev score      (   12): 0.842278\n","  Best dev score (   12): 0.842278\n","2024-03-28 15:19:19 INFO: Model saved to saved_models/constituency/id_icon_charlm_constituency_checkpoint.pt\n","2024-03-28 15:19:19 INFO: Starting epoch 13\n"," 26% 43/167 [01:14<03:31,  1.70s/it, Epoch 13]"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency id_icon --score_dev"],"metadata":{"id":"AwWswhJP6g9j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711639764168,"user_tz":-60,"elapsed":277268,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"57eac78d-0c80-4a61-8e51-d98ee79c1dd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-28 15:25:40 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py id_icon --score_dev\n","2024-03-28 15:25:40 INFO: Default pretrain should be /root/stanza_resources/id/pretrain/conll17.pt  Attempting to download\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 13.5MB/s]        \n","2024-03-28 15:25:40 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 15:25:40 INFO: Downloading these customized packages for language: id (Indonesian)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 107M/107M [00:02<00:00, 46.9MB/s]\n","2024-03-28 15:25:43 INFO: Downloaded file to /root/stanza_resources/id/pretrain/conll17.pt\n","2024-03-28 15:25:43 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 15:25:43 INFO: Using default pretrain for language, found in /root/stanza_resources/id/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.9MB/s]        \n","2024-03-28 15:25:44 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 15:25:44 INFO: Downloading these customized packages for language: id (Indonesian)...\n","==============================\n","| Processor      | Package   |\n","------------------------------\n","| forward_charlm | oscar2023 |\n","==============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/forward_charlm/oscar2023.pt: 100% 22.3M/22.3M [00:00<00:00, 27.0MB/s]\n","2024-03-28 15:25:45 INFO: Downloaded file to /root/stanza_resources/id/forward_charlm/oscar2023.pt\n","2024-03-28 15:25:45 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 15:25:45 INFO: Downloaded model, using model /root/stanza_resources/id/forward_charlm/oscar2023.pt for forward charlm\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 14.8MB/s]        \n","2024-03-28 15:25:45 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 15:25:45 INFO: Downloading these customized packages for language: id (Indonesian)...\n","===============================\n","| Processor       | Package   |\n","-------------------------------\n","| backward_charlm | oscar2023 |\n","===============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/backward_charlm/oscar2023.pt: 100% 22.3M/22.3M [00:01<00:00, 13.9MB/s]\n","2024-03-28 15:25:48 INFO: Downloaded file to /root/stanza_resources/id/backward_charlm/oscar2023.pt\n","2024-03-28 15:25:48 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-28 15:25:48 INFO: Downloaded model, using model /root/stanza_resources/id/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-28 15:25:48 INFO: Running dev step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg', '--shorthand', 'id_icon', '--mode', 'predict', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/id/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/id/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/id/backward_charlm/oscar2023.pt']\n","2024-03-28 15:25:48 INFO: Expanded save_name: id_icon_charlm_constituency.pt\n","2024-03-28 15:25:49 INFO: Running constituency parser in predict mode\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 11.5MB/s]        \n","2024-03-28 15:25:49 INFO: Downloaded file to /root/stanza_resources/resources.json\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/tokenize/gsd.pt: 100% 659k/659k [00:00<00:00, 2.48MB/s]\n","Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.8.0/models/pos/gsd_charlm.pt: 100% 32.5M/32.5M [00:00<00:00, 32.6MB/s]\n","2024-03-28 15:25:52 INFO: Loading these models for language: id (Indonesian):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-28 15:25:52 INFO: Using device: cpu\n","2024-03-28 15:25:52 INFO: Loading: tokenize\n","2024-03-28 15:25:52 INFO: Loading: pos\n","2024-03-28 15:25:54 INFO: Done loading processors!\n","2024-03-28 15:25:56 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","2024-03-28 15:25:57 INFO: Read 1000 trees for evaluation\n","2024-03-28 15:25:57 INFO: Retagging trees using the upos tags from the default package...\n","100% 1000/1000 [01:26<00:00, 11.57it/s]\n","2024-03-28 15:27:24 INFO: Retagging finished\n","2024-03-28 15:27:24 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg\n","100% 1000/1000 [01:53<00:00,  8.84it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.8 sec].\n","pcfg LP/LR summary evalb: LP: 83.5 LR: 84.96 F1: 84.22 Exact: 26.9 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 83.5 LR: 84.96 F1: 84.22 Exact: 26.9 N: 1000\n","factor Tag summary evalb: LP: 7.39 LR: 7.39 F1: 7.39 Exact: 0.0 N: 1000\n","2024-03-28 15:29:21 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/id_icon_dev.mrg: 0.842278\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/2/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_constituency id_icon --score_test"],"metadata":{"id":"hkul4cqI6g9k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711639999814,"user_tz":-60,"elapsed":202804,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a0190832-b750-4a05-8ef5-fa7205ec4e3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-28 15:29:59 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/2/stanza/stanza/utils/training/run_constituency.py id_icon --score_test\n","2024-03-28 15:29:59 INFO: Using default pretrain for language, found in /root/stanza_resources/id/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-28 15:29:59 INFO: Using model /root/stanza_resources/id/forward_charlm/oscar2023.pt for forward charlm\n","2024-03-28 15:29:59 INFO: Using model /root/stanza_resources/id/backward_charlm/oscar2023.pt for backward charlm\n","2024-03-28 15:29:59 INFO: Running test step with args: ['--eval_file', '/content/gdrive/MyDrive/PLN/2/constituency/id_icon_test.mrg', '--shorthand', 'id_icon', '--mode', 'predict', '--retag_method', 'upos', '--wordvec_pretrain_file', '/root/stanza_resources/id/pretrain/conll17.pt', '--charlm_forward_file', '/root/stanza_resources/id/forward_charlm/oscar2023.pt', '--charlm_backward_file', '/root/stanza_resources/id/backward_charlm/oscar2023.pt']\n","2024-03-28 15:29:59 INFO: Expanded save_name: id_icon_charlm_constituency.pt\n","2024-03-28 15:29:59 INFO: Running constituency parser in predict mode\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/47.2k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 379kB [00:00, 11.6MB/s]        \n","2024-03-28 15:30:00 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-28 15:30:00 INFO: Loading these models for language: id (Indonesian):\n","==========================\n","| Processor | Package    |\n","--------------------------\n","| tokenize  | gsd        |\n","| pos       | gsd_charlm |\n","==========================\n","\n","2024-03-28 15:30:00 INFO: Using device: cpu\n","2024-03-28 15:30:00 INFO: Loading: tokenize\n","2024-03-28 15:30:00 INFO: Loading: pos\n","2024-03-28 15:30:02 INFO: Done loading processors!\n","2024-03-28 15:30:03 INFO: Reading trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_test.mrg\n","2024-03-28 15:30:04 INFO: Read 1000 trees for evaluation\n","2024-03-28 15:30:04 INFO: Retagging trees using the upos tags from the default package...\n","100% 1000/1000 [01:20<00:00, 12.48it/s]\n","2024-03-28 15:31:24 INFO: Retagging finished\n","2024-03-28 15:31:24 INFO: Processing 1000 trees from /content/gdrive/MyDrive/PLN/2/constituency/id_icon_test.mrg\n","100% 1000/1000 [01:49<00:00,  9.12it/s]\n","[main] INFO edu.stanford.nlp.parser.metrics.EvaluateTreebank - Testing on treebank\n","[main] INFO edu.stanford.nlp.util.Timing - Testing on treebank done [0.8 sec].\n","pcfg LP/LR summary evalb: LP: 82.26 LR: 83.87 F1: 83.05 Exact: 29.8 N: 1000\n","dep DA summary evalb: LP: 0.0 LR: 0.0 F1: 0.0 Exact: 0.0 N: 0\n","factor LP/LR summary evalb: LP: 82.26 LR: 83.87 F1: 83.05 Exact: 29.8 N: 1000\n","factor Tag summary evalb: LP: 7.95 LR: 7.95 F1: 7.95 Exact: 0.0 N: 1000\n","2024-03-28 15:33:17 INFO: F1 score on /content/gdrive/MyDrive/PLN/2/constituency/id_icon_test.mrg: 0.830598\n"]}]},{"cell_type":"markdown","source":["# EJERCICIO 3. ENTRENAMIENTO Y EVALUACIÓN DE PARSERS DE DEPENDENCIAS"],"metadata":{"id":"aggZJWFCxfn4"}},{"cell_type":"markdown","source":["Básicamente igual al Ejercicio 2 pero esta vez con parsers basados en dependencias. Un par de apuntes:\n","\n","*\tAconsejamos al alumno limitarse a trabajar con el formalismo de anotación basado en dependencias universales (UD, por universal dependencies). La mejor referencia al respecto es la web http://universaldependencies.org, dedicada a la creación y publicación de treebanks y otras herramientas y recursos que emplean dicho formalismo.\n","\n","*\tEn el caso del parsing de dependencias, y si se emplean UD, la herramienta de evaluación a emplear sería alguno de los scripts de evaluación del CoNLL Shared Task (2018 o 2017).\n","\n","\n","ENTREGABLES:\n","\n","Para cada parser empleado se incluirá en la memoria un apartado en el que se analicen sus características (modelo en el que se basa, etc.), URL de la web donde se obtuvo, si fue necesario preprocesar el texto de entrada/postprocesar la salida y cómo, etc. De forma similar, deberán incluirse sendos apartados describiendo las características de los treebanks empleados, si fue necesario adaptarlos y cómo, etc.\n","Finalmente, para cada idioma se incluirá una tabla(s) y/o gráfica(s) comparativa(s) de los resultados obtenidos con cada parser, así como un breve análisis de dichos resultados, junto con las características de la máquina empleada y los tiempos de entrenamiento requeridos."],"metadata":{"id":"L2VIph5iyrPl"}},{"cell_type":"markdown","source":["## (a) INGLÉS + LENGUA ROMANCE (ELEGIBLE, 2 PUNTOS)\n","\n","El enunciado viene a ser el mismo que para el caso del análisis basado en constituyentes (Apartado 2.a), pero esta vez: (1) dos parsers en vez de sólo uno; (2) análisis de dependencias en vez de constituyentes."],"metadata":{"id":"L0JY5TzXxph8"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import random as rn\n","import re\n","from google.colab import drive"],"metadata":{"id":"4CJTVqAOII6G","executionInfo":{"status":"ok","timestamp":1712683528971,"user_tz":-120,"elapsed":286,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j4UHMoXKIJc3","executionInfo":{"status":"ok","timestamp":1712683533054,"user_tz":-120,"elapsed":2186,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"4edf42c2-694f-4908-dbac-0f720c94f17e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Preparacion entorno Stanza"],"metadata":{"id":"HfvqkLumFM9w"}},{"cell_type":"code","source":["!pip install stanza"],"metadata":{"id":"iMFb-HcCDSVk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712681233345,"user_tz":-120,"elapsed":67878,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"62792e55-61f6-4c6b-f0f0-8097077a8475"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stanza\n","  Downloading stanza-1.8.1-py3-none-any.whl (970 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.4/970.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji (from stanza)\n","  Downloading emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.25.2)\n","Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.2.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->stanza)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n","Successfully installed emoji-2.11.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 stanza-1.8.1\n"]}]},{"cell_type":"code","source":["import stanza"],"metadata":{"id":"g7QbLB8yDTF9","executionInfo":{"status":"ok","timestamp":1712683554610,"user_tz":-120,"elapsed":1692,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Se siguen las instrucciones de https://github.com/stanfordnlp/stanza-train/tree/master para preparar el entorno y poder entrenar modelos empleando Stanza.\n","\n","Los siguientes pasos de la preparacion del entorno solo es necesario realizarlos la primera vez que se prepara el entorno de Stanza"],"metadata":{"id":"3tVk9Q0ME-Dc"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3 && git clone https://github.com/stanfordnlp/stanza-train.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUnGUvj09t5R","executionInfo":{"status":"ok","timestamp":1710353627001,"user_tz":-60,"elapsed":1705,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"16ccf235-87dd-4d29-b80c-4c486317503f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stanza-train'...\n","remote: Enumerating objects: 187, done.\u001b[K\n","remote: Counting objects: 100% (187/187), done.\u001b[K\n","remote: Compressing objects: 100% (101/101), done.\u001b[K\n","remote: Total 187 (delta 80), reused 171 (delta 66), pack-reused 0\u001b[K\n","Receiving objects: 100% (187/187), 35.37 KiB | 739.00 KiB/s, done.\n","Resolving deltas: 100% (80/80), done.\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train && git clone https://github.com/stanfordnlp/stanza.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTKVbikt-ddz","executionInfo":{"status":"ok","timestamp":1710353682387,"user_tz":-60,"elapsed":15152,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"480e382c-43a0-4749-d3a3-4aa1b26927dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'stanza'...\n","remote: Enumerating objects: 40307, done.\u001b[K\n","remote: Counting objects: 100% (2405/2405), done.\u001b[K\n","remote: Compressing objects: 100% (770/770), done.\u001b[K\n","remote: Total 40307 (delta 1827), reused 2125 (delta 1633), pack-reused 37902\u001b[K\n","Receiving objects: 100% (40307/40307), 83.29 MiB | 14.05 MiB/s, done.\n","Resolving deltas: 100% (30897/30897), done.\n","Updating files: 100% (519/519), done.\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train && cp config/config.sh stanza/scripts/config.sh"],"metadata":{"id":"OAPqIl7DB3MV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train && cp config/xpos_vocab_factory.py stanza/stanza/models/pos/xpos_vocab_factory.py"],"metadata":{"id":"js9aK1ovEXcv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocesado de datos"],"metadata":{"id":"3_rCT4deD4_o"}},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"KfO3kwfMD-zB"}},{"cell_type":"markdown","source":["##### EN"],"metadata":{"id":"dOPhn2MPEMGa"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_train.conllu\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_dev.conllu\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uj1nzvFRDsap","executionInfo":{"status":"ok","timestamp":1709835666284,"user_tz":-60,"elapsed":35603,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f6007397-6dc2-40b5-b402-50ef9bd10a8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1255 documents):\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (201 documents):\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_dev.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (208 documents):\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_test.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["##### IT"],"metadata":{"id":"RtevTd6IEPLm"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_train.conllu\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_dev.conllu\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"id":"vYs7paZNERXc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710246260468,"user_tz":-60,"elapsed":31070,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"2ce4101d-d808-4598-f16b-3f0dabc346bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1313 documents):\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (57 documents):\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["### Entrenamiento"],"metadata":{"id":"DrRA-lTXEsBO"}},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"UKEDp6wGEsBU"}},{"cell_type":"markdown","source":["##### EN"],"metadata":{"id":"RkkcLEELEsBW"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_config.cfg\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bhja80PvEsBX","executionInfo":{"status":"ok","timestamp":1710183637443,"user_tz":-60,"elapsed":6471,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"81040ae0-70be-4108-ff14-0b72ee56df81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train en_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_dev.spacy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESOXiEikJ4YT","executionInfo":{"status":"ok","timestamp":1710191275970,"user_tz":-60,"elapsed":7617675,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"127c6ce2-46f9-48a8-9130-3dc54261a7b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'morphologizer',\n","'trainable_lemmatizer', 'parser']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS MORPH...  LOSS TRAIN...  LOSS PARSER  TAG_ACC  POS_ACC  MORPH_ACC  LEMMA_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n","---  ------  ------------  -----------  -------------  -------------  -----------  -------  -------  ---------  ---------  -------  -------  -------  ------\n","  0       0          0.00       133.66         134.94         149.73       303.27    21.53    24.51      24.75      77.09    18.93     4.52     0.61    0.34\n","  0     200       4107.87     16020.21       17236.33        9966.39     31016.08    80.92    83.46      81.87      86.80    64.78    52.55    56.45    0.78\n","  0     400       6146.95      6733.73        7989.81        4329.39     21926.75    86.49    87.94      87.58      88.64    68.11    58.78    57.32    0.82\n","  0     600       6422.68      5187.77        6315.11        3312.85     19483.10    88.35    90.07      89.68      89.86    73.59    65.69    64.66    0.85\n","  0     800       6988.02      4784.72        5709.71        3216.38     17821.64    89.22    90.75      90.79      90.42    72.71    65.84    59.26    0.85\n","  0    1000       7282.71      4339.21        5101.92        2883.20     17535.12    89.58    91.02      91.43      91.02    75.15    68.13    66.56    0.86\n","  0    1200       8203.43      4405.56        5429.58        2862.20     17848.85    90.25    91.78      91.72      91.11    76.21    69.10    67.56    0.87\n","  1    1400       8086.90      3590.71        4347.96        2346.92     16578.05    90.78    92.17      92.20      91.63    76.45    70.51    67.11    0.87\n","  1    1600      10296.93      4059.63        5025.74        2540.80     19270.25    91.18    92.51      92.60      91.94    77.68    71.60    69.01    0.88\n","  1    1800      12917.72      4980.95        6039.62        2996.54     22945.20    91.42    92.73      92.86      92.07    78.38    72.87    68.49    0.88\n","  1    2000      17337.67      6429.21        7916.44        3693.27     29444.25    91.69    92.97      93.25      92.41    79.43    74.54    70.88    0.89\n","  2    2200      20481.43      6552.32        8261.58        3544.18     33210.71    92.00    93.06      93.25      92.34    80.47    75.31    72.03    0.89\n","  2    2400      26551.11      7970.17       10010.46        4279.35     40755.89    92.21    93.42      93.64      92.74    80.91    76.28    71.93    0.89\n","  3    2600      30829.55      8457.29       10796.81        4127.22     44565.37    92.38    93.64      93.88      92.90    81.80    77.34    73.52    0.90\n","  4    2800      37991.96      9494.07       12601.50        4349.48     51775.13    92.39    93.49      93.77      92.95    82.06    77.25    72.71    0.90\n","  5    3000      40050.73      9145.49       11931.37        3971.20     50909.50    92.57    93.67      93.90      93.01    82.15    77.67    73.36    0.90\n","  6    3200      40496.28      8587.34       11334.09        3498.11     48341.98    92.40    93.44      94.05      92.90    82.00    77.66    72.64    0.90\n","  7    3400      41774.64      8114.74       10874.36        3119.03     46331.69    92.65    93.79      94.12      93.06    82.33    78.11    74.21    0.90\n","  7    3600      42126.76      7730.07       10465.95        2839.35     44087.21    92.76    93.86      94.07      93.06    82.51    78.23    73.91    0.90\n","  8    3800      42114.13      7177.52        9838.62        2645.95     41592.08    92.61    93.66      94.16      93.10    82.89    78.65    74.90    0.90\n","  9    4000      43188.68      6921.85        9311.29        2377.43     40981.56    92.70    93.79      94.02      93.17    82.73    78.63    75.00    0.90\n"," 10    4200      43378.97      6454.12        9001.67        2241.93     39514.99    92.74    93.69      94.06      93.08    82.84    78.50    75.13    0.90\n"," 11    4400      44526.20      6341.68        8749.45        2049.67     39262.99    92.72    93.70      94.02      93.13    83.15    78.82    75.33    0.90\n"," 12    4600      45140.73      6279.80        8920.45        2050.40     37743.25    92.82    93.75      94.17      93.13    83.12    78.92    75.42    0.90\n"," 13    4800      44713.62      5906.89        8175.59        1784.18     35968.32    92.78    93.67      94.11      93.13    82.97    78.70    75.24    0.90\n"," 14    5000      46253.17      5813.89        8350.67        1800.04     35367.69    92.88    93.77      94.11      93.10    83.09    78.97    75.72    0.90\n"," 14    5200      47558.66      5681.43        7924.24        1708.52     34325.18    92.68    93.73      94.01      93.10    82.82    78.64    75.50    0.90\n"," 15    5400      46278.59      5431.57        7631.62        1564.29     33104.90    92.80    93.83      94.23      93.08    82.94    78.79    76.99    0.90\n"," 16    5600      47793.02      5268.25        7487.11        1528.67     32739.08    92.82    93.73      94.22      93.15    82.70    78.63    75.20    0.90\n"," 17    5800      48292.38      5042.14        7160.98        1524.11     31895.26    92.75    93.75      94.16      93.10    83.19    79.09    75.00    0.90\n"," 18    6000      49306.59      4966.86        7243.61        1508.21     31597.00    92.73    93.76      94.20      93.09    83.28    79.10    75.94    0.90\n"," 19    6200      49910.47      5152.77        7283.46        1502.31     30811.96    92.80    93.72      94.02      93.19    83.35    79.26    75.80    0.90\n"," 20    6400      49538.10      4697.27        6659.14        1370.43     29418.04    92.87    93.84      94.29      93.18    82.90    79.00    74.49    0.90\n"," 21    6600      52051.08      4778.80        6889.86        1329.98     30211.46    92.84    93.70      94.27      93.16    83.25    79.29    76.51    0.90\n"," 21    6800      51432.42      4689.15        6750.50        1307.66     28951.09    92.88    93.85      94.24      93.21    82.98    78.91    75.64    0.90\n"," 22    7000      52298.66      4436.85        6478.34        1164.85     28589.25    92.79    93.75      94.19      93.12    83.08    78.90    76.39    0.90\n"," 23    7200      51616.06      4320.66        6354.86        1166.07     28246.68    92.90    93.83      94.28      93.10    83.10    79.13    75.92    0.90\n"," 24    7400      50906.11      4305.29        6133.15        1169.75     26994.11    92.74    93.74      94.31      93.13    82.99    79.00    76.64    0.90\n"," 25    7600      52319.01      4333.41        6276.29        1209.42     26644.82    92.84    93.78      94.24      93.19    83.11    78.97    75.79    0.90\n"," 26    7800      54380.26      4175.85        6180.53        1139.98     26742.12    92.87    93.95      94.28      93.06    83.01    79.00    76.88    0.90\n"," 27    8000      52785.20      4047.91        5954.48        1081.65     25616.30    92.89    93.80      94.25      93.19    83.26    79.12    76.17    0.90\n"," 28    8200      55995.15      4041.96        5862.23        1150.52     26276.00    92.72    93.80      94.24      93.13    83.13    79.18    76.17    0.90\n"," 29    8400      54745.17      3943.59        5792.42        1078.15     25151.28    92.88    93.87      94.33      93.11    83.37    79.24    77.07    0.90\n"," 29    8600      55175.31      3935.94        5687.75         989.12     24999.87    93.02    93.95      94.39      93.20    83.36    79.33    76.79    0.91\n"," 30    8800      56087.02      3755.25        5570.96        1048.44     24137.29    92.89    93.89      94.23      93.19    83.26    79.31    76.87    0.90\n"," 31    9000      56678.27      3699.24        5553.61         976.31     24405.59    92.89    93.88      94.26      93.17    83.41    79.21    77.36    0.90\n"," 32    9200      57910.79      3686.22        5334.93         960.08     24357.35    92.87    93.85      94.36      93.17    83.49    79.53    76.88    0.91\n"," 33    9400      57879.67      3715.02        5532.75         916.56     23467.30    92.96    93.94      94.27      93.21    83.19    79.02    76.92    0.90\n"," 34    9600      57864.09      3646.50        5369.94         964.21     23614.63    92.86    93.98      94.34      93.17    83.12    79.09    76.84    0.90\n"," 35    9800      58587.22      3564.25        5345.94         903.90     23528.05    92.93    93.78      94.27      93.21    83.26    79.27    75.89    0.90\n"," 36   10000      59766.82      3476.18        5190.74         864.23     22782.20    92.86    93.88      94.20      93.17    83.51    79.44    77.40    0.90\n"," 36   10200      57952.02      3458.55        5231.68         904.73     22238.71    92.96    93.93      94.30      93.20    83.64    79.45    77.03    0.91\n"," 37   10400      59556.85      3462.16        5160.01         887.64     22176.75    92.78    93.74      94.33      93.14    83.41    79.34    76.97    0.90\n"," 38   10600      62245.65      3309.02        4859.81         970.84     22538.40    92.92    93.85      94.22      93.16    82.84    78.75    76.51    0.90\n"," 39   10800      62922.01      3275.46        4886.50         835.38     22095.20    92.84    93.77      94.28      93.17    83.21    78.96    77.21    0.90\n"," 40   11000      61835.02      3318.10        4922.01         861.01     21630.40    92.83    93.77      94.32      93.16    83.34    79.28    77.25    0.90\n"," 41   11200      64390.16      3231.12        4834.22         859.13     21747.79    92.89    93.83      94.22      93.21    83.35    79.16    77.33    0.90\n"," 42   11400      64434.79      3309.63        4861.13         879.78     21835.25    92.97    93.86      94.31      93.22    83.41    79.47    77.51    0.91\n"," 43   11600      62369.58      3166.93        4703.12         839.45     20908.50    93.02    93.97      94.32      93.24    83.42    79.42    77.59    0.91\n"," 43   11800      63765.53      3137.06        4787.17         871.97     20839.13    93.04    93.90      94.31      93.25    83.28    79.28    77.39    0.91\n"," 44   12000      64265.80      3041.52        4640.51         732.85     20680.11    92.93    93.77      94.29      93.21    83.22    79.18    77.22    0.90\n"," 45   12200      64862.17      3024.32        4533.36         772.80     20624.90    92.91    93.96      94.41      93.27    83.57    79.70    77.91    0.91\n"," 46   12400      69312.08      3050.19        4446.87         816.81     20902.36    92.86    93.81      94.33      93.20    83.27    79.29    76.74    0.90\n"," 47   12600      64893.31      2955.61        4466.07         782.44     20081.55    93.01    93.94      94.33      93.23    83.61    79.58    76.25    0.91\n"," 48   12800      67850.05      2907.95        4437.03         742.12     20160.44    92.83    93.85      94.34      93.21    83.58    79.58    76.31    0.91\n"," 49   13000      65705.12      2852.85        4304.50         756.75     19653.44    92.94    93.96      94.38      93.23    83.55    79.49    77.15    0.91\n"," 50   13200      68613.95      2942.08        4327.14         736.82     20054.78    92.90    93.97      94.42      93.23    83.46    79.44    76.86    0.91\n"," 50   13400      68952.40      2846.69        4290.93         714.92     19678.93    92.90    94.01      94.41      93.26    83.25    79.05    77.30    0.90\n"," 51   13600      69729.90      2790.27        4292.01         743.96     19416.55    92.92    93.88      94.46      93.17    83.85    79.86    77.78    0.91\n"," 52   13800      69785.36      2792.16        4141.82         668.70     19471.26    92.93    93.94      94.37      93.11    83.86    80.04    78.21    0.91\n"," 53   14000      69250.35      2823.72        4302.76         682.59     19595.54    92.93    93.90      94.37      93.15    83.39    79.41    76.29    0.91\n"," 54   14200      69395.77      2759.78        4019.86         688.38     18967.87    92.96    93.94      94.36      93.17    83.32    79.31    77.30    0.91\n"," 55   14400      70007.56      2696.17        4203.55         696.22     18855.19    92.92    93.95      94.42      93.22    83.44    79.49    77.37    0.91\n"," 56   14600      71103.76      2718.57        4135.59         698.32     18931.54    92.96    94.01      94.31      93.20    83.57    79.53    77.20    0.91\n"," 57   14800      73857.00      2623.66        4040.67         703.96     19078.89    92.86    93.88      94.44      93.23    83.40    79.37    77.91    0.91\n"," 57   15000      74041.06      2650.65        3952.77         652.49     19193.97    92.91    94.01      94.41      93.23    83.65    79.72    77.28    0.91\n"," 58   15200      73483.33      2600.29        4021.64         631.37     18590.12    92.91    93.89      94.34      93.14    83.30    79.45    76.64    0.90\n"," 59   15400      73106.50      2568.86        3925.32         638.11     18272.65    92.97    93.96      94.36      93.19    83.31    79.37    76.90    0.91\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["##### IT"],"metadata":{"id":"Dg2EZiZCEsBZ"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_config.cfg\""],"metadata":{"id":"6AxxSL_PEsBa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710246453212,"user_tz":-60,"elapsed":4767,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"612118a9-9cdc-4022-907f-2bc49563dc59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train it_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_dev.spacy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJFF1fH3oekX","executionInfo":{"status":"ok","timestamp":1710251827456,"user_tz":-60,"elapsed":5276410,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"bb7f3f9b-5331-4b5f-af86-23edf9d65f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'morphologizer',\n","'trainable_lemmatizer', 'parser']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS MORPH...  LOSS TRAIN...  LOSS PARSER  TAG_ACC  POS_ACC  MORPH_ACC  LEMMA_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n","---  ------  ------------  -----------  -------------  -------------  -----------  -------  -------  ---------  ---------  -------  -------  -------  ------\n","  0       0          0.00       208.86         213.21         236.67       482.78    31.71    32.05      24.54      55.33    28.99    10.81     1.02    0.34\n","  0     200       4581.50     14062.22       18709.24       16303.58     31114.47    87.81    88.49      82.89      85.75    71.21    60.11    76.34    0.81\n","  0     400       6786.83      5875.72        8619.94        7657.37     21860.30    91.38    91.99      90.19      90.20    76.46    67.87    83.30    0.86\n","  0     600       7120.60      4775.80        6716.99        5860.03     20532.59    92.61    93.50      92.19      92.33    79.16    71.46    80.56    0.88\n","  0     800       6931.61      3930.68        5300.38        4696.50     17847.72    93.76    94.06      93.14      93.12    80.59    73.35    93.48    0.90\n","  0    1000       7038.06      3536.06        4765.23        4121.46     16658.17    93.96    94.21      93.49      93.61    83.05    76.12    94.61    0.90\n","  0    1200       7432.77      3445.22        4638.96        3927.70     16368.24    94.54    94.85      94.20      93.95    82.74    76.26    91.76    0.91\n","  1    1400       7520.74      3054.46        4107.70        3505.24     16452.53    94.94    95.22      94.49      94.86    83.52    77.17    95.43    0.91\n","  1    1600       7533.71      2842.77        3846.71        3241.63     15406.52    94.76    95.17      94.57      95.11    83.67    77.81    95.00    0.92\n","  1    1800       8023.12      2760.15        3729.13        3121.57     15225.06    95.06    95.29      94.91      95.35    84.21    78.33    96.34    0.92\n","  1    2000       8629.83      2803.83        3740.55        3064.98     15820.79    95.26    95.47      95.09      95.35    84.99    78.77    95.81    0.92\n","  1    2200      10029.31      3193.22        4345.09        3580.27     17850.04    95.44    95.61      95.26      95.74    85.04    79.48    96.07    0.92\n","  1    2400      11220.98      3533.38        4725.43        3731.54     19891.62    95.55    95.87      95.50      95.81    84.98    79.63    96.16    0.92\n","  2    2600      12969.57      3458.11        4807.01        3769.07     21975.94    95.74    95.97      95.78      96.12    86.11    81.12    96.15    0.93\n","  2    2800      17099.05      4581.14        6201.21        4681.79     27714.91    95.85    96.28      96.00      96.33    86.53    81.33    96.50    0.93\n","  3    3000      21389.22      5506.76        7359.37        5547.68     35177.25    96.01    96.32      96.14      96.45    87.48    82.80    97.28    0.94\n","  3    3200      26174.81      6017.34        8205.85        5830.63     40250.87    96.09    96.39      96.15      96.57    87.84    83.65    97.02    0.94\n","  4    3400      30257.56      6491.87        8828.30        6025.67     44619.47    96.14    96.54      96.30      96.72    87.90    83.50    97.45    0.94\n","  5    3600      31280.95      6260.87        8484.52        5503.39     43767.94    96.24    96.57      96.48      96.98    88.83    84.43    97.06    0.94\n","  5    3800      30577.39      5610.78        7643.75        4828.60     41120.78    96.36    96.57      96.34      96.75    88.93    84.81    97.19    0.94\n","  6    4000      30917.88      5433.11        7515.36        4697.63     39551.81    96.27    96.69      96.54      96.94    88.92    84.65    97.36    0.94\n","  7    4200      32596.68      5311.74        7238.57        4468.67     39660.87    96.45    96.63      96.56      96.85    88.58    84.20    96.85    0.94\n","  7    4400      32825.28      4995.36        6893.13        4095.87     37852.32    96.41    96.60      96.43      96.98    88.81    84.58    97.45    0.94\n","  8    4600      33045.41      4856.00        6631.95        3876.75     36465.12    96.59    96.83      96.63      97.01    89.32    84.91    97.11    0.94\n","  9    4800      33866.95      4694.37        6526.17        3708.57     36084.22    96.33    96.52      96.56      96.98    88.98    84.91    97.28    0.94\n","  9    5000      34566.56      4484.37        6321.84        3551.90     34741.85    96.47    96.66      96.61      96.97    89.38    85.21    97.45    0.94\n"," 10    5200      34114.79      4236.16        5822.50        3267.96     33772.91    96.41    96.64      96.63      96.98    89.18    85.07    97.96    0.94\n"," 11    5400      35548.93      4269.55        5973.47        3389.92     33483.16    96.61    96.78      96.74      96.95    89.10    84.89    97.71    0.94\n"," 11    5600      36512.50      4222.57        5890.32        3189.73     32207.56    96.70    96.76      96.60      97.12    89.28    85.23    97.54    0.95\n"," 12    5800      37429.93      3965.41        5597.62        3013.31     31745.12    96.57    96.80      96.84      97.02    89.09    84.85    97.80    0.94\n"," 13    6000      37482.89      3911.39        5480.94        3029.22     30610.42    96.56    96.84      96.70      97.10    89.08    85.04    97.54    0.94\n"," 13    6200      38682.94      3922.30        5542.96        2987.77     30750.05    96.57    96.75      96.68      96.99    89.12    84.98    97.63    0.94\n"," 14    6400      37665.99      3583.19        5077.42        2682.52     28658.08    96.60    96.76      96.69      97.00    89.08    85.13    98.32    0.94\n"," 15    6600      39048.96      3649.99        5285.64        2704.95     28719.79    96.63    96.86      96.78      97.04    89.01    84.81    97.62    0.94\n"," 16    6800      40777.68      3651.53        5142.97        2658.31     28922.88    96.84    96.88      96.72      97.09    89.33    85.30    97.28    0.95\n"," 16    7000      40250.03      3528.99        4916.97        2486.65     27613.99    96.59    96.82      96.76      97.14    89.38    85.42    98.49    0.95\n"," 17    7200      40950.10      3452.95        4858.65        2407.19     27268.57    96.58    96.81      96.86      97.03    89.10    85.11    97.70    0.94\n"," 18    7400      42425.17      3457.74        4885.85        2651.61     27120.39    96.51    96.73      96.77      97.14    89.15    85.22    97.02    0.94\n"," 18    7600      43685.53      3363.93        4811.34        2384.44     27035.09    96.61    96.93      96.83      97.15    89.13    85.22    97.71    0.95\n"," 19    7800      42276.68      3225.51        4629.23        2350.58     25481.76    96.61    96.83      96.76      97.17    89.25    85.33    97.80    0.95\n"," 20    8000      43975.12      3188.98        4575.82        2333.54     25546.66    96.73    96.89      96.88      97.16    89.22    85.18    97.89    0.95\n"," 20    8200      44980.33      3218.23        4583.04        2305.02     25353.51    96.67    96.92      96.89      97.15    89.60    85.40    98.06    0.95\n"," 21    8400      43482.62      3180.63        4507.87        2277.87     23853.02    96.53    96.71      96.73      97.14    89.43    85.44    97.00    0.95\n"," 22    8600      46984.38      3166.27        4495.16        2275.97     24925.73    96.76    96.85      96.86      97.19    89.24    85.01    97.18    0.95\n"," 22    8800      47557.84      3121.30        4543.21        2250.43     24491.42    96.79    96.89      96.78      97.19    89.57    85.45    98.40    0.95\n"," 23    9000      45989.98      2947.80        4198.60        2098.42     23423.01    96.65    96.74      96.75      97.16    89.22    85.12    97.53    0.95\n"," 24    9200      47143.38      3004.15        4354.38        2057.63     23477.21    96.70    96.76      96.66      97.21    89.43    85.31    96.84    0.95\n"," 25    9400      49269.30      2981.80        4399.50        2220.39     23727.31    96.67    96.93      96.86      97.09    89.40    85.36    98.24    0.95\n"," 25    9600      49759.31      2908.51        4207.84        2056.66     23085.58    96.72    96.93      96.79      97.16    89.59    85.32    97.62    0.95\n"," 26    9800      46339.07      2754.76        3993.74        1939.07     21453.27    96.83    97.07      96.94      97.16    89.85    85.81    97.20    0.95\n"," 27   10000      51226.90      2867.81        4160.79        2044.95     22680.06    96.69    96.83      96.69      97.10    89.50    85.49    96.84    0.95\n"," 27   10200      49450.64      2783.28        4112.37        1956.71     21650.59    96.75    96.89      96.81      97.18    89.37    85.07    97.09    0.95\n"," 28   10400      49801.05      2681.87        3913.66        1971.75     21574.78    96.67    96.76      96.70      97.16    89.53    85.41    96.58    0.95\n"," 29   10600      54535.39      2843.44        4163.77        2074.21     22206.29    96.79    96.83      96.81      97.25    89.13    85.12    97.54    0.95\n"," 29   10800      52555.56      2730.89        3901.49        1924.75     21435.46    96.62    96.83      96.79      97.24    89.42    85.33    97.54    0.95\n"," 30   11000      51873.25      2647.58        3908.81        1857.71     20921.06    96.61    96.83      96.77      97.19    89.71    85.67    97.89    0.95\n"," 31   11200      53594.56      2663.82        3916.24        1968.04     20942.86    96.64    96.83      96.81      97.15    89.58    85.37    97.70    0.95\n"," 31   11400      54735.96      2623.71        3866.41        1913.52     20903.09    96.65    96.74      96.76      97.25    90.03    85.99    97.45    0.95\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["#### Stanza"],"metadata":{"id":"M30PJpNEEsBb"}},{"cell_type":"markdown","source":["##### EN"],"metadata":{"id":"EoLx6UHKEsBc"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_tokenizer_treebank UD_English-EWT"],"metadata":{"id":"X-HVQe_TEFN3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710356776170,"user_tz":-60,"elapsed":13928,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"b6125930-bbda-41e3-ef03-6c6998cf02ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-13 19:06:07 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py UD_English-EWT\n","Preparing data for UD_English-EWT: en_ewt, en\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-train.conllu and writing to ../data/processed/tokenize/en_ewt.train.gold.conllu\n","Augmented 66 quotes: Counter({'″″': 10, '““': 10, '《》': 8, '«»': 7, '「」': 6, '„”': 6, '\"\"': 6, '„“': 5, '””': 5, '»«': 3})\n","Swapped 'w1, w2' for 'w1 ,w2' 74 times\n","Added 109 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-dev.conllu and writing to ../data/processed/tokenize/en_ewt.dev.gold.conllu\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-test.conllu and writing to ../data/processed/tokenize/en_ewt.test.gold.conllu\n","Tokenizer labels written to ../data/processed/tokenize/en_ewt-ud-train.toklabels\n","  579 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/en_ewt-ud-train-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/en_ewt-ud-dev.toklabels\n","  151 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/en_ewt-ud-dev-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/en_ewt-ud-test.toklabels\n","  127 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/en_ewt-ud-test-mwt.json\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_tokenizer UD_English-EWT --step 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nwIkSLX1Ij8K","executionInfo":{"status":"ok","timestamp":1712684851876,"user_tz":-120,"elapsed":41067,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"68210f66-4e3c-4900-bfaa-a429032dcfd4"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 17:46:53 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_tokenizer.py UD_English-EWT --step 1000\n","2024-04-09 17:46:53 DEBUG: UD_English-EWT: en_ewt\n","2024-04-09 17:46:53 INFO: Save file for en_ewt model: en_ewt_tokenizer.pt\n","2024-04-09 17:46:53 INFO: UD_English-EWT: saved_models/tokenize/en_ewt_tokenizer.pt does not exist, training new model\n","2024-04-09 17:46:54 INFO: Running train step with args: ['--label_file', '../data/processed/tokenize/en_ewt-ud-train.toklabels', '--txt_file', '../data/processed/tokenize/en_ewt.train.txt', '--lang', 'en', '--max_seqlen', '300', '--mwt_json_file', '../data/processed/tokenize/en_ewt-ud-dev-mwt.json', '--dev_txt_file', '../data/processed/tokenize/en_ewt.dev.txt', '--dev_label_file', '../data/processed/tokenize/en_ewt-ud-dev.toklabels', '--dev_conll_gold', '../data/processed/tokenize/en_ewt.dev.gold.conllu', '--conll_file', '/tmp/tmppwmyxuhe', '--shorthand', 'en_ewt', '--step', '1000', '--save_name', 'en_ewt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-04-09 17:46:54 INFO: Running tokenizer in train mode\n","2024-04-09 17:46:59 DEBUG: 12530 sentences loaded.\n","2024-04-09 17:46:59 INFO: Found mwts in the training data.  Setting use_mwt to True\n","2024-04-09 17:47:00 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-04-09 17:47:02 INFO: Step     20/  1000 Loss: 0.562\n","2024-04-09 17:47:02 INFO: Step     40/  1000 Loss: 0.465\n","2024-04-09 17:47:02 INFO: Step     60/  1000 Loss: 0.299\n","2024-04-09 17:47:03 INFO: Step     80/  1000 Loss: 0.215\n","2024-04-09 17:47:03 INFO: Step    100/  1000 Loss: 0.169\n","2024-04-09 17:47:03 INFO: Step    120/  1000 Loss: 0.128\n","2024-04-09 17:47:04 INFO: Step    140/  1000 Loss: 0.093\n","2024-04-09 17:47:04 INFO: Step    160/  1000 Loss: 0.099\n","2024-04-09 17:47:04 INFO: Step    180/  1000 Loss: 0.084\n","2024-04-09 17:47:04 INFO: Step    200/  1000 Loss: 0.077\n","2024-04-09 17:47:06 INFO: en_ewt: token F1 = 96.71, sentence F1 = 73.44, mwt F1 = 96.32\n","2024-04-09 17:47:06 INFO: Model saved to saved_models/tokenize/en_ewt_tokenizer.pt\n","2024-04-09 17:47:06 INFO: Dev score: 83.541\tNew best dev score!\n","2024-04-09 17:47:06 INFO: Step    220/  1000 Loss: 0.066\n","2024-04-09 17:47:06 INFO: Step    240/  1000 Loss: 0.068\n","2024-04-09 17:47:06 INFO: Step    260/  1000 Loss: 0.065\n","2024-04-09 17:47:06 INFO: Step    280/  1000 Loss: 0.064\n","2024-04-09 17:47:07 INFO: Step    300/  1000 Loss: 0.064\n","2024-04-09 17:47:07 INFO: Step    320/  1000 Loss: 0.056\n","2024-04-09 17:47:07 INFO: Step    340/  1000 Loss: 0.058\n","2024-04-09 17:47:07 INFO: Step    360/  1000 Loss: 0.055\n","2024-04-09 17:47:08 INFO: Step    380/  1000 Loss: 0.053\n","2024-04-09 17:47:08 INFO: Step    400/  1000 Loss: 0.052\n","2024-04-09 17:47:09 INFO: en_ewt: token F1 = 97.77, sentence F1 = 80.94, mwt F1 = 97.41\n","2024-04-09 17:47:09 INFO: Model saved to saved_models/tokenize/en_ewt_tokenizer.pt\n","2024-04-09 17:47:09 INFO: Dev score: 88.603\tNew best dev score!\n","2024-04-09 17:47:09 INFO: Step    420/  1000 Loss: 0.055\n","2024-04-09 17:47:09 INFO: Step    440/  1000 Loss: 0.049\n","2024-04-09 17:47:10 INFO: Step    460/  1000 Loss: 0.059\n","2024-04-09 17:47:10 INFO: Step    480/  1000 Loss: 0.058\n","2024-04-09 17:47:10 INFO: Step    500/  1000 Loss: 0.057\n","2024-04-09 17:47:10 INFO: Step    520/  1000 Loss: 0.055\n","2024-04-09 17:47:11 INFO: Step    540/  1000 Loss: 0.044\n","2024-04-09 17:47:11 INFO: Step    560/  1000 Loss: 0.049\n","2024-04-09 17:47:11 INFO: Step    580/  1000 Loss: 0.045\n","2024-04-09 17:47:11 INFO: Step    600/  1000 Loss: 0.052\n","2024-04-09 17:47:14 INFO: en_ewt: token F1 = 98.34, sentence F1 = 84.33, mwt F1 = 98.02\n","2024-04-09 17:47:14 INFO: Model saved to saved_models/tokenize/en_ewt_tokenizer.pt\n","2024-04-09 17:47:14 INFO: Dev score: 90.829\tNew best dev score!\n","2024-04-09 17:47:14 INFO: Step    620/  1000 Loss: 0.038\n","2024-04-09 17:47:14 INFO: Step    640/  1000 Loss: 0.048\n","2024-04-09 17:47:15 INFO: Step    660/  1000 Loss: 0.049\n","2024-04-09 17:47:15 INFO: Step    680/  1000 Loss: 0.048\n","2024-04-09 17:47:15 INFO: Step    700/  1000 Loss: 0.045\n","2024-04-09 17:47:15 INFO: Step    720/  1000 Loss: 0.050\n","2024-04-09 17:47:16 INFO: Step    740/  1000 Loss: 0.047\n","2024-04-09 17:47:16 INFO: Step    760/  1000 Loss: 0.056\n","2024-04-09 17:47:16 INFO: Step    780/  1000 Loss: 0.044\n","2024-04-09 17:47:16 INFO: Step    800/  1000 Loss: 0.050\n","2024-04-09 17:47:18 INFO: en_ewt: token F1 = 98.56, sentence F1 = 86.12, mwt F1 = 98.25\n","2024-04-09 17:47:18 INFO: Model saved to saved_models/tokenize/en_ewt_tokenizer.pt\n","2024-04-09 17:47:18 INFO: Dev score: 91.948\tNew best dev score!\n","2024-04-09 17:47:18 INFO: Step    820/  1000 Loss: 0.044\n","2024-04-09 17:47:18 INFO: Step    840/  1000 Loss: 0.045\n","2024-04-09 17:47:18 INFO: Step    860/  1000 Loss: 0.042\n","2024-04-09 17:47:19 INFO: Step    880/  1000 Loss: 0.040\n","2024-04-09 17:47:19 INFO: Step    900/  1000 Loss: 0.046\n","2024-04-09 17:47:19 INFO: Step    920/  1000 Loss: 0.041\n","2024-04-09 17:47:19 INFO: Step    940/  1000 Loss: 0.042\n","2024-04-09 17:47:19 INFO: Step    960/  1000 Loss: 0.045\n","2024-04-09 17:47:20 INFO: Step    980/  1000 Loss: 0.043\n","2024-04-09 17:47:20 INFO: Step   1000/  1000 Loss: 0.046\n","2024-04-09 17:47:21 INFO: en_ewt: token F1 = 98.84, sentence F1 = 87.23, mwt F1 = 98.54\n","2024-04-09 17:47:21 INFO: Model saved to saved_models/tokenize/en_ewt_tokenizer.pt\n","2024-04-09 17:47:21 INFO: Dev score: 92.701\tNew best dev score!\n","2024-04-09 17:47:21 INFO: Best dev score=0.9270146630469626 at step 1000\n","2024-04-09 17:47:21 INFO: Running dev step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/en_ewt.dev.txt', '--lang', 'en', '--conll_file', '/tmp/tmppwmyxuhe', '--shorthand', 'en_ewt', '--mwt_json_file', '../data/processed/tokenize/en_ewt-ud-dev-mwt.json', '--step', '1000', '--save_name', 'en_ewt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-04-09 17:47:21 INFO: Running tokenizer in predict mode\n","2024-04-09 17:47:21 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-04-09 17:47:23 INFO: OOV rate:  0.003% (     4/124606)\n","2024-04-09 17:47:25 INFO: Finished running dev set on\n","UD_English-EWT\n","   Tokens Sentences     Words\n","    98.84     87.23     98.48\n","2024-04-09 17:47:25 INFO: Running test step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/en_ewt.test.txt', '--lang', 'en', '--conll_file', '/tmp/tmppwmyxuhe', '--shorthand', 'en_ewt', '--mwt_json_file', '../data/processed/tokenize/en_ewt-ud-test-mwt.json', '--step', '1000', '--save_name', 'en_ewt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-04-09 17:47:25 INFO: Running tokenizer in predict mode\n","2024-04-09 17:47:25 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-04-09 17:47:27 INFO: OOV rate:  0.002% (     2/123830)\n","2024-04-09 17:47:29 INFO: Finished running test set on\n","UD_English-EWT\n","   Tokens Sentences     Words\n","    98.66     85.66     98.39\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_pos_treebank UD_English-EWT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxznnih_FeG9","executionInfo":{"status":"ok","timestamp":1710439340103,"user_tz":-60,"elapsed":57097,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"7f32265e-9ab0-4325-9d31-3086d8dfae83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-14 18:02:12 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/datasets/prepare_pos_treebank.py UD_English-EWT\n","Preparing data for UD_English-EWT: en_ewt, en\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-train.conllu and writing to /tmp/tmpr95htl7m/en_ewt.train.gold.conllu\n","Augmented 66 quotes: Counter({'″″': 10, '““': 10, '《》': 8, '«»': 7, '「」': 6, '„”': 6, '\"\"': 6, '„“': 5, '””': 5, '»«': 3})\n","Swapped 'w1, w2' for 'w1 ,w2' 74 times\n","Added 109 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-dev.conllu and writing to /tmp/tmpr95htl7m/en_ewt.dev.gold.conllu\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-test.conllu and writing to /tmp/tmpr95htl7m/en_ewt.test.gold.conllu\n","Copying from /tmp/tmpr95htl7m/en_ewt.train.gold.conllu to ../data/processed/pos/en_ewt.train.in.conllu\n","Copying from /tmp/tmpr95htl7m/en_ewt.dev.gold.conllu to ../data/processed/pos/en_ewt.dev.in.conllu\n","Copying from /tmp/tmpr95htl7m/en_ewt.test.gold.conllu to ../data/processed/pos/en_ewt.test.in.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_pos UD_English-EWT --max_steps 500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7psZ8ZwKIFBI","executionInfo":{"status":"ok","timestamp":1712682374848,"user_tz":-120,"elapsed":465942,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"184556d0-1afe-4671-a09d-fb80693c0de2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 16:58:31 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_pos.py UD_English-EWT --max_steps 500\n","2024-04-09 16:58:31 DEBUG: UD_English-EWT: en_ewt\n","2024-04-09 16:58:31 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-04-09 16:58:31 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-04-09 16:58:31 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 16:58:31 INFO: UD_English-EWT: saved_models/pos/en_ewt_charlm_tagger.pt does not exist, training new model\n","2024-04-09 16:58:31 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-04-09 16:58:31 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-04-09 16:58:31 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 16:58:31 INFO: Running train POS for UD_English-EWT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/pos/en_ewt.train.in.conllu', '--output_file', '/tmp/tmpj7dbepn9', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'train', '--eval_file', '../data/processed/pos/en_ewt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--max_steps', '500']\n","2024-04-09 16:58:31 INFO: Running tagger in train mode\n","2024-04-09 16:58:31 INFO: Using pretrained contextualized char embedding\n","2024-04-09 16:58:31 INFO: Loading data with batch size 250...\n","2024-04-09 16:58:31 INFO: Reading ../data/processed/pos/en_ewt.train.in.conllu\n","2024-04-09 16:58:33 INFO: Train File ../data/processed/pos/en_ewt.train.in.conllu, Data Size: 12653\n","2024-04-09 16:58:43 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 16:58:49 INFO: Training tagger...\n","2024-04-09 16:58:49 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:58:49 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 16:58:50 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:58:50 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 16:58:51 INFO: Evaluating the model every 100 steps...\n","2024-04-09 16:59:07 INFO: Finished STEP 20/500, loss = 4.924521 (0.573 sec/batch), lr: 0.003000\n","2024-04-09 16:59:22 INFO: Finished STEP 40/500, loss = 3.063374 (0.616 sec/batch), lr: 0.003000\n","2024-04-09 16:59:37 INFO: Finished STEP 60/500, loss = 2.320861 (0.637 sec/batch), lr: 0.003000\n","2024-04-09 16:59:52 INFO: Finished STEP 80/500, loss = 2.099996 (0.821 sec/batch), lr: 0.003000\n","2024-04-09 17:00:07 INFO: Finished STEP 100/500, loss = 1.831189 (0.573 sec/batch), lr: 0.003000\n","2024-04-09 17:00:07 INFO: Evaluating on dev set...\n","2024-04-09 17:00:15 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:00:15 INFO: 93.42\t92.93\t93.02\t89.10\n","2024-04-09 17:00:15 INFO: step 100: train_loss = 4.535703, dev_score = 0.8910\n","2024-04-09 17:00:15 INFO: Model saved to saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:00:15 INFO: new best model saved.\n","2024-04-09 17:00:30 INFO: Finished STEP 120/500, loss = 1.908401 (0.622 sec/batch), lr: 0.003000\n","2024-04-09 17:00:45 INFO: Finished STEP 140/500, loss = 1.737984 (0.582 sec/batch), lr: 0.003000\n","2024-04-09 17:01:01 INFO: Finished STEP 160/500, loss = 1.675101 (0.600 sec/batch), lr: 0.003000\n","2024-04-09 17:01:16 INFO: Finished STEP 180/500, loss = 1.576439 (0.591 sec/batch), lr: 0.003000\n","2024-04-09 17:01:33 INFO: Finished STEP 200/500, loss = 1.580553 (0.614 sec/batch), lr: 0.003000\n","2024-04-09 17:01:33 INFO: Evaluating on dev set...\n","2024-04-09 17:01:40 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:01:40 INFO: 95.07\t94.59\t95.07\t92.19\n","2024-04-09 17:01:40 INFO: step 200: train_loss = 1.683520, dev_score = 0.9219\n","2024-04-09 17:01:40 INFO: Model saved to saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:01:40 INFO: new best model saved.\n","2024-04-09 17:01:55 INFO: Finished STEP 220/500, loss = 1.453211 (0.762 sec/batch), lr: 0.003000\n","2024-04-09 17:02:11 INFO: Finished STEP 240/500, loss = 1.511748 (0.627 sec/batch), lr: 0.003000\n","2024-04-09 17:02:28 INFO: Finished STEP 260/500, loss = 1.396381 (0.744 sec/batch), lr: 0.003000\n","2024-04-09 17:02:43 INFO: Finished STEP 280/500, loss = 1.380163 (0.683 sec/batch), lr: 0.003000\n","2024-04-09 17:02:58 INFO: Finished STEP 300/500, loss = 1.297369 (0.593 sec/batch), lr: 0.003000\n","2024-04-09 17:02:58 INFO: Evaluating on dev set...\n","2024-04-09 17:03:06 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:03:06 INFO: 95.58\t94.94\t95.46\t92.85\n","2024-04-09 17:03:06 INFO: step 300: train_loss = 1.454129, dev_score = 0.9285\n","2024-04-09 17:03:06 INFO: Model saved to saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:03:06 INFO: new best model saved.\n","2024-04-09 17:03:21 INFO: Finished STEP 320/500, loss = 1.238138 (0.551 sec/batch), lr: 0.003000\n","2024-04-09 17:03:37 INFO: Finished STEP 340/500, loss = 1.236225 (0.688 sec/batch), lr: 0.003000\n","2024-04-09 17:03:52 INFO: Finished STEP 360/500, loss = 1.318859 (0.601 sec/batch), lr: 0.003000\n","2024-04-09 17:04:07 INFO: Finished STEP 380/500, loss = 1.290702 (0.631 sec/batch), lr: 0.003000\n","2024-04-09 17:04:22 INFO: Finished STEP 400/500, loss = 1.281169 (0.650 sec/batch), lr: 0.003000\n","2024-04-09 17:04:22 INFO: Evaluating on dev set...\n","2024-04-09 17:04:31 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:04:31 INFO: 95.68\t95.08\t95.72\t93.19\n","2024-04-09 17:04:31 INFO: step 400: train_loss = 1.334269, dev_score = 0.9319\n","2024-04-09 17:04:31 INFO: Model saved to saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:04:31 INFO: new best model saved.\n","2024-04-09 17:04:46 INFO: Finished STEP 420/500, loss = 1.199907 (0.611 sec/batch), lr: 0.003000\n","2024-04-09 17:05:01 INFO: Finished STEP 440/500, loss = 1.271268 (0.583 sec/batch), lr: 0.003000\n","2024-04-09 17:05:17 INFO: Finished STEP 460/500, loss = 1.243870 (0.480 sec/batch), lr: 0.003000\n","2024-04-09 17:05:32 INFO: Finished STEP 480/500, loss = 1.261614 (0.577 sec/batch), lr: 0.003000\n","2024-04-09 17:05:49 INFO: Finished STEP 500/500, loss = 1.281252 (0.637 sec/batch), lr: 0.003000\n","2024-04-09 17:05:49 INFO: Evaluating on dev set...\n","2024-04-09 17:05:55 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:05:55 INFO: 95.92\t95.34\t95.94\t93.51\n","2024-04-09 17:05:55 INFO: step 500: train_loss = 1.252396, dev_score = 0.9351\n","2024-04-09 17:05:56 INFO: Model saved to saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:05:56 INFO: new best model saved.\n","2024-04-09 17:05:56 INFO: Training ended with 500 steps.\n","2024-04-09 17:05:56 INFO: Best dev F1 = 93.51, at iteration = 500\n","2024-04-09 17:05:56 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:05:56 INFO: Running dev POS for UD_English-EWT with args ['--wordvec_dir', '../data/wordvec', '--output_file', '/tmp/tmpj7dbepn9', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--eval_file', '../data/processed/pos/en_ewt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--max_steps', '500']\n","2024-04-09 17:05:56 INFO: Running tagger in predict mode\n","2024-04-09 17:05:56 INFO: Loading model from: saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 17:05:56 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 17:05:56 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:05:56 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 17:05:56 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:05:56 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 17:05:56 INFO: Loading data with batch size 250...\n","2024-04-09 17:06:01 INFO: Start evaluation...\n","2024-04-09 17:06:08 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:06:08 INFO: 95.92\t95.34\t95.94\t93.51\n","2024-04-09 17:06:08 INFO: POS Tagger score: en_ewt 93.51\n","2024-04-09 17:06:12 INFO: Finished running dev set on\n","UD_English-EWT\n","   UPOS    XPOS  UFeats AllTags\n","  95.92   95.34   95.94   93.51\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_English-EWT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VBFb_nSROIxB","executionInfo":{"status":"ok","timestamp":1712681512181,"user_tz":-120,"elapsed":116418,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"12f6bef5-c957-4212-98cc-476655a711b7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 16:50:01 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_depparse_treebank.py UD_English-EWT\n","2024-04-09 16:50:01 INFO: Using tagger model in saved_models/pos/en_ewt_charlm_tagger.pt for en_ewt\n","2024-04-09 16:50:01 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 16:50:01 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-04-09 16:50:01 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","Preparing data for UD_English-EWT: en_ewt, en\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-train.conllu and writing to /tmp/tmp9k9mv4uz/en_ewt.train.gold.conllu\n","Augmented 66 quotes: Counter({'″″': 10, '““': 10, '《》': 8, '«»': 7, '「」': 6, '„”': 6, '\"\"': 6, '„“': 5, '””': 5, '»«': 3})\n","Swapped 'w1, w2' for 'w1 ,w2' 74 times\n","Added 109 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-dev.conllu and writing to /tmp/tmp9k9mv4uz/en_ewt.dev.gold.conllu\n","Reading from ../data/udbase/UD_English-EWT/en_ewt-ud-test.conllu and writing to /tmp/tmp9k9mv4uz/en_ewt.test.gold.conllu\n","2024-04-09 16:50:07 INFO: Running tagger to retag /tmp/tmp9k9mv4uz/en_ewt.train.gold.conllu to ../data/processed/depparse/en_ewt.train.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'en_ewt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmp9k9mv4uz/en_ewt.train.gold.conllu', '--output_file', '../data/processed/depparse/en_ewt.train.in.conllu']\n","2024-04-09 16:50:08 INFO: Running tagger in predict mode\n","2024-04-09 16:50:08 INFO: Loading model from: saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 16:50:11 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 16:50:11 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:50:11 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 16:50:11 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:50:12 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 16:50:13 INFO: Loading data with batch size 250...\n","2024-04-09 16:50:28 INFO: Start evaluation...\n","2024-04-09 16:51:24 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 16:51:24 INFO: 98.13\t97.96\t98.22\t97.04\n","2024-04-09 16:51:24 INFO: POS Tagger score: en_ewt 97.04\n","2024-04-09 16:51:24 INFO: Running tagger to retag /tmp/tmp9k9mv4uz/en_ewt.dev.gold.conllu to ../data/processed/depparse/en_ewt.dev.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'en_ewt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmp9k9mv4uz/en_ewt.dev.gold.conllu', '--output_file', '../data/processed/depparse/en_ewt.dev.in.conllu']\n","2024-04-09 16:51:24 INFO: Running tagger in predict mode\n","2024-04-09 16:51:24 INFO: Loading model from: saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 16:51:24 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 16:51:24 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:51:24 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 16:51:24 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:51:24 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 16:51:24 INFO: Loading data with batch size 250...\n","2024-04-09 16:51:30 INFO: Start evaluation...\n","2024-04-09 16:51:37 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 16:51:37 INFO: 96.54\t96.04\t96.71\t94.68\n","2024-04-09 16:51:37 INFO: POS Tagger score: en_ewt 94.68\n","2024-04-09 16:51:37 INFO: Running tagger to retag /tmp/tmp9k9mv4uz/en_ewt.test.gold.conllu to ../data/processed/depparse/en_ewt.test.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'en_ewt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--eval_file', '/tmp/tmp9k9mv4uz/en_ewt.test.gold.conllu', '--output_file', '../data/processed/depparse/en_ewt.test.in.conllu']\n","2024-04-09 16:51:37 INFO: Running tagger in predict mode\n","2024-04-09 16:51:37 INFO: Loading model from: saved_models/pos/en_ewt_charlm_tagger.pt\n","2024-04-09 16:51:37 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 16:51:37 DEBUG: POS model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:51:37 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 16:51:37 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 16:51:37 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 16:51:37 INFO: Loading data with batch size 250...\n","2024-04-09 16:51:39 INFO: Start evaluation...\n","2024-04-09 16:51:48 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 16:51:48 INFO: 96.54\t96.15\t96.92\t94.78\n","2024-04-09 16:51:48 INFO: POS Tagger score: en_ewt 94.78\n","Copying from ../data/processed/depparse/en_ewt.dev.in.conllu to ../data/processed/depparse/en_ewt.dev.gold.conllu\n","Copying from ../data/processed/depparse/en_ewt.test.in.conllu to ../data/processed/depparse/en_ewt.test.gold.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_depparse UD_English-EWT --max_steps 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XVEXe4deOTe5","outputId":"572e0702-4ff9-4b08-f141-f4fe29af7554","executionInfo":{"status":"ok","timestamp":1712683269154,"user_tz":-120,"elapsed":789707,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 17:08:01 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_depparse.py UD_English-EWT --max_steps 1000\n","2024-04-09 17:08:01 DEBUG: UD_English-EWT: en_ewt\n","2024-04-09 17:08:01 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-04-09 17:08:01 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-04-09 17:08:01 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:08:01 INFO: UD_English-EWT: saved_models/depparse/en_ewt_charlm_parser.pt does not exist, training new model\n","2024-04-09 17:08:01 INFO: Using model /root/stanza_resources/en/forward_charlm/1billion.pt for forward charlm\n","2024-04-09 17:08:01 INFO: Using model /root/stanza_resources/en/backward_charlm/1billion.pt for backward charlm\n","2024-04-09 17:08:01 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:08:01 INFO: Running train depparse for UD_English-EWT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/depparse/en_ewt.train.in.conllu', '--eval_file', '../data/processed/depparse/en_ewt.dev.in.conllu', '--output_file', '/tmp/tmpyksixau1', '--gold_file', '../data/processed/depparse/en_ewt.dev.gold.conllu', '--batch_size', '5000', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--max_steps', '1000']\n","2024-04-09 17:08:02 INFO: Running parser in train mode\n","2024-04-09 17:08:02 INFO: Using pretrained contextualized char embedding\n","2024-04-09 17:08:02 INFO: Loading data with batch size 5000...\n","2024-04-09 17:08:04 INFO: Original data size: 12653\n","2024-04-09 17:08:04 INFO: Augmented data size: 12653\n","2024-04-09 17:08:14 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 17:08:17 DEBUG: 45 batches created.\n","2024-04-09 17:08:18 DEBUG: 6 batches created.\n","2024-04-09 17:08:18 INFO: Training parser...\n","2024-04-09 17:08:18 DEBUG: Depparse model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:08:18 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 17:08:18 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:08:19 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 17:08:33 INFO: Finished STEP 20/1000, loss = 7.178265 (0.456 sec/batch), lr: 0.003000\n","2024-04-09 17:08:46 INFO: Finished STEP 40/1000, loss = 6.298375 (0.454 sec/batch), lr: 0.003000\n","2024-04-09 17:08:58 INFO: Finished STEP 60/1000, loss = 6.776392 (0.427 sec/batch), lr: 0.003000\n","2024-04-09 17:09:11 INFO: Finished STEP 80/1000, loss = 6.268416 (0.524 sec/batch), lr: 0.003000\n","2024-04-09 17:09:24 INFO: Finished STEP 100/1000, loss = 6.390122 (0.569 sec/batch), lr: 0.003000\n","2024-04-09 17:09:24 INFO: Evaluating on dev set...\n","2024-04-09 17:09:32 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:09:32 INFO: 19.46\t6.94\t15.87\n","2024-04-09 17:09:32 INFO: step 100: train_loss = 13.861285, dev_score = 0.1946\n","2024-04-09 17:09:33 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:09:33 INFO: new best model saved.\n","2024-04-09 17:09:34 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:09:34 INFO: new model checkpoint saved.\n","2024-04-09 17:09:48 INFO: Finished STEP 120/1000, loss = 4.677549 (0.442 sec/batch), lr: 0.003000\n","2024-04-09 17:10:02 INFO: Finished STEP 140/1000, loss = 4.725724 (0.580 sec/batch), lr: 0.003000\n","2024-04-09 17:10:14 INFO: Finished STEP 160/1000, loss = 4.436088 (0.460 sec/batch), lr: 0.003000\n","2024-04-09 17:10:28 INFO: Finished STEP 180/1000, loss = 3.808078 (0.425 sec/batch), lr: 0.003000\n","2024-04-09 17:10:40 INFO: Finished STEP 200/1000, loss = 4.247329 (0.619 sec/batch), lr: 0.003000\n","2024-04-09 17:10:40 INFO: Evaluating on dev set...\n","2024-04-09 17:10:48 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:10:48 INFO: 55.33\t42.67\t49.96\n","2024-04-09 17:10:48 INFO: step 200: train_loss = 4.517341, dev_score = 0.5533\n","2024-04-09 17:10:49 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:10:49 INFO: new best model saved.\n","2024-04-09 17:10:50 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:10:50 INFO: new model checkpoint saved.\n","2024-04-09 17:11:04 INFO: Finished STEP 220/1000, loss = 3.144830 (0.535 sec/batch), lr: 0.003000\n","2024-04-09 17:11:17 INFO: Finished STEP 240/1000, loss = 3.461271 (0.516 sec/batch), lr: 0.003000\n","2024-04-09 17:11:30 INFO: Finished STEP 260/1000, loss = 4.072646 (0.681 sec/batch), lr: 0.003000\n","2024-04-09 17:11:43 INFO: Finished STEP 280/1000, loss = 3.504908 (0.592 sec/batch), lr: 0.003000\n","2024-04-09 17:11:57 INFO: Finished STEP 300/1000, loss = 3.405160 (0.642 sec/batch), lr: 0.003000\n","2024-04-09 17:11:57 INFO: Evaluating on dev set...\n","2024-04-09 17:12:03 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:12:03 INFO: 70.95\t61.52\t63.78\n","2024-04-09 17:12:03 INFO: step 300: train_loss = 3.419645, dev_score = 0.7095\n","2024-04-09 17:12:04 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:12:04 INFO: new best model saved.\n","2024-04-09 17:12:05 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:12:05 INFO: new model checkpoint saved.\n","2024-04-09 17:12:18 INFO: Finished STEP 320/1000, loss = 2.591097 (0.524 sec/batch), lr: 0.003000\n","2024-04-09 17:12:32 INFO: Finished STEP 340/1000, loss = 2.601622 (0.474 sec/batch), lr: 0.003000\n","2024-04-09 17:12:46 INFO: Finished STEP 360/1000, loss = 2.853571 (0.528 sec/batch), lr: 0.003000\n","2024-04-09 17:12:59 INFO: Finished STEP 380/1000, loss = 2.271701 (0.477 sec/batch), lr: 0.003000\n","2024-04-09 17:13:12 INFO: Finished STEP 400/1000, loss = 2.686934 (0.498 sec/batch), lr: 0.003000\n","2024-04-09 17:13:12 INFO: Evaluating on dev set...\n","2024-04-09 17:13:17 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:13:17 INFO: 77.08\t69.08\t70.74\n","2024-04-09 17:13:17 INFO: step 400: train_loss = 2.737705, dev_score = 0.7708\n","2024-04-09 17:13:18 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:13:18 INFO: new best model saved.\n","2024-04-09 17:13:19 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:13:19 INFO: new model checkpoint saved.\n","2024-04-09 17:13:35 INFO: Finished STEP 420/1000, loss = 1.665959 (0.509 sec/batch), lr: 0.003000\n","2024-04-09 17:13:48 INFO: Finished STEP 440/1000, loss = 2.402816 (0.564 sec/batch), lr: 0.003000\n","2024-04-09 17:14:00 INFO: Finished STEP 460/1000, loss = 2.090051 (0.459 sec/batch), lr: 0.003000\n","2024-04-09 17:14:14 INFO: Finished STEP 480/1000, loss = 1.832946 (0.479 sec/batch), lr: 0.003000\n","2024-04-09 17:14:27 INFO: Finished STEP 500/1000, loss = 3.063203 (0.704 sec/batch), lr: 0.003000\n","2024-04-09 17:14:27 INFO: Evaluating on dev set...\n","2024-04-09 17:14:34 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:14:34 INFO: 80.37\t73.47\t75.04\n","2024-04-09 17:14:34 INFO: step 500: train_loss = 2.284583, dev_score = 0.8037\n","2024-04-09 17:14:34 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:14:34 INFO: new best model saved.\n","2024-04-09 17:14:36 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:14:36 INFO: new model checkpoint saved.\n","2024-04-09 17:14:49 INFO: Finished STEP 520/1000, loss = 2.748752 (0.603 sec/batch), lr: 0.003000\n","2024-04-09 17:15:02 INFO: Finished STEP 540/1000, loss = 1.999649 (0.493 sec/batch), lr: 0.003000\n","2024-04-09 17:15:15 INFO: Finished STEP 560/1000, loss = 1.837906 (0.454 sec/batch), lr: 0.003000\n","2024-04-09 17:15:29 INFO: Finished STEP 580/1000, loss = 1.944713 (0.479 sec/batch), lr: 0.003000\n","2024-04-09 17:15:41 INFO: Finished STEP 600/1000, loss = 1.975215 (0.515 sec/batch), lr: 0.003000\n","2024-04-09 17:15:41 INFO: Evaluating on dev set...\n","2024-04-09 17:15:48 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:15:48 INFO: 82.49\t76.16\t77.72\n","2024-04-09 17:15:48 INFO: step 600: train_loss = 2.095141, dev_score = 0.8249\n","2024-04-09 17:15:49 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:15:49 INFO: new best model saved.\n","2024-04-09 17:15:50 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:15:50 INFO: new model checkpoint saved.\n","2024-04-09 17:16:04 INFO: Finished STEP 620/1000, loss = 2.118063 (0.524 sec/batch), lr: 0.003000\n","2024-04-09 17:16:17 INFO: Finished STEP 640/1000, loss = 1.884089 (0.511 sec/batch), lr: 0.003000\n","2024-04-09 17:16:30 INFO: Finished STEP 660/1000, loss = 1.618319 (0.423 sec/batch), lr: 0.003000\n","2024-04-09 17:16:45 INFO: Finished STEP 680/1000, loss = 2.291624 (0.593 sec/batch), lr: 0.003000\n","2024-04-09 17:16:58 INFO: Finished STEP 700/1000, loss = 1.365386 (0.444 sec/batch), lr: 0.003000\n","2024-04-09 17:16:58 INFO: Evaluating on dev set...\n","2024-04-09 17:17:03 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:17:03 INFO: 83.66\t77.86\t79.23\n","2024-04-09 17:17:03 INFO: step 700: train_loss = 1.989415, dev_score = 0.8366\n","2024-04-09 17:17:03 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:17:03 INFO: new best model saved.\n","2024-04-09 17:17:05 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:17:05 INFO: new model checkpoint saved.\n","2024-04-09 17:17:20 INFO: Finished STEP 720/1000, loss = 2.485086 (0.612 sec/batch), lr: 0.003000\n","2024-04-09 17:17:34 INFO: Finished STEP 740/1000, loss = 1.556868 (0.501 sec/batch), lr: 0.003000\n","2024-04-09 17:17:47 INFO: Finished STEP 760/1000, loss = 2.249087 (0.632 sec/batch), lr: 0.003000\n","2024-04-09 17:18:00 INFO: Finished STEP 780/1000, loss = 1.710674 (0.524 sec/batch), lr: 0.003000\n","2024-04-09 17:18:13 INFO: Finished STEP 800/1000, loss = 1.828173 (0.549 sec/batch), lr: 0.003000\n","2024-04-09 17:18:13 INFO: Evaluating on dev set...\n","2024-04-09 17:18:19 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:18:19 INFO: 84.56\t79.06\t80.34\n","2024-04-09 17:18:19 INFO: step 800: train_loss = 1.854373, dev_score = 0.8456\n","2024-04-09 17:18:19 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:18:19 INFO: new best model saved.\n","2024-04-09 17:18:21 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:18:21 INFO: new model checkpoint saved.\n","2024-04-09 17:18:34 INFO: Finished STEP 820/1000, loss = 1.374011 (0.484 sec/batch), lr: 0.003000\n","2024-04-09 17:18:47 INFO: Finished STEP 840/1000, loss = 0.808101 (0.837 sec/batch), lr: 0.003000\n","2024-04-09 17:19:00 INFO: Finished STEP 860/1000, loss = 1.600871 (0.571 sec/batch), lr: 0.003000\n","2024-04-09 17:19:12 INFO: Finished STEP 880/1000, loss = 1.163533 (0.497 sec/batch), lr: 0.003000\n","2024-04-09 17:19:26 INFO: Finished STEP 900/1000, loss = 1.812034 (0.516 sec/batch), lr: 0.003000\n","2024-04-09 17:19:26 INFO: Evaluating on dev set...\n","2024-04-09 17:19:33 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:19:33 INFO: 85.09\t79.83\t81.07\n","2024-04-09 17:19:33 INFO: step 900: train_loss = 1.770506, dev_score = 0.8509\n","2024-04-09 17:19:33 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:19:33 INFO: new best model saved.\n","2024-04-09 17:19:35 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:19:35 INFO: new model checkpoint saved.\n","2024-04-09 17:19:48 INFO: Finished STEP 920/1000, loss = 1.507632 (0.439 sec/batch), lr: 0.003000\n","2024-04-09 17:20:01 INFO: Finished STEP 940/1000, loss = 1.978781 (0.672 sec/batch), lr: 0.003000\n","2024-04-09 17:20:14 INFO: Finished STEP 960/1000, loss = 1.960168 (0.670 sec/batch), lr: 0.003000\n","2024-04-09 17:20:27 INFO: Finished STEP 980/1000, loss = 2.353849 (0.585 sec/batch), lr: 0.003000\n","2024-04-09 17:20:42 INFO: Finished STEP 1000/1000, loss = 1.516160 (0.496 sec/batch), lr: 0.003000\n","2024-04-09 17:20:42 INFO: Evaluating on dev set...\n","2024-04-09 17:20:48 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:20:48 INFO: 85.61\t80.69\t81.82\n","2024-04-09 17:20:48 INFO: step 1000: train_loss = 1.716948, dev_score = 0.8561\n","2024-04-09 17:20:48 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:20:48 INFO: new best model saved.\n","2024-04-09 17:20:50 INFO: Model saved to saved_models/depparse/en_ewt_charlm_parser_checkpoint.pt\n","2024-04-09 17:20:50 INFO: new model checkpoint saved.\n","2024-04-09 17:20:50 INFO: Training ended with 1000 steps.\n","2024-04-09 17:20:50 INFO: Best dev F1 = 85.61, at iteration = 1000\n","2024-04-09 17:20:50 INFO: Using default pretrain for language, found in /root/stanza_resources/en/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:20:50 INFO: Running dev depparse for UD_English-EWT with args ['--wordvec_dir', '../data/wordvec', '--eval_file', '../data/processed/depparse/en_ewt.dev.in.conllu', '--output_file', '/tmp/tmpyksixau1', '--gold_file', '../data/processed/depparse/en_ewt.dev.gold.conllu', '--lang', 'en', '--shorthand', 'en_ewt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/en/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'en_1billion', '--charlm_forward_file', '/root/stanza_resources/en/forward_charlm/1billion.pt', '--charlm_backward_file', '/root/stanza_resources/en/backward_charlm/1billion.pt', '--max_steps', '1000']\n","2024-04-09 17:20:50 INFO: Running parser in predict mode\n","2024-04-09 17:20:50 INFO: Loading model from: saved_models/depparse/en_ewt_charlm_parser.pt\n","2024-04-09 17:20:51 DEBUG: Loaded pretrain from /root/stanza_resources/en/pretrain/conll17.pt\n","2024-04-09 17:20:51 DEBUG: Depparse model loading charmodels: /root/stanza_resources/en/forward_charlm/1billion.pt and /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:20:51 DEBUG: Loading charlm from /root/stanza_resources/en/forward_charlm/1billion.pt\n","2024-04-09 17:20:51 DEBUG: Loading charlm from /root/stanza_resources/en/backward_charlm/1billion.pt\n","2024-04-09 17:20:51 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 17:20:51 INFO: Loading data with batch size 5000...\n","2024-04-09 17:20:54 DEBUG: 6 batches created.\n","2024-04-09 17:21:01 INFO: F1 scores for each dependency:\n","  Note that unlabeled attachment errors hurt the labeled attachment scores\n","         acl: p 0.6733 r 0.6121 f1 0.6413 (165 actual)\n","   acl:relcl: p 0.7310 r 0.6636 f1 0.6957 (217 actual)\n","       advcl: p 0.6142 r 0.6464 f1 0.6299 (362 actual)\n"," advcl:relcl: p 0.3333 r 0.1111 f1 0.1667 (9 actual)\n","      advmod: p 0.8414 r 0.8158 f1 0.8284 (1346 actual)\n","        amod: p 0.8797 r 0.8553 f1 0.8674 (1334 actual)\n","       appos: p 0.4505 r 0.5291 f1 0.4866 (172 actual)\n","         aux: p 0.9480 r 0.9733 f1 0.9605 (749 actual)\n","    aux:pass: p 0.8652 r 0.9506 f1 0.9059 (162 actual)\n","        case: p 0.9229 r 0.9399 f1 0.9313 (2012 actual)\n","          cc: p 0.8947 r 0.8969 f1 0.8958 (786 actual)\n","  cc:preconj: p 1.0000 r 0.7500 f1 0.8571 (12 actual)\n","       ccomp: p 0.6652 r 0.7487 f1 0.7045 (199 actual)\n","    compound: p 0.7397 r 0.8034 f1 0.7702 (941 actual)\n","compound:prt: p 0.5870 r 0.7297 f1 0.6506 (74 actual)\n","        conj: p 0.7402 r 0.7241 f1 0.7321 (917 actual)\n","         cop: p 0.8901 r 0.8844 f1 0.8873 (623 actual)\n","       csubj: p 0.6667 r 0.2051 f1 0.3137 (39 actual)\n"," csubj:outer: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n","         dep: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n","         det: p 0.9683 r 0.9677 f1 0.9680 (1828 actual)\n","  det:predet: p 0.8519 r 0.9583 f1 0.9020 (24 actual)\n","   discourse: p 0.7944 r 0.6911 f1 0.7391 (123 actual)\n","  dislocated: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n","        expl: p 0.8272 r 0.7701 f1 0.7976 (87 actual)\n","       fixed: p 0.9773 r 0.7288 f1 0.8350 (59 actual)\n","        flat: p 0.8025 r 0.8025 f1 0.8025 (238 actual)\n","    goeswith: p 1.0000 r 0.4545 f1 0.6250 (22 actual)\n","        iobj: p 0.7857 r 0.6027 f1 0.6822 (73 actual)\n","        list: p 0.1864 r 0.1467 f1 0.1642 (75 actual)\n","        mark: p 0.9408 r 0.9222 f1 0.9314 (758 actual)\n","        nmod: p 0.7273 r 0.7783 f1 0.7519 (812 actual)\n","  nmod:npmod: p 0.2500 r 0.0833 f1 0.1250 (12 actual)\n","   nmod:poss: p 0.9488 r 0.9488 f1 0.9488 (391 actual)\n","   nmod:tmod: p 0.7333 r 0.6471 f1 0.6875 (34 actual)\n","       nsubj: p 0.9115 r 0.9157 f1 0.9136 (1958 actual)\n"," nsubj:outer: p 0.6667 r 0.2727 f1 0.3871 (22 actual)\n","  nsubj:pass: p 0.7953 r 0.8774 f1 0.8344 (155 actual)\n","      nummod: p 0.8084 r 0.8498 f1 0.8286 (273 actual)\n","         obj: p 0.8692 r 0.9143 f1 0.8912 (1214 actual)\n","         obl: p 0.7620 r 0.7445 f1 0.7531 (1006 actual)\n","   obl:agent: p 0.5000 r 0.2500 f1 0.3333 (28 actual)\n","   obl:npmod: p 0.6522 r 0.3061 f1 0.4167 (49 actual)\n","    obl:tmod: p 0.6667 r 0.6452 f1 0.6557 (62 actual)\n","      orphan: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n","   parataxis: p 0.5183 r 0.3960 f1 0.4490 (250 actual)\n","       punct: p 0.8586 r 0.8612 f1 0.8599 (3061 actual)\n","  reparandum: p 0.0000 r 0.0000 f1 0.0000 (7 actual)\n","        root: p 0.9240 r 0.9240 f1 0.9240 (2001 actual)\n","    vocative: p 0.5714 r 0.3636 f1 0.4444 (22 actual)\n","       xcomp: p 0.8109 r 0.8602 f1 0.8348 (379 actual)\n","2024-04-09 17:21:03 INFO: LAS\tMLAS\tBLEX\n","2024-04-09 17:21:03 INFO: 85.61\t80.69\t81.82\n","2024-04-09 17:21:03 INFO: Parser score:\n","2024-04-09 17:21:03 INFO: en_ewt 85.61\n","2024-04-09 17:21:06 INFO: Finished running dev set on\n","UD_English-EWT\n","  UAS   LAS  CLAS  MLAS  BLEX\n","88.59 85.61 81.82 80.69 81.82\n"]}]},{"cell_type":"markdown","source":["##### IT"],"metadata":{"id":"1G193zPLEsBe"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_tokenizer_treebank UD_Italian-ISDT"],"metadata":{"id":"l2hQg-i3EsBe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710590270788,"user_tz":-60,"elapsed":51859,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"4d71a855-0318-459e-e554-3f13b532468f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-16 11:57:40 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py UD_Italian-ISDT\n","Preparing data for UD_Italian-ISDT: it_isdt, it\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-train.conllu and writing to ../data/processed/tokenize/it_isdt.train.gold.conllu\n","Augmented 140 quotes: Counter({'„”': 21, '″″': 18, '\"\"': 15, '「」': 14, '»«': 13, '““': 13, '””': 12, '„“': 12, '《》': 12, '«»': 10})\n","Swapped 'w1, w2' for 'w1 ,w2' 125 times\n","Added 159 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-dev.conllu and writing to ../data/processed/tokenize/it_isdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-test.conllu and writing to ../data/processed/tokenize/it_isdt.test.gold.conllu\n","Tokenizer labels written to ../data/processed/tokenize/it_isdt-ud-train.toklabels\n","  807 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/it_isdt-ud-train-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/it_isdt-ud-dev.toklabels\n","  91 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/it_isdt-ud-dev-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/it_isdt-ud-test.toklabels\n","  92 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/it_isdt-ud-test-mwt.json\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_tokenizer UD_Italian-ISDT --step 1000"],"metadata":{"id":"gIjMN5FqFJxf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710590313402,"user_tz":-60,"elapsed":37640,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a0898d57-1df9-426b-e5df-2a63fbe40936"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-16 11:57:59 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/training/run_tokenizer.py UD_Italian-ISDT --step 1000\n","2024-03-16 11:57:59 DEBUG: UD_Italian-ISDT: it_isdt\n","2024-03-16 11:57:59 INFO: Save file for it_isdt model: it_isdt_tokenizer.pt\n","2024-03-16 11:57:59 INFO: UD_Italian-ISDT: saved_models/tokenize/it_isdt_tokenizer.pt does not exist, training new model\n","2024-03-16 11:57:59 INFO: Running train step with args: ['--label_file', '../data/processed/tokenize/it_isdt-ud-train.toklabels', '--txt_file', '../data/processed/tokenize/it_isdt.train.txt', '--lang', 'it', '--max_seqlen', '400', '--mwt_json_file', '../data/processed/tokenize/it_isdt-ud-dev-mwt.json', '--dev_txt_file', '../data/processed/tokenize/it_isdt.dev.txt', '--dev_label_file', '../data/processed/tokenize/it_isdt-ud-dev.toklabels', '--dev_conll_gold', '../data/processed/tokenize/it_isdt.dev.gold.conllu', '--conll_file', '/tmp/tmpur1pn5ge', '--shorthand', 'it_isdt', '--step', '1000', '--save_name', 'it_isdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-16 11:58:00 INFO: Running tokenizer in train mode\n","2024-03-16 11:58:06 DEBUG: 13206 sentences loaded.\n","2024-03-16 11:58:06 INFO: Found mwts in the training data.  Setting use_mwt to True\n","2024-03-16 11:58:07 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-16 11:58:09 INFO: Step     20/  1000 Loss: 0.545\n","2024-03-16 11:58:09 INFO: Step     40/  1000 Loss: 0.437\n","2024-03-16 11:58:10 INFO: Step     60/  1000 Loss: 0.279\n","2024-03-16 11:58:10 INFO: Step     80/  1000 Loss: 0.190\n","2024-03-16 11:58:10 INFO: Step    100/  1000 Loss: 0.120\n","2024-03-16 11:58:10 INFO: Step    120/  1000 Loss: 0.082\n","2024-03-16 11:58:11 INFO: Step    140/  1000 Loss: 0.073\n","2024-03-16 11:58:11 INFO: Step    160/  1000 Loss: 0.067\n","2024-03-16 11:58:11 INFO: Step    180/  1000 Loss: 0.068\n","2024-03-16 11:58:11 INFO: Step    200/  1000 Loss: 0.063\n","2024-03-16 11:58:12 INFO: it_isdt: token F1 = 99.29, sentence F1 = 92.37, mwt F1 = 98.63\n","2024-03-16 11:58:12 INFO: Model saved to saved_models/tokenize/it_isdt_tokenizer.pt\n","2024-03-16 11:58:12 INFO: Dev score: 95.724\tNew best dev score!\n","2024-03-16 11:58:13 INFO: Step    220/  1000 Loss: 0.058\n","2024-03-16 11:58:13 INFO: Step    240/  1000 Loss: 0.043\n","2024-03-16 11:58:13 INFO: Step    260/  1000 Loss: 0.059\n","2024-03-16 11:58:13 INFO: Step    280/  1000 Loss: 0.049\n","2024-03-16 11:58:14 INFO: Step    300/  1000 Loss: 0.051\n","2024-03-16 11:58:14 INFO: Step    320/  1000 Loss: 0.045\n","2024-03-16 11:58:14 INFO: Step    340/  1000 Loss: 0.044\n","2024-03-16 11:58:14 INFO: Step    360/  1000 Loss: 0.041\n","2024-03-16 11:58:15 INFO: Step    380/  1000 Loss: 0.042\n","2024-03-16 11:58:15 INFO: Step    400/  1000 Loss: 0.039\n","2024-03-16 11:58:16 INFO: it_isdt: token F1 = 99.53, sentence F1 = 93.33, mwt F1 = 99.09\n","2024-03-16 11:58:16 INFO: Model saved to saved_models/tokenize/it_isdt_tokenizer.pt\n","2024-03-16 11:58:16 INFO: Dev score: 96.345\tNew best dev score!\n","2024-03-16 11:58:17 INFO: Step    420/  1000 Loss: 0.044\n","2024-03-16 11:58:17 INFO: Step    440/  1000 Loss: 0.039\n","2024-03-16 11:58:18 INFO: Step    460/  1000 Loss: 0.043\n","2024-03-16 11:58:18 INFO: Step    480/  1000 Loss: 0.038\n","2024-03-16 11:58:18 INFO: Step    500/  1000 Loss: 0.041\n","2024-03-16 11:58:18 INFO: Step    520/  1000 Loss: 0.044\n","2024-03-16 11:58:19 INFO: Step    540/  1000 Loss: 0.037\n","2024-03-16 11:58:19 INFO: Step    560/  1000 Loss: 0.036\n","2024-03-16 11:58:19 INFO: Step    580/  1000 Loss: 0.043\n","2024-03-16 11:58:19 INFO: Step    600/  1000 Loss: 0.042\n","2024-03-16 11:58:20 INFO: it_isdt: token F1 = 99.56, sentence F1 = 96.15, mwt F1 = 99.24\n","2024-03-16 11:58:20 INFO: Model saved to saved_models/tokenize/it_isdt_tokenizer.pt\n","2024-03-16 11:58:20 INFO: Dev score: 97.831\tNew best dev score!\n","2024-03-16 11:58:21 INFO: Step    620/  1000 Loss: 0.034\n","2024-03-16 11:58:21 INFO: Step    640/  1000 Loss: 0.035\n","2024-03-16 11:58:21 INFO: Step    660/  1000 Loss: 0.033\n","2024-03-16 11:58:21 INFO: Step    680/  1000 Loss: 0.041\n","2024-03-16 11:58:22 INFO: Step    700/  1000 Loss: 0.038\n","2024-03-16 11:58:22 INFO: Step    720/  1000 Loss: 0.038\n","2024-03-16 11:58:22 INFO: Step    740/  1000 Loss: 0.039\n","2024-03-16 11:58:22 INFO: Step    760/  1000 Loss: 0.033\n","2024-03-16 11:58:23 INFO: Step    780/  1000 Loss: 0.035\n","2024-03-16 11:58:23 INFO: Step    800/  1000 Loss: 0.034\n","2024-03-16 11:58:24 INFO: it_isdt: token F1 = 99.65, sentence F1 = 97.35, mwt F1 = 99.34\n","2024-03-16 11:58:24 INFO: Model saved to saved_models/tokenize/it_isdt_tokenizer.pt\n","2024-03-16 11:58:24 INFO: Dev score: 98.491\tNew best dev score!\n","2024-03-16 11:58:24 INFO: Step    820/  1000 Loss: 0.029\n","2024-03-16 11:58:24 INFO: Step    840/  1000 Loss: 0.033\n","2024-03-16 11:58:25 INFO: Step    860/  1000 Loss: 0.033\n","2024-03-16 11:58:25 INFO: Step    880/  1000 Loss: 0.033\n","2024-03-16 11:58:25 INFO: Step    900/  1000 Loss: 0.039\n","2024-03-16 11:58:25 INFO: Step    920/  1000 Loss: 0.032\n","2024-03-16 11:58:26 INFO: Step    940/  1000 Loss: 0.032\n","2024-03-16 11:58:26 INFO: Step    960/  1000 Loss: 0.036\n","2024-03-16 11:58:26 INFO: Step    980/  1000 Loss: 0.034\n","2024-03-16 11:58:26 INFO: Step   1000/  1000 Loss: 0.036\n","2024-03-16 11:58:27 INFO: it_isdt: token F1 = 99.68, sentence F1 = 96.94, mwt F1 = 99.41\n","2024-03-16 11:58:27 INFO: Dev score: 98.296\n","2024-03-16 11:58:27 INFO: Best dev score=0.9849059477343888 at step 800\n","2024-03-16 11:58:27 INFO: Running dev step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/it_isdt.dev.txt', '--lang', 'it', '--conll_file', '/tmp/tmpur1pn5ge', '--shorthand', 'it_isdt', '--mwt_json_file', '../data/processed/tokenize/it_isdt-ud-dev-mwt.json', '--step', '1000', '--save_name', 'it_isdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-16 11:58:27 INFO: Running tokenizer in predict mode\n","2024-03-16 11:58:27 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-16 11:58:29 INFO: OOV rate:  0.003% (     2/ 60586)\n","2024-03-16 11:58:30 INFO: Finished running dev set on\n","UD_Italian-ISDT\n","   Tokens Sentences     Words\n","    99.65     97.35     99.28\n","2024-03-16 11:58:30 INFO: Running test step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/it_isdt.test.txt', '--lang', 'it', '--conll_file', '/tmp/tmpur1pn5ge', '--shorthand', 'it_isdt', '--mwt_json_file', '../data/processed/tokenize/it_isdt-ud-test-mwt.json', '--step', '1000', '--save_name', 'it_isdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-16 11:58:30 INFO: Running tokenizer in predict mode\n","2024-03-16 11:58:30 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-16 11:58:31 INFO: OOV rate:  0.004% (     2/ 53359)\n","2024-03-16 11:58:31 INFO: Finished running test set on\n","UD_Italian-ISDT\n","   Tokens Sentences     Words\n","    99.81     98.76     99.49\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_pos_treebank UD_Italian-ISDT"],"metadata":{"id":"hVrzq1ZeFKDA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710590339393,"user_tz":-60,"elapsed":8826,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"6ed95ca6-f111-46f4-e9c1-fae635e0e38f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-16 11:58:53 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/datasets/prepare_pos_treebank.py UD_Italian-ISDT\n","Preparing data for UD_Italian-ISDT: it_isdt, it\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-train.conllu and writing to /tmp/tmps__y1fqn/it_isdt.train.gold.conllu\n","Augmented 140 quotes: Counter({'„”': 21, '″″': 18, '\"\"': 15, '「」': 14, '»«': 13, '““': 13, '””': 12, '„“': 12, '《》': 12, '«»': 10})\n","Swapped 'w1, w2' for 'w1 ,w2' 125 times\n","Added 159 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-dev.conllu and writing to /tmp/tmps__y1fqn/it_isdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-test.conllu and writing to /tmp/tmps__y1fqn/it_isdt.test.gold.conllu\n","Copying from /tmp/tmps__y1fqn/it_isdt.train.gold.conllu to ../data/processed/pos/it_isdt.train.in.conllu\n","Copying from /tmp/tmps__y1fqn/it_isdt.dev.gold.conllu to ../data/processed/pos/it_isdt.dev.in.conllu\n","Copying from /tmp/tmps__y1fqn/it_isdt.test.gold.conllu to ../data/processed/pos/it_isdt.test.in.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_pos UD_Italian-ISDT --max_steps 500"],"metadata":{"id":"REN4eEikFKNk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712684273158,"user_tz":-120,"elapsed":443656,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"3a8c337a-eea9-4393-93d8-cd4116fce2db"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-09 17:30:31 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_pos.py UD_Italian-ISDT --max_steps 500\n","2024-04-09 17:30:31 DEBUG: UD_Italian-ISDT: it_isdt\n","2024-04-09 17:30:31 INFO: Using model /root/stanza_resources/it/forward_charlm/conll17.pt for forward charlm\n","2024-04-09 17:30:31 INFO: Using model /root/stanza_resources/it/backward_charlm/conll17.pt for backward charlm\n","2024-04-09 17:30:31 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:30:31 INFO: UD_Italian-ISDT: saved_models/pos/it_isdt_charlm_tagger.pt does not exist, training new model\n","2024-04-09 17:30:31 INFO: Using model /root/stanza_resources/it/forward_charlm/conll17.pt for forward charlm\n","2024-04-09 17:30:31 INFO: Using model /root/stanza_resources/it/backward_charlm/conll17.pt for backward charlm\n","2024-04-09 17:30:31 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:30:31 INFO: Running train POS for UD_Italian-ISDT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/pos/it_isdt.train.in.conllu', '--output_file', '/tmp/tmpgv2ilkll', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'train', '--eval_file', '../data/processed/pos/it_isdt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--max_steps', '500']\n","2024-04-09 17:30:31 INFO: Running tagger in train mode\n","2024-04-09 17:30:31 INFO: Using pretrained contextualized char embedding\n","2024-04-09 17:30:31 INFO: Loading data with batch size 250...\n","2024-04-09 17:30:31 INFO: Reading ../data/processed/pos/it_isdt.train.in.conllu\n","2024-04-09 17:30:35 INFO: Train File ../data/processed/pos/it_isdt.train.in.conllu, Data Size: 13280\n","2024-04-09 17:30:48 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-04-09 17:30:55 INFO: Training tagger...\n","2024-04-09 17:30:55 DEBUG: POS model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-04-09 17:30:55 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-04-09 17:30:55 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-04-09 17:30:55 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 17:30:56 INFO: Evaluating the model every 100 steps...\n","2024-04-09 17:31:12 INFO: Finished STEP 20/500, loss = 5.093433 (0.510 sec/batch), lr: 0.003000\n","2024-04-09 17:31:27 INFO: Finished STEP 40/500, loss = 2.817125 (0.807 sec/batch), lr: 0.003000\n","2024-04-09 17:31:42 INFO: Finished STEP 60/500, loss = 1.856807 (0.621 sec/batch), lr: 0.003000\n","2024-04-09 17:31:58 INFO: Finished STEP 80/500, loss = 1.567479 (0.581 sec/batch), lr: 0.003000\n","2024-04-09 17:32:15 INFO: Finished STEP 100/500, loss = 1.325073 (0.562 sec/batch), lr: 0.003000\n","2024-04-09 17:32:15 INFO: Evaluating on dev set...\n","2024-04-09 17:32:18 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:32:18 INFO: 96.72\t96.44\t93.83\t92.46\n","2024-04-09 17:32:18 INFO: step 100: train_loss = 4.358659, dev_score = 0.9246\n","2024-04-09 17:32:18 INFO: Model saved to saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:32:18 INFO: new best model saved.\n","2024-04-09 17:32:32 INFO: Finished STEP 120/500, loss = 1.322115 (0.565 sec/batch), lr: 0.003000\n","2024-04-09 17:32:48 INFO: Finished STEP 140/500, loss = 1.248561 (0.529 sec/batch), lr: 0.003000\n","2024-04-09 17:33:04 INFO: Finished STEP 160/500, loss = 1.211368 (0.520 sec/batch), lr: 0.003000\n","2024-04-09 17:33:19 INFO: Finished STEP 180/500, loss = 1.080508 (1.251 sec/batch), lr: 0.003000\n","2024-04-09 17:33:36 INFO: Finished STEP 200/500, loss = 1.125742 (0.681 sec/batch), lr: 0.003000\n","2024-04-09 17:33:36 INFO: Evaluating on dev set...\n","2024-04-09 17:33:39 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:33:39 INFO: 97.63\t97.41\t96.09\t95.12\n","2024-04-09 17:33:39 INFO: step 200: train_loss = 1.203966, dev_score = 0.9512\n","2024-04-09 17:33:39 INFO: Model saved to saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:33:39 INFO: new best model saved.\n","2024-04-09 17:33:53 INFO: Finished STEP 220/500, loss = 1.017267 (0.559 sec/batch), lr: 0.003000\n","2024-04-09 17:34:10 INFO: Finished STEP 240/500, loss = 1.022276 (0.508 sec/batch), lr: 0.003000\n","2024-04-09 17:34:24 INFO: Finished STEP 260/500, loss = 0.986925 (0.612 sec/batch), lr: 0.003000\n","2024-04-09 17:34:43 INFO: Finished STEP 280/500, loss = 0.986606 (0.697 sec/batch), lr: 0.003000\n","2024-04-09 17:34:58 INFO: Finished STEP 300/500, loss = 0.943908 (0.616 sec/batch), lr: 0.003000\n","2024-04-09 17:34:58 INFO: Evaluating on dev set...\n","2024-04-09 17:35:00 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:35:00 INFO: 97.72\t97.64\t96.62\t95.70\n","2024-04-09 17:35:00 INFO: step 300: train_loss = 1.006256, dev_score = 0.9570\n","2024-04-09 17:35:00 INFO: Model saved to saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:35:00 INFO: new best model saved.\n","2024-04-09 17:35:15 INFO: Finished STEP 320/500, loss = 0.853579 (0.583 sec/batch), lr: 0.003000\n","2024-04-09 17:35:30 INFO: Finished STEP 340/500, loss = 0.923605 (0.522 sec/batch), lr: 0.003000\n","2024-04-09 17:35:45 INFO: Finished STEP 360/500, loss = 0.892226 (0.525 sec/batch), lr: 0.003000\n","2024-04-09 17:36:03 INFO: Finished STEP 380/500, loss = 0.928775 (0.540 sec/batch), lr: 0.003000\n","2024-04-09 17:36:18 INFO: Finished STEP 400/500, loss = 0.872687 (0.614 sec/batch), lr: 0.003000\n","2024-04-09 17:36:18 INFO: Evaluating on dev set...\n","2024-04-09 17:36:20 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:36:20 INFO: 97.88\t97.68\t97.13\t96.24\n","2024-04-09 17:36:20 INFO: step 400: train_loss = 0.918004, dev_score = 0.9624\n","2024-04-09 17:36:20 INFO: Model saved to saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:36:20 INFO: new best model saved.\n","2024-04-09 17:36:36 INFO: Finished STEP 420/500, loss = 0.920255 (0.594 sec/batch), lr: 0.003000\n","2024-04-09 17:36:51 INFO: Finished STEP 440/500, loss = 0.915007 (0.611 sec/batch), lr: 0.003000\n","2024-04-09 17:37:08 INFO: Finished STEP 460/500, loss = 0.825625 (0.938 sec/batch), lr: 0.003000\n","2024-04-09 17:37:24 INFO: Finished STEP 480/500, loss = 0.864209 (0.543 sec/batch), lr: 0.003000\n","2024-04-09 17:37:39 INFO: Finished STEP 500/500, loss = 0.764741 (0.533 sec/batch), lr: 0.003000\n","2024-04-09 17:37:39 INFO: Evaluating on dev set...\n","2024-04-09 17:37:42 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:37:42 INFO: 97.97\t97.82\t97.48\t96.60\n","2024-04-09 17:37:42 INFO: step 500: train_loss = 0.860070, dev_score = 0.9660\n","2024-04-09 17:37:42 INFO: Model saved to saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:37:42 INFO: new best model saved.\n","2024-04-09 17:37:42 INFO: Training ended with 500 steps.\n","2024-04-09 17:37:42 INFO: Best dev F1 = 96.60, at iteration = 500\n","2024-04-09 17:37:42 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-04-09 17:37:42 INFO: Running dev POS for UD_Italian-ISDT with args ['--wordvec_dir', '../data/wordvec', '--output_file', '/tmp/tmpgv2ilkll', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'predict', '--eval_file', '../data/processed/pos/it_isdt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--max_steps', '500']\n","2024-04-09 17:37:42 INFO: Running tagger in predict mode\n","2024-04-09 17:37:42 INFO: Loading model from: saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-04-09 17:37:42 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-04-09 17:37:42 DEBUG: POS model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-04-09 17:37:42 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-04-09 17:37:42 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-04-09 17:37:43 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-04-09 17:37:43 INFO: Loading data with batch size 250...\n","2024-04-09 17:37:43 INFO: Start evaluation...\n","2024-04-09 17:37:49 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-04-09 17:37:49 INFO: 97.97\t97.82\t97.48\t96.60\n","2024-04-09 17:37:49 INFO: POS Tagger score: it_isdt 96.60\n","2024-04-09 17:37:50 INFO: Finished running dev set on\n","UD_Italian-ISDT\n","   UPOS    XPOS  UFeats AllTags\n","  97.97   97.82   97.48   96.60\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_Italian-ISDT"],"metadata":{"id":"7VRupcjJFKbw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710591387475,"user_tz":-60,"elapsed":113542,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"134957b7-5274-4117-f5b8-04c69ed9ac49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-16 12:14:36 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/datasets/prepare_depparse_treebank.py UD_Italian-ISDT\n","2024-03-16 12:14:36 INFO: Using tagger model in saved_models/pos/it_isdt_charlm_tagger.pt for it_isdt\n","2024-03-16 12:14:36 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-16 12:14:36 INFO: Using model /root/stanza_resources/it/forward_charlm/conll17.pt for forward charlm\n","2024-03-16 12:14:36 INFO: Using model /root/stanza_resources/it/backward_charlm/conll17.pt for backward charlm\n","Preparing data for UD_Italian-ISDT: it_isdt, it\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-train.conllu and writing to /tmp/tmpoziz9yga/it_isdt.train.gold.conllu\n","Augmented 140 quotes: Counter({'„”': 21, '″″': 18, '\"\"': 15, '「」': 14, '»«': 13, '““': 13, '””': 12, '„“': 12, '《》': 12, '«»': 10})\n","Swapped 'w1, w2' for 'w1 ,w2' 125 times\n","Added 159 new sentences with asdf, zzzz -> asdf,zzzz\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-dev.conllu and writing to /tmp/tmpoziz9yga/it_isdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Italian-ISDT/it_isdt-ud-test.conllu and writing to /tmp/tmpoziz9yga/it_isdt.test.gold.conllu\n","2024-03-16 12:14:40 INFO: Running tagger to retag /tmp/tmpoziz9yga/it_isdt.train.gold.conllu to ../data/processed/depparse/it_isdt.train.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'it_isdt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--eval_file', '/tmp/tmpoziz9yga/it_isdt.train.gold.conllu', '--output_file', '../data/processed/depparse/it_isdt.train.in.conllu']\n","2024-03-16 12:14:41 INFO: Running tagger in predict mode\n","2024-03-16 12:14:41 INFO: Loading model from: saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-03-16 12:14:41 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-03-16 12:14:41 DEBUG: POS model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:14:41 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-03-16 12:14:41 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:14:42 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-16 12:14:42 INFO: Loading data with batch size 250...\n","2024-03-16 12:15:00 INFO: Start evaluation...\n","2024-03-16 12:16:11 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-16 12:16:11 INFO: 98.56\t98.46\t98.19\t97.60\n","2024-03-16 12:16:11 INFO: POS Tagger score: it_isdt 97.60\n","2024-03-16 12:16:11 INFO: Running tagger to retag /tmp/tmpoziz9yga/it_isdt.dev.gold.conllu to ../data/processed/depparse/it_isdt.dev.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'it_isdt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--eval_file', '/tmp/tmpoziz9yga/it_isdt.dev.gold.conllu', '--output_file', '../data/processed/depparse/it_isdt.dev.in.conllu']\n","2024-03-16 12:16:11 INFO: Running tagger in predict mode\n","2024-03-16 12:16:11 INFO: Loading model from: saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-03-16 12:16:11 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-03-16 12:16:11 DEBUG: POS model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:16:11 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-03-16 12:16:11 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:16:12 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-16 12:16:12 INFO: Loading data with batch size 250...\n","2024-03-16 12:16:12 INFO: Start evaluation...\n","2024-03-16 12:16:19 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-16 12:16:19 INFO: 98.21\t98.11\t97.78\t97.09\n","2024-03-16 12:16:19 INFO: POS Tagger score: it_isdt 97.09\n","2024-03-16 12:16:19 INFO: Running tagger to retag /tmp/tmpoziz9yga/it_isdt.test.gold.conllu to ../data/processed/depparse/it_isdt.test.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'it_isdt_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--eval_file', '/tmp/tmpoziz9yga/it_isdt.test.gold.conllu', '--output_file', '../data/processed/depparse/it_isdt.test.in.conllu']\n","2024-03-16 12:16:19 INFO: Running tagger in predict mode\n","2024-03-16 12:16:19 INFO: Loading model from: saved_models/pos/it_isdt_charlm_tagger.pt\n","2024-03-16 12:16:19 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-03-16 12:16:19 DEBUG: POS model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:16:19 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-03-16 12:16:19 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:16:20 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-16 12:16:20 INFO: Loading data with batch size 250...\n","2024-03-16 12:16:21 INFO: Start evaluation...\n","2024-03-16 12:16:25 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-16 12:16:25 INFO: 98.20\t98.07\t97.75\t97.21\n","2024-03-16 12:16:25 INFO: POS Tagger score: it_isdt 97.21\n","Copying from ../data/processed/depparse/it_isdt.dev.in.conllu to ../data/processed/depparse/it_isdt.dev.gold.conllu\n","Copying from ../data/processed/depparse/it_isdt.test.in.conllu to ../data/processed/depparse/it_isdt.test.gold.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_depparse UD_Italian-ISDT --max_steps 1000"],"metadata":{"id":"Rw4muBxCFKpv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710592157619,"user_tz":-60,"elapsed":762800,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"7bd4c2e2-028f-4a05-ff4b-f0575e6a9946"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-16 12:16:38 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/a/Stanza/stanza-train/stanza/stanza/utils/training/run_depparse.py UD_Italian-ISDT --max_steps 1000\n","2024-03-16 12:16:38 DEBUG: UD_Italian-ISDT: it_isdt\n","2024-03-16 12:16:38 INFO: Using model /root/stanza_resources/it/forward_charlm/conll17.pt for forward charlm\n","2024-03-16 12:16:38 INFO: Using model /root/stanza_resources/it/backward_charlm/conll17.pt for backward charlm\n","2024-03-16 12:16:38 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-16 12:16:38 INFO: UD_Italian-ISDT: saved_models/depparse/it_isdt_charlm_parser.pt does not exist, training new model\n","2024-03-16 12:16:38 INFO: Using model /root/stanza_resources/it/forward_charlm/conll17.pt for forward charlm\n","2024-03-16 12:16:38 INFO: Using model /root/stanza_resources/it/backward_charlm/conll17.pt for backward charlm\n","2024-03-16 12:16:38 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-16 12:16:38 INFO: Running train depparse for UD_Italian-ISDT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/depparse/it_isdt.train.in.conllu', '--eval_file', '../data/processed/depparse/it_isdt.dev.in.conllu', '--output_file', '/tmp/tmpiqqa2d5i', '--gold_file', '../data/processed/depparse/it_isdt.dev.gold.conllu', '--batch_size', '5000', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--max_steps', '1000']\n","2024-03-16 12:16:39 INFO: Running parser in train mode\n","2024-03-16 12:16:39 INFO: Using pretrained contextualized char embedding\n","2024-03-16 12:16:39 INFO: Loading data with batch size 5000...\n","2024-03-16 12:16:42 INFO: Original data size: 13280\n","2024-03-16 12:16:42 INFO: Augmented data size: 14427\n","2024-03-16 12:16:55 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-03-16 12:17:01 DEBUG: 64 batches created.\n","2024-03-16 12:17:02 DEBUG: 3 batches created.\n","2024-03-16 12:17:02 INFO: Training parser...\n","2024-03-16 12:17:02 DEBUG: Depparse model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:17:02 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-03-16 12:17:02 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:17:03 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-16 12:17:18 INFO: Finished STEP 20/1000, loss = 7.289875 (0.520 sec/batch), lr: 0.003000\n","2024-03-16 12:17:30 INFO: Finished STEP 40/1000, loss = 6.702160 (0.499 sec/batch), lr: 0.003000\n","2024-03-16 12:17:42 INFO: Finished STEP 60/1000, loss = 5.424966 (0.432 sec/batch), lr: 0.003000\n","2024-03-16 12:17:55 INFO: Finished STEP 80/1000, loss = 6.154058 (0.429 sec/batch), lr: 0.003000\n","2024-03-16 12:18:08 INFO: Finished STEP 100/1000, loss = 5.089869 (0.614 sec/batch), lr: 0.003000\n","2024-03-16 12:18:08 INFO: Evaluating on dev set...\n","2024-03-16 12:18:12 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:18:12 INFO: 32.36\t11.38\t35.00\n","2024-03-16 12:18:12 INFO: step 100: train_loss = 13.751255, dev_score = 0.3236\n","2024-03-16 12:18:13 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:18:13 INFO: new best model saved.\n","2024-03-16 12:18:14 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:18:14 INFO: new model checkpoint saved.\n","2024-03-16 12:18:28 INFO: Finished STEP 120/1000, loss = 4.297572 (0.391 sec/batch), lr: 0.003000\n","2024-03-16 12:18:40 INFO: Finished STEP 140/1000, loss = 3.340072 (0.401 sec/batch), lr: 0.003000\n","2024-03-16 12:18:53 INFO: Finished STEP 160/1000, loss = 3.248682 (0.516 sec/batch), lr: 0.003000\n","2024-03-16 12:19:06 INFO: Finished STEP 180/1000, loss = 3.042123 (0.532 sec/batch), lr: 0.003000\n","2024-03-16 12:19:21 INFO: Finished STEP 200/1000, loss = 2.959103 (0.518 sec/batch), lr: 0.003000\n","2024-03-16 12:19:21 INFO: Evaluating on dev set...\n","2024-03-16 12:19:24 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:19:24 INFO: 66.53\t48.62\t50.65\n","2024-03-16 12:19:24 INFO: step 200: train_loss = 4.019110, dev_score = 0.6653\n","2024-03-16 12:19:24 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:19:24 INFO: new best model saved.\n","2024-03-16 12:19:29 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:19:29 INFO: new model checkpoint saved.\n","2024-03-16 12:19:42 INFO: Finished STEP 220/1000, loss = 3.362679 (0.743 sec/batch), lr: 0.003000\n","2024-03-16 12:19:57 INFO: Finished STEP 240/1000, loss = 3.132994 (0.647 sec/batch), lr: 0.003000\n","2024-03-16 12:20:10 INFO: Finished STEP 260/1000, loss = 3.338323 (0.832 sec/batch), lr: 0.003000\n","2024-03-16 12:20:23 INFO: Finished STEP 280/1000, loss = 2.816835 (0.555 sec/batch), lr: 0.003000\n","2024-03-16 12:20:36 INFO: Finished STEP 300/1000, loss = 1.717533 (0.379 sec/batch), lr: 0.003000\n","2024-03-16 12:20:36 INFO: Evaluating on dev set...\n","2024-03-16 12:20:39 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:20:39 INFO: 76.32\t64.11\t65.73\n","2024-03-16 12:20:39 INFO: step 300: train_loss = 2.829427, dev_score = 0.7632\n","2024-03-16 12:20:39 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:20:39 INFO: new best model saved.\n","2024-03-16 12:20:43 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:20:43 INFO: new model checkpoint saved.\n","2024-03-16 12:20:56 INFO: Finished STEP 320/1000, loss = 2.079200 (0.416 sec/batch), lr: 0.003000\n","2024-03-16 12:21:10 INFO: Finished STEP 340/1000, loss = 1.775226 (0.524 sec/batch), lr: 0.003000\n","2024-03-16 12:21:23 INFO: Finished STEP 360/1000, loss = 2.507719 (0.524 sec/batch), lr: 0.003000\n","2024-03-16 12:21:35 INFO: Finished STEP 380/1000, loss = 1.529313 (0.436 sec/batch), lr: 0.003000\n","2024-03-16 12:21:50 INFO: Finished STEP 400/1000, loss = 2.083428 (0.520 sec/batch), lr: 0.003000\n","2024-03-16 12:21:50 INFO: Evaluating on dev set...\n","2024-03-16 12:21:52 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:21:52 INFO: 80.58\t70.87\t72.33\n","2024-03-16 12:21:52 INFO: step 400: train_loss = 2.292111, dev_score = 0.8058\n","2024-03-16 12:21:52 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:21:52 INFO: new best model saved.\n","2024-03-16 12:21:54 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:21:54 INFO: new model checkpoint saved.\n","2024-03-16 12:22:07 INFO: Finished STEP 420/1000, loss = 2.242893 (0.559 sec/batch), lr: 0.003000\n","2024-03-16 12:22:21 INFO: Finished STEP 440/1000, loss = 2.043287 (0.546 sec/batch), lr: 0.003000\n","2024-03-16 12:22:33 INFO: Finished STEP 460/1000, loss = 1.819642 (0.561 sec/batch), lr: 0.003000\n","2024-03-16 12:22:46 INFO: Finished STEP 480/1000, loss = 1.092932 (0.496 sec/batch), lr: 0.003000\n","2024-03-16 12:23:00 INFO: Finished STEP 500/1000, loss = 1.606908 (0.450 sec/batch), lr: 0.003000\n","2024-03-16 12:23:00 INFO: Evaluating on dev set...\n","2024-03-16 12:23:02 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:23:02 INFO: 83.56\t75.59\t76.46\n","2024-03-16 12:23:02 INFO: step 500: train_loss = 2.268860, dev_score = 0.8356\n","2024-03-16 12:23:03 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:23:03 INFO: new best model saved.\n","2024-03-16 12:23:05 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:23:05 INFO: new model checkpoint saved.\n","2024-03-16 12:23:19 INFO: Finished STEP 520/1000, loss = 2.477646 (0.650 sec/batch), lr: 0.003000\n","2024-03-16 12:23:33 INFO: Finished STEP 540/1000, loss = 1.340457 (0.387 sec/batch), lr: 0.003000\n","2024-03-16 12:23:47 INFO: Finished STEP 560/1000, loss = 19.150381 (1.439 sec/batch), lr: 0.003000\n","2024-03-16 12:23:59 INFO: Finished STEP 580/1000, loss = 1.325263 (0.371 sec/batch), lr: 0.003000\n","2024-03-16 12:24:12 INFO: Finished STEP 600/1000, loss = 1.009063 (0.496 sec/batch), lr: 0.003000\n","2024-03-16 12:24:12 INFO: Evaluating on dev set...\n","2024-03-16 12:24:14 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:24:14 INFO: 84.41\t77.99\t79.02\n","2024-03-16 12:24:14 INFO: step 600: train_loss = 1.862686, dev_score = 0.8441\n","2024-03-16 12:24:15 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:24:15 INFO: new best model saved.\n","2024-03-16 12:24:16 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:24:16 INFO: new model checkpoint saved.\n","2024-03-16 12:24:29 INFO: Finished STEP 620/1000, loss = 1.912113 (0.521 sec/batch), lr: 0.003000\n","2024-03-16 12:24:43 INFO: Finished STEP 640/1000, loss = 1.057247 (0.460 sec/batch), lr: 0.003000\n","2024-03-16 12:24:55 INFO: Finished STEP 660/1000, loss = 1.527643 (0.473 sec/batch), lr: 0.003000\n","2024-03-16 12:25:10 INFO: Finished STEP 680/1000, loss = 2.155262 (0.737 sec/batch), lr: 0.003000\n","2024-03-16 12:25:23 INFO: Finished STEP 700/1000, loss = 1.704605 (0.386 sec/batch), lr: 0.003000\n","2024-03-16 12:25:23 INFO: Evaluating on dev set...\n","2024-03-16 12:25:26 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:25:26 INFO: 85.99\t79.53\t80.47\n","2024-03-16 12:25:26 INFO: step 700: train_loss = 1.937784, dev_score = 0.8599\n","2024-03-16 12:25:27 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:25:27 INFO: new best model saved.\n","2024-03-16 12:25:28 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:25:28 INFO: new model checkpoint saved.\n","2024-03-16 12:25:42 INFO: Finished STEP 720/1000, loss = 1.135635 (0.471 sec/batch), lr: 0.003000\n","2024-03-16 12:25:55 INFO: Finished STEP 740/1000, loss = 1.433011 (0.504 sec/batch), lr: 0.003000\n","2024-03-16 12:26:08 INFO: Finished STEP 760/1000, loss = 1.674940 (0.449 sec/batch), lr: 0.003000\n","2024-03-16 12:26:21 INFO: Finished STEP 780/1000, loss = 2.159946 (0.693 sec/batch), lr: 0.003000\n","2024-03-16 12:26:34 INFO: Finished STEP 800/1000, loss = 2.388945 (0.817 sec/batch), lr: 0.003000\n","2024-03-16 12:26:34 INFO: Evaluating on dev set...\n","2024-03-16 12:26:38 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:26:38 INFO: 86.60\t80.80\t81.58\n","2024-03-16 12:26:38 INFO: step 800: train_loss = 1.677967, dev_score = 0.8660\n","2024-03-16 12:26:38 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:26:38 INFO: new best model saved.\n","2024-03-16 12:26:39 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:26:39 INFO: new model checkpoint saved.\n","2024-03-16 12:26:53 INFO: Finished STEP 820/1000, loss = 17.858278 (1.467 sec/batch), lr: 0.003000\n","2024-03-16 12:27:06 INFO: Finished STEP 840/1000, loss = 1.143545 (0.511 sec/batch), lr: 0.003000\n","2024-03-16 12:27:19 INFO: Finished STEP 860/1000, loss = 1.444636 (0.492 sec/batch), lr: 0.003000\n","2024-03-16 12:27:31 INFO: Finished STEP 880/1000, loss = 1.311913 (0.500 sec/batch), lr: 0.003000\n","2024-03-16 12:27:45 INFO: Finished STEP 900/1000, loss = 1.512429 (0.515 sec/batch), lr: 0.003000\n","2024-03-16 12:27:45 INFO: Evaluating on dev set...\n","2024-03-16 12:27:48 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:27:48 INFO: 87.53\t82.05\t82.89\n","2024-03-16 12:27:48 INFO: step 900: train_loss = 1.718944, dev_score = 0.8753\n","2024-03-16 12:27:48 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:27:48 INFO: new best model saved.\n","2024-03-16 12:27:53 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:27:53 INFO: new model checkpoint saved.\n","2024-03-16 12:28:06 INFO: Finished STEP 920/1000, loss = 1.251533 (0.504 sec/batch), lr: 0.003000\n","2024-03-16 12:28:22 INFO: Finished STEP 940/1000, loss = 1.467526 (0.570 sec/batch), lr: 0.003000\n","2024-03-16 12:28:34 INFO: Finished STEP 960/1000, loss = 1.190571 (0.505 sec/batch), lr: 0.003000\n","2024-03-16 12:28:47 INFO: Finished STEP 980/1000, loss = 1.132850 (0.450 sec/batch), lr: 0.003000\n","2024-03-16 12:29:00 INFO: Finished STEP 1000/1000, loss = 1.514111 (0.583 sec/batch), lr: 0.003000\n","2024-03-16 12:29:00 INFO: Evaluating on dev set...\n","2024-03-16 12:29:02 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:29:02 INFO: 87.64\t82.13\t82.90\n","2024-03-16 12:29:02 INFO: step 1000: train_loss = 1.494424, dev_score = 0.8764\n","2024-03-16 12:29:03 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:29:03 INFO: new best model saved.\n","2024-03-16 12:29:07 INFO: Model saved to saved_models/depparse/it_isdt_charlm_parser_checkpoint.pt\n","2024-03-16 12:29:07 INFO: new model checkpoint saved.\n","2024-03-16 12:29:07 INFO: Training ended with 1000 steps.\n","2024-03-16 12:29:07 INFO: Best dev F1 = 87.64, at iteration = 1000\n","2024-03-16 12:29:07 INFO: Using default pretrain for language, found in /root/stanza_resources/it/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-16 12:29:07 INFO: Running dev depparse for UD_Italian-ISDT with args ['--wordvec_dir', '../data/wordvec', '--eval_file', '../data/processed/depparse/it_isdt.dev.in.conllu', '--output_file', '/tmp/tmpiqqa2d5i', '--gold_file', '../data/processed/depparse/it_isdt.dev.gold.conllu', '--lang', 'it', '--shorthand', 'it_isdt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/it/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'it_conll17', '--charlm_forward_file', '/root/stanza_resources/it/forward_charlm/conll17.pt', '--charlm_backward_file', '/root/stanza_resources/it/backward_charlm/conll17.pt', '--max_steps', '1000']\n","2024-03-16 12:29:07 INFO: Running parser in predict mode\n","2024-03-16 12:29:07 INFO: Loading model from: saved_models/depparse/it_isdt_charlm_parser.pt\n","2024-03-16 12:29:07 DEBUG: Loaded pretrain from /root/stanza_resources/it/pretrain/conll17.pt\n","2024-03-16 12:29:07 DEBUG: Depparse model loading charmodels: /root/stanza_resources/it/forward_charlm/conll17.pt and /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:29:07 DEBUG: Loading charlm from /root/stanza_resources/it/forward_charlm/conll17.pt\n","2024-03-16 12:29:08 DEBUG: Loading charlm from /root/stanza_resources/it/backward_charlm/conll17.pt\n","2024-03-16 12:29:08 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-16 12:29:08 INFO: Loading data with batch size 5000...\n","2024-03-16 12:29:09 DEBUG: 3 batches created.\n","2024-03-16 12:29:11 INFO: F1 scores for each dependency:\n","  Note that unlabeled attachment errors hurt the labeled attachment scores\n","         acl: p 0.6286 r 0.5739 f1 0.6000 (115 actual)\n","   acl:relcl: p 0.7442 r 0.6957 f1 0.7191 (138 actual)\n","       advcl: p 0.6214 r 0.6170 f1 0.6192 (141 actual)\n","      advmod: p 0.8420 r 0.8535 f1 0.8477 (437 actual)\n","        amod: p 0.9335 r 0.9055 f1 0.9193 (667 actual)\n","       appos: p 0.5000 r 0.4103 f1 0.4507 (39 actual)\n","         aux: p 0.9524 r 0.9217 f1 0.9368 (217 actual)\n","    aux:pass: p 0.8276 r 0.9114 f1 0.8675 (79 actual)\n","        case: p 0.9843 r 0.9890 f1 0.9866 (1643 actual)\n","          cc: p 0.9497 r 0.9264 f1 0.9379 (326 actual)\n","       ccomp: p 0.6230 r 0.6129 f1 0.6179 (62 actual)\n","    compound: p 0.6071 r 0.6538 f1 0.6296 (26 actual)\n","        conj: p 0.6787 r 0.7649 f1 0.7192 (370 actual)\n","         cop: p 0.8433 r 0.8968 f1 0.8692 (126 actual)\n","       csubj: p 0.6250 r 0.3846 f1 0.4762 (13 actual)\n","         det: p 0.9835 r 0.9867 f1 0.9851 (1809 actual)\n","    det:poss: p 0.9855 r 1.0000 f1 0.9927 (68 actual)\n","  det:predet: p 0.9474 r 1.0000 f1 0.9730 (18 actual)\n","   discourse: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n","        expl: p 0.7154 r 0.9688 f1 0.8230 (96 actual)\n"," expl:impers: p 1.0000 r 0.2222 f1 0.3636 (9 actual)\n","   expl:pass: p 1.0000 r 0.3077 f1 0.4706 (13 actual)\n","       fixed: p 0.9444 r 0.8293 f1 0.8831 (41 actual)\n","        flat: p 1.0000 r 1.0000 f1 1.0000 (14 actual)\n","flat:foreign: p 0.0000 r 0.0000 f1 0.0000 (3 actual)\n","   flat:name: p 0.9236 r 0.9177 f1 0.9206 (158 actual)\n","        iobj: p 0.8235 r 0.5385 f1 0.6512 (26 actual)\n","        mark: p 0.9237 r 0.9504 f1 0.9369 (242 actual)\n","        nmod: p 0.8144 r 0.8127 f1 0.8135 (977 actual)\n","       nsubj: p 0.8789 r 0.8263 f1 0.8517 (518 actual)\n","  nsubj:pass: p 0.7113 r 0.8519 f1 0.7753 (81 actual)\n","      nummod: p 0.9111 r 0.8913 f1 0.9011 (184 actual)\n","         obj: p 0.8026 r 0.8937 f1 0.8457 (414 actual)\n","         obl: p 0.8320 r 0.7822 f1 0.8063 (684 actual)\n","   obl:agent: p 0.7200 r 0.8571 f1 0.7826 (42 actual)\n","      orphan: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n","   parataxis: p 0.5833 r 0.2258 f1 0.3256 (31 actual)\n","       punct: p 0.7573 r 0.7573 f1 0.7573 (1413 actual)\n","        root: p 0.9309 r 0.9309 f1 0.9309 (564 actual)\n","    vocative: p 0.2500 r 0.3333 f1 0.2857 (3 actual)\n","       xcomp: p 0.6224 r 0.6354 f1 0.6289 (96 actual)\n","2024-03-16 12:29:14 INFO: LAS\tMLAS\tBLEX\n","2024-03-16 12:29:14 INFO: 87.64\t82.13\t82.90\n","2024-03-16 12:29:14 INFO: Parser score:\n","2024-03-16 12:29:14 INFO: it_isdt 87.64\n","2024-03-16 12:29:15 INFO: Finished running dev set on\n","UD_Italian-ISDT\n","  UAS   LAS  CLAS  MLAS  BLEX\n","90.22 87.64 82.90 82.13 82.90\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"JKfXXg-TEwmX"}},{"cell_type":"code","source":["# Función para imprimir por pantalla la evaluación, como el conll18_ud_eval tiene esta implementación en main,\n","# se hace un wrapper para emplearlo como función fuera del script\n","def print_eval(verbose:bool, counts:bool, evaluation):\n","  if not verbose and not counts:\n","    print(\"LAS F1 Score: {:.2f}\".format(100 * evaluation[\"LAS\"].f1))\n","    print(\"MLAS Score: {:.2f}\".format(100 * evaluation[\"MLAS\"].f1))\n","    print(\"BLEX Score: {:.2f}\".format(100 * evaluation[\"BLEX\"].f1))\n","  else:\n","    if counts:\n","      print(\"Metric     | Correct   |      Gold | Predicted | Aligned\")\n","    else:\n","      print(\"Metric     | Precision |    Recall |  F1 Score | AligndAcc\")\n","    print(\"-----------+-----------+-----------+-----------+-----------\")\n","    for metric in[\"Tokens\", \"Sentences\", \"Words\", \"UPOS\", \"XPOS\", \"UFeats\", \"AllTags\", \"Lemmas\", \"UAS\", \"LAS\", \"CLAS\", \"MLAS\", \"BLEX\"]:\n","      if counts:\n","        print(\"{:11}|{:10} |{:10} |{:10} |{:10}\".format(\n","        metric,\n","        evaluation[metric].correct,\n","        evaluation[metric].gold_total,\n","        evaluation[metric].system_total,\n","        evaluation[metric].aligned_total or (evaluation[metric].correct if metric == \"Words\" else \"\")\n","        ))\n","      else:\n","        print(\"{:11}|{:10.2f} |{:10.2f} |{:10.2f} |{}\".format(\n","        metric,\n","        100 * evaluation[metric].precision,\n","        100 * evaluation[metric].recall,\n","        100 * evaluation[metric].f1,\n","        \"{:10.2f}\".format(100 * evaluation[metric].aligned_accuracy) if evaluation[metric].aligned_accuracy is not None else \"\"\n","        ))"],"metadata":{"id":"gNft7HnhymVn","executionInfo":{"status":"ok","timestamp":1712683608086,"user_tz":-120,"elapsed":231,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/PLN/3')\n","import conll18_ud_eval as conll"],"metadata":{"id":"arlULaLfj-IJ","executionInfo":{"status":"ok","timestamp":1712683615666,"user_tz":-120,"elapsed":241,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"SsZunAluEwmZ"}},{"cell_type":"code","source":["!pip install spacy_conll"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gL-yDL5-rq5e","executionInfo":{"status":"ok","timestamp":1710252452770,"user_tz":-60,"elapsed":10210,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"0eb2da01-cb2d-4bcb-9922-0d4edb06b70d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spacy_conll\n","  Downloading spacy_conll-3.4.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from spacy_conll) (3.7.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (4.66.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.6.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.25.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->spacy_conll) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->spacy_conll) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=3.0.1->spacy_conll) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.0.1->spacy_conll) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0.1->spacy_conll) (2.1.5)\n","Installing collected packages: spacy_conll\n","Successfully installed spacy_conll-3.4.0\n"]}]},{"cell_type":"code","source":["import spacy_conll"],"metadata":{"id":"9cTKcMCHsTsO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### EN"],"metadata":{"id":"F4mD2Nx4Ewma"}},{"cell_type":"code","source":["nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/Trained/model-best\")\n","config = {\"include_headers\": True}\n","nlp.add_pipe(\"conll_formatter\", config=config, last=True)"],"metadata":{"id":"nSpv2fhcEwmb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710192924930,"user_tz":-60,"elapsed":1147,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f72c0c7c-2f0c-4211-b6f5-94604f459f43"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConllFormatter(conversion_maps=None, ext_names={'conll_str': 'conll_str', 'conll': 'conll', 'conll_pd': 'conll_pd'}, field_names={'ID': 'ID', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'UPOS': 'UPOS', 'XPOS': 'XPOS', 'FEATS': 'FEATS', 'HEAD': 'HEAD', 'DEPREL': 'DEPREL', 'DEPS': 'DEPS', 'MISC': 'MISC'}, include_headers=True, disable_pandas=False)"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/EN/en_ewt_gold_test.conllu\""],"metadata":{"id":"Nv2mOoNazVL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"L8VPUscqrdUU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  of.write(doc._.conll_str)\n","  of.write('\\n')"],"metadata":{"id":"2hK9rS29tLio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"Si4NNbKtytuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IO-sQqUEzc7h","executionInfo":{"status":"ok","timestamp":1710193092839,"user_tz":-60,"elapsed":223,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"d9f6ef06-c7ff-497a-d89a-d438b3a5d968"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     24031 |     24740 |     25511 |          \n","Sentences  |      1448 |      2077 |      2024 |          \n","Words      |     24647 |     25094 |     25511 |     24647\n","UPOS       |     23016 |     25094 |     25511 |     24647\n","XPOS       |     22509 |     25094 |     25511 |     24647\n","UFeats     |     23122 |     25094 |     25511 |     24647\n","AllTags    |     22077 |     25094 |     25511 |     24647\n","Lemmas     |     23376 |     25094 |     25511 |     24647\n","UAS        |     20405 |     25094 |     25511 |     24647\n","LAS        |     17799 |     25094 |     25511 |     24647\n","CLAS       |      9536 |     15177 |     13330 |     14883\n","MLAS       |      8598 |     15177 |     13330 |     14883\n","BLEX       |      9126 |     15177 |     13330 |     14883\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     94.20 |     97.13 |     95.64 |\n","Sentences  |     71.54 |     69.72 |     70.62 |\n","Words      |     96.61 |     98.22 |     97.41 |\n","UPOS       |     90.22 |     91.72 |     90.96 |     93.38\n","XPOS       |     88.23 |     89.70 |     88.96 |     91.33\n","UFeats     |     90.64 |     92.14 |     91.38 |     93.81\n","AllTags    |     86.54 |     87.98 |     87.25 |     89.57\n","Lemmas     |     91.63 |     93.15 |     92.39 |     94.84\n","UAS        |     79.99 |     81.31 |     80.64 |     82.79\n","LAS        |     69.77 |     70.93 |     70.34 |     72.22\n","CLAS       |     71.54 |     62.83 |     66.90 |     64.07\n","MLAS       |     64.50 |     56.65 |     60.32 |     57.77\n","BLEX       |     68.46 |     60.13 |     64.03 |     61.32\n"]}]},{"cell_type":"markdown","source":["##### IT"],"metadata":{"id":"x4xf96bcEwmb"}},{"cell_type":"code","source":["nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/Trained/model-best\")\n","config = {\"include_headers\": True}\n","nlp.add_pipe(\"conll_formatter\", config=config, last=True)"],"metadata":{"id":"EjYNzmE0Ewmc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710252726872,"user_tz":-60,"elapsed":688,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"9f41d9be-837d-4038-c96b-bedd49bd5f95"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConllFormatter(conversion_maps=None, ext_names={'conll_str': 'conll_str', 'conll': 'conll', 'conll_pd': 'conll_pd'}, field_names={'ID': 'ID', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'UPOS': 'UPOS', 'XPOS': 'XPOS', 'FEATS': 'FEATS', 'HEAD': 'HEAD', 'DEPREL': 'DEPREL', 'DEPS': 'DEPS', 'MISC': 'MISC'}, include_headers=True, disable_pandas=False)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/a/Spacy/IT/it_isdt_gold_test.conllu\""],"metadata":{"id":"OKxgzrfn_hrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"0J4dyZ8_APqb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  of.write(doc._.conll_str)\n","  of.write('\\n')"],"metadata":{"id":"-zc0VRTLAThI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"3IAh3sMUAUCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtTlcs8OAXnp","executionInfo":{"status":"ok","timestamp":1710252900698,"user_tz":-60,"elapsed":194,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"d66510b4-d0c2-43f9-817a-d543cbcd3fb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |      9665 |      9680 |      9674 |          \n","Sentences  |       478 |       482 |       486 |          \n","Words      |      8929 |     10417 |      9674 |      8929\n","UPOS       |      8654 |     10417 |      9674 |      8929\n","XPOS       |      8627 |     10417 |      9674 |      8929\n","UFeats     |      8649 |     10417 |      9674 |      8929\n","AllTags    |      8521 |     10417 |      9674 |      8929\n","Lemmas     |      8657 |     10417 |      9674 |      8929\n","UAS        |      7756 |     10417 |      9674 |      8929\n","LAS        |      7062 |     10417 |      9674 |      8929\n","CLAS       |      3579 |      5133 |      4568 |      5021\n","MLAS       |      2874 |      5133 |      4568 |      5021\n","BLEX       |      3452 |      5133 |      4568 |      5021\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.91 |     99.85 |     99.88 |\n","Sentences  |     98.35 |     99.17 |     98.76 |\n","Words      |     92.30 |     85.72 |     88.89 |\n","UPOS       |     89.46 |     83.08 |     86.15 |     96.92\n","XPOS       |     89.18 |     82.82 |     85.88 |     96.62\n","UFeats     |     89.40 |     83.03 |     86.10 |     96.86\n","AllTags    |     88.08 |     81.80 |     84.82 |     95.43\n","Lemmas     |     89.49 |     83.10 |     86.18 |     96.95\n","UAS        |     80.17 |     74.46 |     77.21 |     86.86\n","LAS        |     73.00 |     67.79 |     70.30 |     79.09\n","CLAS       |     78.35 |     69.73 |     73.79 |     71.28\n","MLAS       |     62.92 |     55.99 |     59.25 |     57.24\n","BLEX       |     75.57 |     67.25 |     71.17 |     68.75\n"]}]},{"cell_type":"markdown","source":["#### Stanza"],"metadata":{"id":"WNGMaGviEwmc"}},{"cell_type":"code","source":["from stanza.utils.conll import CoNLL"],"metadata":{"id":"JQbMLCIW5lYd","executionInfo":{"status":"ok","timestamp":1712683629409,"user_tz":-120,"elapsed":251,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["##### EN"],"metadata":{"id":"xcGTck8-Ewmc"}},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/udbase/UD_English-EWT/en_ewt-ud-test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/a/Stanza/EN_output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/processed/depparse/en_ewt.test.gold.conllu\""],"metadata":{"id":"1rUNnDapkHbH","executionInfo":{"status":"ok","timestamp":1712683543413,"user_tz":-120,"elapsed":232,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["nlp = stanza.Pipeline('en', processors='tokenize,pos,lemma,depparse', use_gpu=True,\n","                      tokenize_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/tokenize/en_ewt_tokenizer.pt',\n","                      pos_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/pos/en_ewt_charlm_tagger.pt',\n","                      depparse_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/depparse/en_ewt_charlm_parser.pt')"],"metadata":{"id":"EYLDYxbuEwmc","colab":{"base_uri":"https://localhost:8080/","height":584,"referenced_widgets":["f4d59602bc954acf8c7655a46cb90a62","5c5ee07ec6f04a20a1191deb3d3e4433","f39bc92762424d7b90578ad27aea6cfb","7cb2ee6f762c4543aaf4d0c3b7accc83","eeff787662374cfeaec6eda78ae2316d","74dc4dbad3ec404f91e4c7504bb39ac3","55c79d28eca747bda2b95c646cc8e1af","e8c3300954b842c397addaba3a0c0838","d822cdbb879c45d7aff9d7ad6f40f104","d369392d35fd4442bdfe6c839f854bb1","36ebe0fec7474b71b7b427e24f2f28b6","9fdbc387cfbd4d2cac947bf9adab450f","7192a62689f84eeea3f3c09b67a03057","8839fdc829a74229bfabb8d68cc604d2","a7fa62cc299f4b62bf3186d61a063e87","471cc6408f274dfa9590f59b0f950d38","7622f296092d41c5b81147af14216a48","942b6d893d084bb3bd8f421394cf33ef","5dbc258d8de840f991287c2d965483f5","74386b8e349c4fb0856b7daba873902c","860b1ed750594136b9dead5cfe8314f8","1a8a9b089e1845949530bc9b5a0b0b71","b6f2d90b12274b0bbd6896a8b9b853a0","253c81d1d105447a8ec8cf4e073f4923","a90993f10612441fac9270b1b84256b9","e17456ae56cf4a27b81785be9261fab9","5e3f7adab11a4e2c9e0b8ed3946ca818","eee1b13d5c2046eebc8506b65fb30431","0303000f8b0c463a8b1c480e7bcb8872","27c9de3071a34ea086d0e4acf0cb67c3","21240e9a396e47f485ebe48c155f983a","025f602258bf475ba42212007eba1c1f","6124840ff9bd4411bf5842cb60e39585","9acedf82f49f48c585ec58540310e374","9096ec9d7aaf4251865a660c6de4efb5","d6b9c893f57143938c44201dc6a538a5","2c284a2e97b44480a2faad5027c79e32","cdff387092074444b52117f1aca35558","462e1d41b40c4e9cbd7749b326a79d70","87f8a31b30df40c8b36c19d5e36405fe","18e329d1be494f8bb539143d38f4d935","d172b2de5953401a9f03caff3af9781e","f9ea9bcd04784e42ace35b11cf9113ae","e97e91b3231b4667a332548f2426e606","d3881b394d1d4e4fa0f54972bd82f25e","35aa2d2b3c7343ddab32bf10df25ab73","477d0c4d1fe5485382d8a5d50b60fda1","58993144f29f4ce281bb42b2c1a4202c","e7c6e6adac9c4ca1b6018940bb9a51e5","0dc6ffdc2f2448ddb0896799aeeed076","1749ae76d4854c6dadf5e98236e60406","3670b79e081540f494f49a280ebc0156","b6eb5983c01742d08eced3dffe3df694","e107fb3b1f704ea5a3e9b582b7f60136","05a06baf9b204439986501b63b69860d","283b72fd8ce242439c719e44f2cde749","100a267e1cf34717acf755dd1a12ec2e","4c6d2b12558b4ba49696fbbd5bff036a","62bb1556ee144b2397cc3411d2f02e75","20d9f74e159f462f90f7796500636a14","6e94cd15ba264fe692abe6829d162abd","6beecfdc4ffd4ef1ace45e76973dd5c4","381f76bedbc242319932df8784fb52c2","9e4c5e35b7c54abeb50c1c20a4d2c78e","3d3424ebd3784e2296bdebf3c643bb56","e926cfa7471542db97e1a618200a905c"]},"executionInfo":{"status":"ok","timestamp":1712683569407,"user_tz":-120,"elapsed":7402,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"89cba912-01d5-402e-c5e5-105b4fb5aeed"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4d59602bc954acf8c7655a46cb90a62"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n","WARNING:stanza:Language en package default expects mwt, which has been added\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/tokenize/combined.pt:   0%|    …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fdbc387cfbd4d2cac947bf9adab450f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/mwt/combined.pt:   0%|         …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6f2d90b12274b0bbd6896a8b9b853a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/pos/combined_charlm.pt:   0%|  …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9acedf82f49f48c585ec58540310e374"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/lemma/combined_nocharlm.pt:   0…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3881b394d1d4e4fa0f54972bd82f25e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.8.0/models/depparse/combined_charlm.pt:   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283b72fd8ce242439c719e44f2cde749"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Loading these models for language: en (English):\n","=======================================\n","| Processor | Package                 |\n","---------------------------------------\n","| tokenize  | /content/g...kenizer.pt |\n","| mwt       | combined                |\n","| pos       | /content/g..._tagger.pt |\n","| lemma     | combined_nocharlm       |\n","| depparse  | /content/g..._parser.pt |\n","=======================================\n","\n","INFO:stanza:Using device: cuda\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Loading: pos\n","INFO:stanza:Loading: lemma\n","INFO:stanza:Loading: depparse\n","INFO:stanza:Done loading processors!\n"]}]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"PAVtSVYdmwmh","executionInfo":{"status":"ok","timestamp":1712683591494,"user_tz":-120,"elapsed":18924,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","CoNLL.write_doc2conll(doc, output_file)"],"metadata":{"id":"pgivi5fsmw-m","executionInfo":{"status":"ok","timestamp":1712683633534,"user_tz":-120,"elapsed":1828,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Se modifica el output porque Sttanza esta añadiendo etiquetas <UNK\\>, como unicamente se detectas dos ocurrencias, se ajustan a mano"],"metadata":{"id":"cDgTDwNW59p1"}},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"dSD2jFqpm0HE","executionInfo":{"status":"ok","timestamp":1712683815310,"user_tz":-120,"elapsed":2134,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"id":"M1kYU4P5m0S6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712683817905,"user_tz":-120,"elapsed":284,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"36239ae5-a8b4-4e47-9f0d-36f48134af6c"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     24538 |     24740 |     24725 |          \n","Sentences  |      1357 |      2077 |      1676 |          \n","Words      |     24832 |     25094 |     25067 |     24832\n","UPOS       |     24694 |     25094 |     25067 |     24832\n","XPOS       |     24677 |     25094 |     25067 |     24832\n","UFeats     |     24723 |     25094 |     25067 |     24832\n","AllTags    |     24630 |     25094 |     25067 |     24832\n","Lemmas     |     24154 |     25094 |     25067 |     24832\n","UAS        |     21526 |     25094 |     25067 |     24832\n","LAS        |     20949 |     25094 |     25067 |     24832\n","CLAS       |     12010 |     15177 |     15107 |     15004\n","MLAS       |     11853 |     15177 |     15107 |     15004\n","BLEX       |     11594 |     15177 |     15107 |     15004\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.24 |     99.18 |     99.21 |\n","Sentences  |     80.97 |     65.33 |     72.32 |\n","Words      |     99.06 |     98.96 |     99.01 |\n","UPOS       |     98.51 |     98.41 |     98.46 |     99.44\n","XPOS       |     98.44 |     98.34 |     98.39 |     99.38\n","UFeats     |     98.63 |     98.52 |     98.57 |     99.56\n","AllTags    |     98.26 |     98.15 |     98.20 |     99.19\n","Lemmas     |     96.36 |     96.25 |     96.31 |     97.27\n","UAS        |     85.87 |     85.78 |     85.83 |     86.69\n","LAS        |     83.57 |     83.48 |     83.53 |     84.36\n","CLAS       |     79.50 |     79.13 |     79.32 |     80.05\n","MLAS       |     78.46 |     78.10 |     78.28 |     79.00\n","BLEX       |     76.75 |     76.39 |     76.57 |     77.27\n"]}]},{"cell_type":"markdown","source":["##### IT"],"metadata":{"id":"WXJIzEZBEwmd"}},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/udbase/UD_Italian-ISDT/it_isdt-ud-test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/a/Stanza/IT_output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/processed/depparse/it_isdt.test.gold.conllu\""],"metadata":{"id":"64ANC-5dEwmd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = stanza.Pipeline('it', processors='tokenize,pos,lemma,depparse', use_gpu=True,\n","                      tokenize_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/tokenize/it_isdt_tokenizer.pt',\n","                      pos_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/pos/it_isdt_charlm_tagger.pt',\n","                      depparse_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/depparse/it_isdt_charlm_parser.pt')"],"metadata":{"id":"VK77vW2kGKFM","colab":{"base_uri":"https://localhost:8080/","height":584,"referenced_widgets":["4d4cdefcb8314247a29817eab82ea0ce","1342393725b641caaf4baa8560bd5241","53691b24fbf84c5b95466e16b9a58f1c","987a43e428174e1b887d5e4ad57e389d","0b25c2355bf74d75bd50083cf37a4dd4","d3435c58daa349488cebf32dfa8333df","0ac5cc09769a4120bdc71c6d6edcf553","04c6048aa4df411986323b7590f5c028","12e5338dbb2448ffacd739355dc84727","c4e5db1a96d549cfa9fe38f7281050d6","c97d07b6a84d4a6d98016b3671915933","044dcc7daa104db5a09c7ccd95caf875","55a2f5d0ac3b4ee491dc2e0c4f960ee2","ac96442e287d4f948b338930c3422507","7b585495d9dc42198b413e3eb69a7642","c0a9217cb6ea4a0d825b8997f76fc737","c1273db334464dcf82fbdbd1ad0f87b6","b5351dbb0e1a4c1babd7c9d42ce88872","f125096f30c74934a78d981abbc6ec9c","dc51249f04674c0cb5cdf9605c0d0ac0","2a9a5b2d9bbc44a2824d4a8649781885","66c0d5b2c25e45cba46a8dd38ee271c2","c171673696b4420b9fbe8f4e8d9e393f","5b0742b0ec084d0caf8a5459b28f73d5","add7c43e5ef049fe82c5e41bbb2204ff","980d63d47faf4be49981b8b2ec918284","e55fd040b4cf414aa1341a44ccd80e44","737beac83216446899e992ee78a55ea0","d303515bffda499087af421d69a76a7f","178bdddf4a63449ea4a3a3df1e9d1dd0","9dd05edf7c0a467eafdbd649df2b390a","3324aebe97bb48f4b1c62b1bd09ab7ca","98b8a0646f1345179d54cb88ecf2fdde","1c2075215f9e4ea384e98eb26d4ea1de","5bd69c039cf9495f81f291391b448779","e2568143e60f4743a38900355918566b","267fa8ae5c8646d99537d4763c31a656","7c3cdb7b20da4787aa12ce3e59f141b2","85bdadb2a50c467aa2ba18c33f92f13f","463d289f9b8a4d3cae96b27e863a802a","57e5ec59d15447a4a118950df95db00d","4df7243839e6433da8024e5ce69e85b4","c662370eb8da4167a28fd2bd74b54b70","8d40b5779be34685913e99132f22f4d6","d9e5e16049054d87bc3fa1ec5a6e868d","fc70fd99697b44dda94c6c04ee47bfa1","83fa9a0b812f42dbb1e99bbb9359251f","352b5289f47848d7bcb77afccc4e6bbe","cd6a61d5e4ce423095576f9dfb801fbf","b3ad738d1258483b8d8eabbf576b4888","62cd263d095d4209951e359511423a71","56f45fdf8ac9490ab1d701cbf1ae7b35","27995e8a9e5c4a3b8dbdfb920206db30","5cd991219aa9406c872ca104df9c5fe1","c5c36360e8ec45b5938338972c12259e","7e8aae2a311d4128a92ef110cbbd2553","74c979dc12664848b8dcfa3da796f355","3558067f53f84896b7329da0ac059271","f980bf555420440884e77f9e3bf5a41c","a386da73afca4af9ac3206564a669226","aeb923d0b4954c9ab783f30573c8b010","6699f150d5f74aafa36dc45fa6d74453","b0c0d1177d454dca8f461b49ef5abf9f","19f995d082b6471ab46a4b774d10a675","3f18873462a848afa6cd474c3fd5f9f2","b53334c0b8da4affabe687edba4d2ff8"]},"executionInfo":{"status":"ok","timestamp":1710592298681,"user_tz":-60,"elapsed":8651,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"d34e93db-51fc-4842-a02b-7ed87191289e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d4cdefcb8314247a29817eab82ea0ce"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n","WARNING:stanza:Language it package default expects mwt, which has been added\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/tokenize/combined.pt:   0%|    …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"044dcc7daa104db5a09c7ccd95caf875"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/mwt/combined.pt:   0%|         …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c171673696b4420b9fbe8f4e8d9e393f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/pos/combined_charlm.pt:   0%|  …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c2075215f9e4ea384e98eb26d4ea1de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/lemma/combined_nocharlm.pt:   0…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e5e16049054d87bc3fa1ec5a6e868d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.8.0/models/depparse/combined_charlm.pt:   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8aae2a311d4128a92ef110cbbd2553"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Loading these models for language: it (Italian):\n","=======================================\n","| Processor | Package                 |\n","---------------------------------------\n","| tokenize  | /content/g...kenizer.pt |\n","| mwt       | combined                |\n","| pos       | /content/g..._tagger.pt |\n","| lemma     | combined_nocharlm       |\n","| depparse  | /content/g..._parser.pt |\n","=======================================\n","\n","INFO:stanza:Using device: cpu\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Loading: pos\n","INFO:stanza:Loading: lemma\n","INFO:stanza:Loading: depparse\n","INFO:stanza:Done loading processors!\n"]}]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"X_kl3JZJGNK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","CoNLL.write_doc2conll(doc, output_file)"],"metadata":{"id":"siSyFQrzGVho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"q0U6yUK9GVuk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_3S-6LUrGW7R","executionInfo":{"status":"ok","timestamp":1710592427426,"user_tz":-60,"elapsed":210,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"aa3cf83f-534e-4cc7-ccb6-7f0f41c1f3ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |      9659 |      9680 |      9674 |          \n","Sentences  |       477 |       482 |       484 |          \n","Words      |     10343 |     10417 |     10399 |     10343\n","UPOS       |     10341 |     10417 |     10399 |     10343\n","XPOS       |     10341 |     10417 |     10399 |     10343\n","UFeats     |     10339 |     10417 |     10399 |     10343\n","AllTags    |     10339 |     10417 |     10399 |     10343\n","Lemmas     |     10163 |     10417 |     10399 |     10343\n","UAS        |      9377 |     10417 |     10399 |     10343\n","LAS        |      9108 |     10417 |     10399 |     10343\n","CLAS       |      4210 |      5133 |      5107 |      5078\n","MLAS       |      4165 |      5133 |      5107 |      5078\n","BLEX       |      4097 |      5133 |      5107 |      5078\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.84 |     99.78 |     99.81 |\n","Sentences  |     98.55 |     98.96 |     98.76 |\n","Words      |     99.46 |     99.29 |     99.38 |\n","UPOS       |     99.44 |     99.27 |     99.36 |     99.98\n","XPOS       |     99.44 |     99.27 |     99.36 |     99.98\n","UFeats     |     99.42 |     99.25 |     99.34 |     99.96\n","AllTags    |     99.42 |     99.25 |     99.34 |     99.96\n","Lemmas     |     97.73 |     97.56 |     97.65 |     98.26\n","UAS        |     90.17 |     90.02 |     90.09 |     90.66\n","LAS        |     87.59 |     87.43 |     87.51 |     88.06\n","CLAS       |     82.44 |     82.02 |     82.23 |     82.91\n","MLAS       |     81.55 |     81.14 |     81.35 |     82.02\n","BLEX       |     80.22 |     79.82 |     80.02 |     80.68\n"]}]},{"cell_type":"markdown","source":["## (b) OTROS PARSERS Y/O IDIOMAS (OPTATIVO, HASTA 3 PUNTOS)\n","\n","De nuevo el enunciado viene a ser el mismo que para el caso del análisis basado en constituyentes (Apartado 2.b), si bien esta vez para análisis de dependencias."],"metadata":{"id":"E42T_YU9yC8P"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import spacy\n","import random as rn\n","import re\n","from google.colab import drive"],"metadata":{"id":"u1rhsfUXG9zu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Montamos el Google Drive en el directorio del proyecto y descomprimios el fichero con los datos\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FI9_5sInG-Qx","executionInfo":{"status":"ok","timestamp":1710685922130,"user_tz":-60,"elapsed":18242,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"27a82163-1b03-45fe-ce7e-c93bca266eec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["### Preparacion entorno Stanza"],"metadata":{"id":"-a6OdrMV08-7"}},{"cell_type":"code","source":["!pip install stanza"],"metadata":{"id":"J5DRgOV7G_22","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710686054179,"user_tz":-60,"elapsed":98815,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f4d62810-245e-4d2a-c001-3cdd5b741947"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stanza\n","  Downloading stanza-1.8.1-py3-none-any.whl (970 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m970.4/970.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting emoji (from stanza)\n","  Downloading emoji-2.10.1-py2.py3-none-any.whl (421 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.25.2)\n","Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.31.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.2.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from stanza) (0.10.2)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.12)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3.0->stanza)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3.0->stanza)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n","Successfully installed emoji-2.10.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 stanza-1.8.1\n"]}]},{"cell_type":"code","source":["import stanza"],"metadata":{"id":"hb8BEMcgHBrj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocesado de datos"],"metadata":{"id":"UaBFLX1TGYSl"}},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"_bL7GrsUGYSm"}},{"cell_type":"markdown","source":["##### EL"],"metadata":{"id":"rXHQeUSVGYSm"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_train.conllu\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_dev.conllu\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710324776537,"user_tz":-60,"elapsed":12310,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"db3a6814-3bfb-47a2-e60b-cd04b9b13582","id":"zZbMTL1tGYSm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (167 documents):\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (41 documents):\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["##### ZH"],"metadata":{"id":"F5YVNWdZGYSm"}},{"cell_type":"code","source":["# Se invoca el comando \"convert\" de Spacy en CLI para transformar los treebanks de formato .conllu a .spacy\n","\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_train.conllu\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/\" --converter conllu --n-sents 10 --merge-subtokens\n","!python -m spacy convert \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_dev.conllu\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/\" --converter conllu --n-sents 10 --merge-subtokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710334373464,"user_tz":-60,"elapsed":17216,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f8b81427-2650-49d9-93d5-c57db7e8eb4e","id":"5PanOLLlGYSm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (400 documents):\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (50 documents):\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_dev.spacy\u001b[0m\n"]}]},{"cell_type":"markdown","source":["##### RU"],"metadata":{"id":"aO8tte9H2U5j"}},{"cell_type":"markdown","source":["### Entrenamiento"],"metadata":{"id":"P02x9RcCGcNP"}},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"7UXC-nfxGcNQ"}},{"cell_type":"markdown","source":["##### EL"],"metadata":{"id":"TRD3hZToGcNR"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_config.cfg\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710324923761,"user_tz":-60,"elapsed":5655,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"4c7ef21b-76c4-4fe0-c59b-8b25bdc5a881","id":"1jvyEnRRGcNR"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train el_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_dev.spacy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710330634735,"user_tz":-60,"elapsed":3673828,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"155651e7-b644-412d-c876-34a4dae1cd5a","id":"siJyuUP5GcNS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'morphologizer',\n","'trainable_lemmatizer', 'parser']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS MORPH...  LOSS TRAIN...  LOSS PARSER  TAG_ACC  POS_ACC  MORPH_ACC  LEMMA_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n","---  ------  ------------  -----------  -------------  -------------  -----------  -------  -------  ---------  ---------  -------  -------  -------  ------\n","  0       0          0.00       262.43         279.88         310.54       612.21    39.23    38.40      22.06      52.69    21.89     8.39     0.29    0.35\n","  1     200       5567.76     13862.37       25498.12       23945.71     39980.36    90.00    89.13      74.59      78.02    76.78    68.51    77.88    0.81\n","  2     400       7967.11      4362.40       12391.19       11459.80     25034.10    92.18    91.80      81.70      83.02    80.91    74.83    79.95    0.85\n","  3     600       7928.65      2638.74        8477.95        7390.39     19580.48    93.62    93.67      83.89      85.66    82.61    76.54    88.46    0.87\n","  4     800       8031.55      1965.76        6682.23        5067.76     17382.55    93.72    93.92      85.04      86.58    83.08    78.03    86.95    0.88\n","  5    1000       8064.26      1569.66        5500.78        3660.55     15274.49    93.93    94.23      86.46      87.26    83.39    77.96    92.63    0.88\n","  7    1200       7795.38      1256.12        4321.07        2400.43     12953.24    94.14    94.44      86.66      87.81    83.67    78.16    93.09    0.88\n","  8    1400       7438.67      1081.27        3643.16        1790.91     11347.41    94.05    93.99      86.58      87.56    83.24    78.39    87.32    0.88\n","  9    1600       8107.64      1022.62        3464.89        1470.96     10969.17    94.15    94.11      87.01      87.99    83.47    78.80    88.54    0.89\n"," 10    1800       8282.90       889.33        2834.75        1255.38     10041.37    94.19    94.23      87.37      87.71    83.39    78.36    90.11    0.88\n"," 11    2000       7836.09       853.49        2710.99        1027.48      8940.06    94.13    94.31      87.03      87.81    83.67    78.82    91.87    0.89\n"," 13    2200       7715.66       730.87        2332.35         887.33      8172.29    94.18    94.58      87.75      87.84    82.97    78.25    92.48    0.89\n"," 14    2400       7938.55       711.61        2243.67         822.74      7928.67    94.36    94.26      87.79      88.20    84.02    79.60    92.13    0.89\n"," 15    2600       7445.88       628.67        1962.40         676.59      7278.90    94.44    94.30      87.52      88.31    84.05    79.56    89.66    0.89\n"," 16    2800       7656.13       626.88        1969.82         670.72      6936.53    94.38    94.40      88.07      88.35    84.19    79.63    91.74    0.89\n"," 17    3000       7842.24       579.04        1724.01         621.98      6755.98    94.35    94.53      88.11      88.09    83.65    79.27    93.66    0.89\n"," 19    3200       7695.80       577.98        1629.40         569.87      6086.55    94.18    94.32      87.82      88.09    83.51    78.60    90.82    0.89\n"," 20    3400       8032.97       489.19        1515.01         513.14      6009.76    94.24    94.49      88.04      88.19    84.15    79.51    92.73    0.89\n"," 21    3600       8482.08       541.84        1557.56         507.30      6052.30    94.29    94.64      88.11      88.23    83.37    78.68    89.54    0.89\n"," 22    3800       8073.40       492.20        1458.17         448.24      5611.02    94.43    94.66      88.25      88.21    83.76    79.12    90.98    0.89\n"," 23    4000       7759.57       475.58        1418.67         439.36      5270.67    94.23    94.43      88.10      88.29    83.96    79.41    93.66    0.89\n"," 25    4200       8022.30       463.50        1288.08         420.65      5267.10    94.35    94.64      88.17      88.30    84.32    79.73    92.59    0.89\n"," 26    4400       7681.55       425.56        1210.90         366.18      4932.33    94.43    94.60      88.42      88.36    83.60    79.30    89.98    0.89\n"," 27    4600       7991.84       409.79        1156.51         386.64      4951.43    94.35    94.57      88.23      88.35    84.61    80.49    93.33    0.89\n"," 28    4800       8133.31       406.09        1193.30         335.29      4832.33    94.36    94.63      88.03      88.47    84.17    79.84    88.24    0.89\n"," 29    5000       8154.99       417.10        1181.10         358.73      4828.59    94.29    94.54      88.23      88.54    83.79    79.45    89.81    0.89\n"," 31    5200       7942.97       386.64        1046.60         326.22      4642.30    94.30    94.42      88.26      88.45    84.30    80.07    92.69    0.89\n"," 32    5400       8448.16       381.91        1027.24         307.63      4652.61    94.23    94.30      88.20      88.56    84.73    80.48    90.75    0.89\n"," 33    5600       7272.80       351.15         978.90         255.90      4233.53    94.20    94.48      88.50      88.66    84.35    79.82    88.48    0.89\n"," 34    5800       8477.51       344.04         994.03         300.77      4456.04    94.46    94.53      88.50      88.52    84.37    80.28    90.93    0.89\n"," 35    6000       8104.58       339.32         984.53         326.32      4240.67    94.39    94.45      88.48      88.67    83.80    79.90    91.85    0.89\n"," 37    6200       7777.42       322.16         880.42         259.18      3976.88    94.40    94.72      88.49      88.58    84.84    80.42    94.79    0.89\n"," 38    6400       7965.91       338.08         926.67         285.93      3956.64    94.39    94.44      88.51      88.57    83.91    79.53    90.20    0.89\n"," 39    6600       7991.54       311.46         878.03         255.34      3926.80    94.43    94.73      88.42      88.43    84.45    80.01    93.74    0.89\n"," 40    6800       8006.97       330.52         880.50         259.17      3811.21    94.27    94.41      88.64      88.37    84.00    79.33    91.13    0.89\n"," 41    7000       7825.00       297.28         860.41         220.76      3779.07    94.27    94.46      88.42      88.31    83.30    78.95    90.89    0.89\n"," 43    7200       8685.44       281.93         769.84         214.91      3809.29    94.30    94.56      88.57      88.35    83.90    79.41    87.33    0.89\n"," 44    7400       8509.77       281.99         784.74         245.65      3683.58    94.48    94.84      88.26      88.64    84.06    79.72    90.89    0.89\n"," 45    7600       8589.06       305.11         792.37         235.17      3705.82    94.45    94.66      88.48      88.44    84.08    79.57    88.08    0.89\n"," 46    7800       8857.27       268.64         742.86         221.81      3705.49    94.51    94.63      88.42      88.47    84.89    80.74    91.85    0.89\n"," 47    8000       8338.59       291.96         772.83         231.64      3545.72    94.42    94.57      88.55      88.55    84.37    80.06    90.02    0.89\n"," 49    8200       7868.79       259.12         728.51         193.83      3472.28    94.25    94.56      88.59      88.69    84.75    80.78    92.04    0.89\n"," 50    8400       8190.93       257.81         677.29         207.36      3392.49    94.37    94.66      88.35      88.54    84.35    80.16    88.21    0.89\n"," 51    8600       9307.83       268.41         704.17         184.54      3578.17    94.54    94.74      88.76      88.52    84.20    79.81    87.01    0.89\n"," 52    8800       8766.89       243.64         653.97         191.41      3362.67    94.62    94.78      88.91      88.62    84.32    80.25    89.78    0.89\n"," 53    9000       8720.31       251.06         698.46         185.64      3397.24    94.09    94.42      88.65      88.67    84.27    79.95    91.65    0.89\n"," 55    9200       9625.15       235.34         646.35         180.73      3487.53    94.39    94.58      88.55      88.51    84.63    80.26    90.66    0.89\n"," 56    9400      10209.89       243.71         631.59         177.39      3593.49    94.33    94.63      88.67      88.42    84.53    80.53    92.36    0.89\n"," 57    9600       7501.36       219.30         628.64         180.75      3095.88    94.34    94.66      88.76      88.50    84.69    80.46    90.60    0.89\n"," 58    9800       9806.37       234.36         657.36         199.55      3422.87    94.38    94.58      88.78      88.72    84.93    80.90    89.81    0.90\n"," 59   10000       9322.42       242.99         609.94         147.28      3344.15    94.30    94.57      88.87      88.55    84.56    80.33    90.45    0.89\n"," 61   10200       8832.53       216.40         577.61         159.77      3131.41    94.28    94.53      88.60      88.46    85.14    81.00    93.87    0.89\n"," 62   10400       9633.70       209.23         586.49         156.14      3289.31    94.45    94.50      88.62      88.67    83.98    79.63    91.09    0.89\n"," 63   10600       9792.08       210.27         586.03         168.79      3190.75    94.54    94.64      88.66      88.77    84.74    80.25    92.63    0.89\n"," 64   10800       8796.54       205.30         541.91         190.91      2992.70    94.38    94.55      88.55      88.81    84.85    80.53    92.84    0.89\n"," 65   11000       9088.61       194.63         542.57         149.14      3104.95    94.40    94.57      88.61      88.69    84.15    79.98    85.21    0.89\n"," 67   11200       9454.06       196.53         576.69         143.46      3087.54    94.55    94.78      88.89      88.65    85.03    80.77    91.71    0.90\n"," 68   11400       9694.03       199.88         539.89         147.14      3131.14    94.48    94.51      88.76      88.61    84.62    80.17    93.56    0.89\n"," 69   11600       9979.84       206.43         529.00         154.46      3079.05    94.43    94.69      88.76      88.79    84.56    80.24    89.59    0.89\n"," 70   11800       9111.91       203.08         546.15         135.65      2948.81    94.38    94.73      89.04      88.88    83.88    79.62    93.14    0.89\n"," 71   12000       9552.53       185.22         521.45         131.36      2985.10    94.43    94.41      88.86      88.74    84.38    80.30    90.73    0.89\n"," 73   12200       9056.31       190.95         463.59         125.13      2942.98    94.41    94.61      88.82      88.50    84.32    80.14    93.60    0.89\n"," 74   12400      10132.32       189.55         504.52         133.67      3032.46    94.41    94.75      89.02      88.55    84.75    80.80    92.50    0.89\n"," 75   12600      10406.93       176.83         468.35         108.23      3035.73    94.17    94.45      88.76      88.65    84.53    80.09    88.92    0.89\n"," 76   12800      10372.22       183.54         485.51         126.26      3069.61    94.22    94.56      88.70      88.47    84.70    80.40    92.02    0.89\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["##### ZH"],"metadata":{"id":"3sbduyW7GcNS"}},{"cell_type":"code","source":["# Se genera el archivo de configuracion definitivo\n","!python -m spacy init fill-config \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_base_config.cfg\" \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_config.cfg\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710334478063,"user_tz":-60,"elapsed":4921,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"0669428f-709b-4c5e-c4bc-ec3161646f02","id":"LRLIs-BqGcNS"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_config.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train zh_config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_config.cfg\" --output \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/Trained\" --paths.train \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_train.spacy\" --paths.dev  \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_dev.spacy\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710336368208,"user_tz":-60,"elapsed":1822746,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"0db358c9-d90a-42cd-fb18-255eb6fccf6b","id":"PVBgwaAfGcNT"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Created output directory:\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/ZH/Trained\u001b[0m\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/ZH/Trained\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'tagger', 'morphologizer',\n","'trainable_lemmatizer', 'parser']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TAGGER  LOSS MORPH...  LOSS TRAIN...  LOSS PARSER  TAG_ACC  POS_ACC  MORPH_ACC  LEMMA_ACC  DEP_UAS  DEP_LAS  SENTS_F  SCORE \n","---  ------  ------------  -----------  -------------  -------------  -----------  -------  -------  ---------  ---------  -------  -------  -------  ------\n","  0       0          0.00       445.23         443.90         475.31       421.12    33.29    31.38      88.42      40.17     4.85     4.30     0.00    0.35\n","  0     200       3979.12     33418.12       33975.74        1867.88     24312.45    78.30    77.07      96.72      40.17    29.06    17.23    52.33    0.57\n","  1     400       7158.58     21368.06       22777.54           3.82     22229.64    81.38    80.13      97.39      40.17    32.18    22.03    19.95    0.59\n","  1     600       9199.59     16906.22       18149.58           6.92     22042.41    82.95    81.99      97.68      40.17    41.31    29.59    41.29    0.62\n","  2     800       9790.42     17031.21       18144.17           3.34     20125.00    84.39    83.35      97.86      40.17    34.60    26.84    27.04    0.62\n","  2    1000      10783.30     13822.79       14865.80           5.38     18442.35    85.39    84.70      97.88      40.17    37.03    27.11    22.08    0.62\n","  3    1200      11955.93     14691.23       15735.58           4.60     19911.42    86.11    84.95      97.90      40.17    39.95    29.79    22.88    0.63\n","  3    1400      12552.61     12347.26       13362.65           5.43     17758.47    86.10    85.21      98.01      40.17    37.62    28.71    19.37    0.63\n","  4    1600      13395.66     12581.05       13552.52           3.77     18404.73    86.52    85.56      98.08      40.17    39.70    30.17    27.27    0.63\n","  4    1800      14259.02     11069.96       11989.78           7.61     17198.42    86.85    85.77      98.05      40.17    39.82    30.73    57.97    0.64\n","  5    2000      14587.96     11367.00       12294.10           4.09     16579.48    86.86    85.84      98.04      40.17    36.44    28.84    44.84    0.63\n","  5    2200      14610.93      9676.05       10627.89           3.81     15557.22    86.87    86.22      98.07      40.17    36.21    29.11    31.08    0.63\n","  6    2400      15680.03     10730.82       11600.12           3.20     16332.60    87.17    86.24      98.29      40.17    40.04    31.11    27.30    0.64\n","  6    2600      16080.40      8916.55        9755.39           3.41     14942.78    87.23    86.28      98.24      40.17    36.92    29.08    40.73    0.63\n","  7    2800      17395.29      9674.67       10563.11           6.27     15635.34    87.11    86.12      98.08      40.17    35.38    29.09    22.86    0.63\n","  7    3000      16618.87      8236.48        8929.44           5.15     14378.64    87.30    86.55      98.21      40.17    39.53    31.44    36.75    0.64\n","  8    3200      18150.04      8956.63        9979.26           6.31     14757.66    87.25    86.33      98.11      40.17    36.23    28.82    14.73    0.63\n","  8    3400      17446.83      7533.23        8345.40           5.66     13593.89    87.28    86.15      98.03      40.17    39.76    31.26    50.65    0.64\n","  9    3600      18736.54      8318.10        9126.61           4.07     14112.30    87.87    86.91      98.18      40.17    37.97    29.36    42.15    0.64\n","  9    3800      17798.35      7038.20        7802.00           1.49     13197.74    87.60    86.99      98.23      40.17    38.59    31.17    48.51    0.64\n"," 10    4000      19392.98      7765.96        8608.33           5.27     13569.82    88.14    87.21      98.32      40.17    40.26    31.11    41.81    0.64\n"," 10    4200      19547.91      6639.16        7364.94           5.30     13130.51    87.90    87.18      98.31      40.17    36.92    29.80    32.14    0.64\n"," 11    4400      20702.29      7228.48        8014.39           3.05     13300.84    88.03    87.11      98.22      40.17    36.36    29.94    37.20    0.64\n"," 11    4600      19358.01      6235.56        6910.10           6.50     12273.76    87.92    86.99      98.25      40.17    36.62    29.46    35.74    0.63\n"," 12    4800      21427.38      7000.19        7766.20           6.20     13007.87    87.91    87.07      98.22      40.17    37.78    30.53    42.81    0.64\n"," 12    5000      20503.78      5805.74        6593.74           4.14     11651.33    87.72    86.89      98.15      40.17    37.08    30.24    28.83    0.64\n"," 13    5200      21463.93      6631.66        7356.47           3.85     12324.33    87.97    87.25      98.29      40.17    34.42    28.62    36.49    0.63\n"," 13    5400      20983.40      5811.24        6493.98           4.42     11475.89    87.84    87.00      98.24      40.17    38.93    31.58    43.67    0.64\n"," 14    5600      21554.73      6079.65        6863.04           2.78     11661.52    87.92    87.08      98.28      40.17    35.00    28.61    28.15    0.63\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/gdrive/MyDrive/PLN/3/a/Spacy/ZH/Trained/model-last\n"]}]},{"cell_type":"markdown","source":["#### Stanza"],"metadata":{"id":"0Cg6Cj0DGcNT"}},{"cell_type":"markdown","source":["##### EL"],"metadata":{"id":"R4RfxFcqGcNT"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_tokenizer_treebank UD_Greek-GDT"],"metadata":{"id":"1bC5Ob-4GcNT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710686124406,"user_tz":-60,"elapsed":49251,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"b0389722-b177-4559-83c1-7fb28b1e9bf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:35:18 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py UD_Greek-GDT\n","Preparing data for UD_Greek-GDT: el_gdt, el\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-train.conllu and writing to ../data/processed/tokenize/el_gdt.train.gold.conllu\n","Augmented 15 quotes: Counter({'\"\"': 4, '„“': 4, '″″': 2, '»«': 2, '「」': 2, '““': 1})\n","Swapped 'w1, w2' for 'w1 ,w2' 22 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Added 4 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-dev.conllu and writing to ../data/processed/tokenize/el_gdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-test.conllu and writing to ../data/processed/tokenize/el_gdt.test.gold.conllu\n","Tokenizer labels written to ../data/processed/tokenize/el_gdt-ud-train.toklabels\n","  14 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/el_gdt-ud-train-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/el_gdt-ud-dev.toklabels\n","  14 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/el_gdt-ud-dev-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/el_gdt-ud-test.toklabels\n","  12 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/el_gdt-ud-test-mwt.json\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_tokenizer UD_Greek-GDT --step 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5Xv6AB5xfp7","executionInfo":{"status":"ok","timestamp":1710686174329,"user_tz":-60,"elapsed":37000,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"42715756-aaa0-49f3-fda8-2d8fbc54883d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:35:41 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_tokenizer.py UD_Greek-GDT --step 1000\n","2024-03-17 14:35:41 DEBUG: UD_Greek-GDT: el_gdt\n","2024-03-17 14:35:41 INFO: Save file for el_gdt model: el_gdt_tokenizer.pt\n","2024-03-17 14:35:41 INFO: UD_Greek-GDT: saved_models/tokenize/el_gdt_tokenizer.pt does not exist, training new model\n","2024-03-17 14:35:41 INFO: Running train step with args: ['--label_file', '../data/processed/tokenize/el_gdt-ud-train.toklabels', '--txt_file', '../data/processed/tokenize/el_gdt.train.txt', '--lang', 'el', '--max_seqlen', '500', '--mwt_json_file', '../data/processed/tokenize/el_gdt-ud-dev-mwt.json', '--dev_txt_file', '../data/processed/tokenize/el_gdt.dev.txt', '--dev_label_file', '../data/processed/tokenize/el_gdt-ud-dev.toklabels', '--dev_conll_gold', '../data/processed/tokenize/el_gdt.dev.gold.conllu', '--conll_file', '/tmp/tmpvarwop8b', '--shorthand', 'el_gdt', '--step', '1000', '--save_name', 'el_gdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:35:45 INFO: Running tokenizer in train mode\n","2024-03-17 14:35:46 DEBUG: 1657 sentences loaded.\n","2024-03-17 14:35:46 INFO: Found mwts in the training data.  Setting use_mwt to True\n","2024-03-17 14:35:46 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:35:49 INFO: Step     20/  1000 Loss: 0.497\n","2024-03-17 14:35:49 INFO: Step     40/  1000 Loss: 0.402\n","2024-03-17 14:35:50 INFO: Step     60/  1000 Loss: 0.252\n","2024-03-17 14:35:50 INFO: Step     80/  1000 Loss: 0.173\n","2024-03-17 14:35:50 INFO: Step    100/  1000 Loss: 0.118\n","2024-03-17 14:35:51 INFO: Step    120/  1000 Loss: 0.069\n","2024-03-17 14:35:51 INFO: Step    140/  1000 Loss: 0.056\n","2024-03-17 14:35:51 INFO: Step    160/  1000 Loss: 0.050\n","2024-03-17 14:35:52 INFO: Step    180/  1000 Loss: 0.042\n","2024-03-17 14:35:52 INFO: Step    200/  1000 Loss: 0.039\n","2024-03-17 14:35:53 INFO: el_gdt: token F1 = 99.05, sentence F1 = 82.71, mwt F1 = 98.89\n","2024-03-17 14:35:53 INFO: Model saved to saved_models/tokenize/el_gdt_tokenizer.pt\n","2024-03-17 14:35:53 INFO: Dev score: 90.184\tNew best dev score!\n","2024-03-17 14:35:53 INFO: Step    220/  1000 Loss: 0.040\n","2024-03-17 14:35:53 INFO: Step    240/  1000 Loss: 0.038\n","2024-03-17 14:35:54 INFO: Step    260/  1000 Loss: 0.036\n","2024-03-17 14:35:54 INFO: Step    280/  1000 Loss: 0.030\n","2024-03-17 14:35:54 INFO: Step    300/  1000 Loss: 0.030\n","2024-03-17 14:35:54 INFO: Step    320/  1000 Loss: 0.028\n","2024-03-17 14:35:55 INFO: Step    340/  1000 Loss: 0.028\n","2024-03-17 14:35:55 INFO: Step    360/  1000 Loss: 0.027\n","2024-03-17 14:35:56 INFO: Step    380/  1000 Loss: 0.031\n","2024-03-17 14:35:56 INFO: Step    400/  1000 Loss: 0.029\n","2024-03-17 14:35:57 INFO: el_gdt: token F1 = 99.72, sentence F1 = 88.55, mwt F1 = 99.66\n","2024-03-17 14:35:57 INFO: Model saved to saved_models/tokenize/el_gdt_tokenizer.pt\n","2024-03-17 14:35:57 INFO: Dev score: 93.835\tNew best dev score!\n","2024-03-17 14:35:58 INFO: Step    420/  1000 Loss: 0.025\n","2024-03-17 14:35:58 INFO: Step    440/  1000 Loss: 0.028\n","2024-03-17 14:35:58 INFO: Step    460/  1000 Loss: 0.023\n","2024-03-17 14:35:59 INFO: Step    480/  1000 Loss: 0.024\n","2024-03-17 14:35:59 INFO: Step    500/  1000 Loss: 0.027\n","2024-03-17 14:36:00 INFO: Step    520/  1000 Loss: 0.026\n","2024-03-17 14:36:00 INFO: Step    540/  1000 Loss: 0.026\n","2024-03-17 14:36:01 INFO: Step    560/  1000 Loss: 0.024\n","2024-03-17 14:36:01 INFO: Step    580/  1000 Loss: 0.023\n","2024-03-17 14:36:01 INFO: Step    600/  1000 Loss: 0.026\n","2024-03-17 14:36:02 INFO: el_gdt: token F1 = 99.83, sentence F1 = 91.53, mwt F1 = 99.80\n","2024-03-17 14:36:02 INFO: Model saved to saved_models/tokenize/el_gdt_tokenizer.pt\n","2024-03-17 14:36:02 INFO: Dev score: 95.521\tNew best dev score!\n","2024-03-17 14:36:02 INFO: Step    620/  1000 Loss: 0.020\n","2024-03-17 14:36:03 INFO: Step    640/  1000 Loss: 0.024\n","2024-03-17 14:36:03 INFO: Step    660/  1000 Loss: 0.024\n","2024-03-17 14:36:03 INFO: Step    680/  1000 Loss: 0.023\n","2024-03-17 14:36:03 INFO: Step    700/  1000 Loss: 0.019\n","2024-03-17 14:36:04 INFO: Step    720/  1000 Loss: 0.023\n","2024-03-17 14:36:04 INFO: Step    740/  1000 Loss: 0.027\n","2024-03-17 14:36:04 INFO: Step    760/  1000 Loss: 0.022\n","2024-03-17 14:36:05 INFO: Step    780/  1000 Loss: 0.019\n","2024-03-17 14:36:05 INFO: Step    800/  1000 Loss: 0.027\n","2024-03-17 14:36:06 INFO: el_gdt: token F1 = 99.85, sentence F1 = 92.33, mwt F1 = 99.82\n","2024-03-17 14:36:06 INFO: Model saved to saved_models/tokenize/el_gdt_tokenizer.pt\n","2024-03-17 14:36:06 INFO: Dev score: 95.959\tNew best dev score!\n","2024-03-17 14:36:06 INFO: Step    820/  1000 Loss: 0.024\n","2024-03-17 14:36:06 INFO: Step    840/  1000 Loss: 0.024\n","2024-03-17 14:36:07 INFO: Step    860/  1000 Loss: 0.020\n","2024-03-17 14:36:07 INFO: Step    880/  1000 Loss: 0.018\n","2024-03-17 14:36:07 INFO: Step    900/  1000 Loss: 0.028\n","2024-03-17 14:36:07 INFO: Step    920/  1000 Loss: 0.021\n","2024-03-17 14:36:08 INFO: Step    940/  1000 Loss: 0.020\n","2024-03-17 14:36:08 INFO: Step    960/  1000 Loss: 0.020\n","2024-03-17 14:36:08 INFO: Step    980/  1000 Loss: 0.015\n","2024-03-17 14:36:09 INFO: Step   1000/  1000 Loss: 0.022\n","2024-03-17 14:36:09 INFO: el_gdt: token F1 = 99.85, sentence F1 = 92.27, mwt F1 = 99.83\n","2024-03-17 14:36:09 INFO: Dev score: 95.930\n","2024-03-17 14:36:09 INFO: Best dev score=0.9595853232603222 at step 800\n","2024-03-17 14:36:09 INFO: Running dev step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/el_gdt.dev.txt', '--lang', 'el', '--conll_file', '/tmp/tmpvarwop8b', '--shorthand', 'el_gdt', '--mwt_json_file', '../data/processed/tokenize/el_gdt-ud-dev-mwt.json', '--step', '1000', '--save_name', 'el_gdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:36:09 INFO: Running tokenizer in predict mode\n","2024-03-17 14:36:09 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:36:10 INFO: OOV rate:  0.003% (     2/ 60719)\n","2024-03-17 14:36:11 INFO: Finished running dev set on\n","UD_Greek-GDT\n","   Tokens Sentences     Words\n","    99.85     92.33     99.84\n","2024-03-17 14:36:11 INFO: Running test step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/el_gdt.test.txt', '--lang', 'el', '--conll_file', '/tmp/tmpvarwop8b', '--shorthand', 'el_gdt', '--mwt_json_file', '../data/processed/tokenize/el_gdt-ud-test-mwt.json', '--step', '1000', '--save_name', 'el_gdt_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:36:11 INFO: Running tokenizer in predict mode\n","2024-03-17 14:36:11 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:36:12 INFO: OOV rate:  0.005% (     3/ 62159)\n","2024-03-17 14:36:13 INFO: Finished running test set on\n","UD_Greek-GDT\n","   Tokens Sentences     Words\n","    99.65     88.77     99.64\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_pos_treebank UD_Greek-GDT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"foYq_m-kxf0Z","executionInfo":{"status":"ok","timestamp":1710686183039,"user_tz":-60,"elapsed":5079,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"9b9e2b2b-8daf-4d89-af9e-6c725725bc99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:36:21 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_pos_treebank.py UD_Greek-GDT\n","Preparing data for UD_Greek-GDT: el_gdt, el\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-train.conllu and writing to /tmp/tmpr4yf5zuw/el_gdt.train.gold.conllu\n","Augmented 15 quotes: Counter({'\"\"': 4, '„“': 4, '″″': 2, '»«': 2, '「」': 2, '““': 1})\n","Swapped 'w1, w2' for 'w1 ,w2' 22 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Added 4 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-dev.conllu and writing to /tmp/tmpr4yf5zuw/el_gdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-test.conllu and writing to /tmp/tmpr4yf5zuw/el_gdt.test.gold.conllu\n","Copying from /tmp/tmpr4yf5zuw/el_gdt.train.gold.conllu to ../data/processed/pos/el_gdt.train.in.conllu\n","Copying from /tmp/tmpr4yf5zuw/el_gdt.dev.gold.conllu to ../data/processed/pos/el_gdt.dev.in.conllu\n","Copying from /tmp/tmpr4yf5zuw/el_gdt.test.gold.conllu to ../data/processed/pos/el_gdt.test.in.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_pos UD_Greek-GDT --max_steps 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABayBt81xgCI","executionInfo":{"status":"ok","timestamp":1710686521336,"user_tz":-60,"elapsed":324822,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"7a25692f-5f42-4791-e5de-989937fa4594"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:36:40 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_pos.py UD_Greek-GDT --max_steps 500\n","2024-03-17 14:36:40 DEBUG: UD_Greek-GDT: el_gdt\n","2024-03-17 14:36:40 INFO: Default pretrain should be /root/stanza_resources/el/pretrain/conll17.pt  Attempting to download\n","2024-03-17 14:36:40 DEBUG: Downloading resource file from https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/46.6k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 21.1MB/s]        \n","2024-03-17 14:36:40 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-17 14:36:40 DEBUG: Processing parameter \"processors\"...\n","2024-03-17 14:36:40 DEBUG: Found pretrain: conll17.\n","2024-03-17 14:36:40 DEBUG: Found dependencies [] for processor pretrain model conll17\n","2024-03-17 14:36:40 INFO: Downloading these customized packages for language: el (Greek)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-el/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 108M/108M [00:01<00:00, 75.4MB/s]\n","2024-03-17 14:36:42 INFO: Downloaded file to /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:36:42 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-17 14:36:42 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:36:43 INFO: UD_Greek-GDT: saved_models/pos/el_gdt_nocharlm_tagger.pt does not exist, training new model\n","2024-03-17 14:36:43 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:36:43 INFO: Running train POS for UD_Greek-GDT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/pos/el_gdt.train.in.conllu', '--output_file', '/tmp/tmpcmbxpg_g', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'train', '--eval_file', '../data/processed/pos/el_gdt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--max_steps', '500']\n","2024-03-17 14:36:43 INFO: Running tagger in train mode\n","2024-03-17 14:36:43 INFO: Loading data with batch size 250...\n","2024-03-17 14:36:43 INFO: Reading ../data/processed/pos/el_gdt.train.in.conllu\n","2024-03-17 14:36:43 INFO: Train File ../data/processed/pos/el_gdt.train.in.conllu, Data Size: 1666\n","2024-03-17 14:36:45 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:36:46 INFO: Training tagger...\n","2024-03-17 14:36:46 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:36:47 INFO: Evaluating the model every 100 steps...\n","2024-03-17 14:37:00 INFO: Finished STEP 20/500, loss = 5.220048 (0.419 sec/batch), lr: 0.003000\n","2024-03-17 14:37:12 INFO: Finished STEP 40/500, loss = 3.574221 (0.385 sec/batch), lr: 0.003000\n","2024-03-17 14:37:23 INFO: Finished STEP 60/500, loss = 2.781765 (0.420 sec/batch), lr: 0.003000\n","2024-03-17 14:37:35 INFO: Finished STEP 80/500, loss = 2.338785 (0.444 sec/batch), lr: 0.003000\n","2024-03-17 14:37:47 INFO: Finished STEP 100/500, loss = 2.108846 (0.425 sec/batch), lr: 0.003000\n","2024-03-17 14:37:47 INFO: Evaluating on dev set...\n","2024-03-17 14:37:48 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:37:48 INFO: 93.19\t93.19\t80.46\t78.42\n","2024-03-17 14:37:48 INFO: step 100: train_loss = 4.706397, dev_score = 0.7842\n","2024-03-17 14:37:48 INFO: Model saved to saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:37:48 INFO: new best model saved.\n","2024-03-17 14:38:00 INFO: Finished STEP 120/500, loss = 1.879683 (0.450 sec/batch), lr: 0.003000\n","2024-03-17 14:38:12 INFO: Finished STEP 140/500, loss = 1.781272 (0.315 sec/batch), lr: 0.003000\n","2024-03-17 14:38:25 INFO: Finished STEP 160/500, loss = 1.733207 (0.459 sec/batch), lr: 0.003000\n","2024-03-17 14:38:37 INFO: Finished STEP 180/500, loss = 1.741945 (0.475 sec/batch), lr: 0.003000\n","2024-03-17 14:38:49 INFO: Finished STEP 200/500, loss = 1.516677 (0.428 sec/batch), lr: 0.003000\n","2024-03-17 14:38:49 INFO: Evaluating on dev set...\n","2024-03-17 14:38:50 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:38:50 INFO: 95.88\t95.88\t88.27\t87.05\n","2024-03-17 14:38:50 INFO: step 200: train_loss = 1.775216, dev_score = 0.8705\n","2024-03-17 14:38:51 INFO: Model saved to saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:38:51 INFO: new best model saved.\n","2024-03-17 14:39:03 INFO: Finished STEP 220/500, loss = 1.530587 (0.430 sec/batch), lr: 0.003000\n","2024-03-17 14:39:15 INFO: Finished STEP 240/500, loss = 1.457710 (0.438 sec/batch), lr: 0.003000\n","2024-03-17 14:39:27 INFO: Finished STEP 260/500, loss = 1.437358 (0.448 sec/batch), lr: 0.003000\n","2024-03-17 14:39:39 INFO: Finished STEP 280/500, loss = 1.502097 (0.311 sec/batch), lr: 0.003000\n","2024-03-17 14:39:51 INFO: Finished STEP 300/500, loss = 1.391510 (0.463 sec/batch), lr: 0.003000\n","2024-03-17 14:39:51 INFO: Evaluating on dev set...\n","2024-03-17 14:39:53 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:39:53 INFO: 96.46\t96.46\t91.13\t89.99\n","2024-03-17 14:39:53 INFO: step 300: train_loss = 1.488059, dev_score = 0.8999\n","2024-03-17 14:39:53 INFO: Model saved to saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:39:53 INFO: new best model saved.\n","2024-03-17 14:40:05 INFO: Finished STEP 320/500, loss = 1.427963 (0.408 sec/batch), lr: 0.003000\n","2024-03-17 14:40:17 INFO: Finished STEP 340/500, loss = 1.321392 (0.455 sec/batch), lr: 0.003000\n","2024-03-17 14:40:29 INFO: Finished STEP 360/500, loss = 1.340488 (0.440 sec/batch), lr: 0.003000\n","2024-03-17 14:40:41 INFO: Finished STEP 380/500, loss = 1.351739 (0.477 sec/batch), lr: 0.003000\n","2024-03-17 14:40:53 INFO: Finished STEP 400/500, loss = 1.265568 (0.475 sec/batch), lr: 0.003000\n","2024-03-17 14:40:53 INFO: Evaluating on dev set...\n","2024-03-17 14:40:54 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:40:54 INFO: 96.84\t96.84\t92.28\t91.14\n","2024-03-17 14:40:54 INFO: step 400: train_loss = 1.368537, dev_score = 0.9114\n","2024-03-17 14:40:54 INFO: Model saved to saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:40:54 INFO: new best model saved.\n","2024-03-17 14:41:07 INFO: Finished STEP 420/500, loss = 1.366990 (0.307 sec/batch), lr: 0.003000\n","2024-03-17 14:41:19 INFO: Finished STEP 440/500, loss = 1.292229 (0.450 sec/batch), lr: 0.003000\n","2024-03-17 14:41:30 INFO: Finished STEP 460/500, loss = 1.234993 (0.480 sec/batch), lr: 0.003000\n","2024-03-17 14:41:42 INFO: Finished STEP 480/500, loss = 1.227324 (0.451 sec/batch), lr: 0.003000\n","2024-03-17 14:41:54 INFO: Finished STEP 500/500, loss = 1.263664 (0.429 sec/batch), lr: 0.003000\n","2024-03-17 14:41:54 INFO: Evaluating on dev set...\n","2024-03-17 14:41:56 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:41:56 INFO: 97.10\t97.10\t93.05\t91.99\n","2024-03-17 14:41:56 INFO: step 500: train_loss = 1.291151, dev_score = 0.9199\n","2024-03-17 14:41:56 INFO: Model saved to saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:41:56 INFO: new best model saved.\n","2024-03-17 14:41:56 INFO: Training ended with 500 steps.\n","2024-03-17 14:41:56 INFO: Best dev F1 = 91.99, at iteration = 500\n","2024-03-17 14:41:56 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:41:56 INFO: Running dev POS for UD_Greek-GDT with args ['--wordvec_dir', '../data/wordvec', '--output_file', '/tmp/tmpcmbxpg_g', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'predict', '--eval_file', '../data/processed/pos/el_gdt.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--max_steps', '500']\n","2024-03-17 14:41:56 INFO: Running tagger in predict mode\n","2024-03-17 14:41:56 INFO: Loading model from: saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:41:57 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:41:57 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:41:57 INFO: Loading data with batch size 250...\n","2024-03-17 14:41:57 INFO: Start evaluation...\n","2024-03-17 14:41:59 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:41:59 INFO: 97.10\t97.10\t93.05\t91.99\n","2024-03-17 14:41:59 INFO: POS Tagger score: el_gdt 91.99\n","2024-03-17 14:42:00 INFO: Finished running dev set on\n","UD_Greek-GDT\n","   UPOS    XPOS  UFeats AllTags\n","  97.10   97.10   93.05   91.99\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_Greek-GDT"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivIXxaw1xgOq","executionInfo":{"status":"ok","timestamp":1710686547847,"user_tz":-60,"elapsed":22835,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"dc670780-2961-4708-fb1b-e38f3417be48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:42:08 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_depparse_treebank.py UD_Greek-GDT\n","2024-03-17 14:42:08 INFO: Using tagger model in saved_models/pos/el_gdt_nocharlm_tagger.pt for el_gdt\n","2024-03-17 14:42:08 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","Preparing data for UD_Greek-GDT: el_gdt, el\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-train.conllu and writing to /tmp/tmpja36wjwh/el_gdt.train.gold.conllu\n","Augmented 15 quotes: Counter({'\"\"': 4, '„“': 4, '″″': 2, '»«': 2, '「」': 2, '““': 1})\n","Swapped 'w1, w2' for 'w1 ,w2' 22 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Added 4 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-dev.conllu and writing to /tmp/tmpja36wjwh/el_gdt.dev.gold.conllu\n","Reading from ../data/udbase/UD_Greek-GDT/el_gdt-ud-test.conllu and writing to /tmp/tmpja36wjwh/el_gdt.test.gold.conllu\n","2024-03-17 14:42:09 INFO: Running tagger to retag /tmp/tmpja36wjwh/el_gdt.train.gold.conllu to ../data/processed/depparse/el_gdt.train.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'el_gdt_nocharlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--eval_file', '/tmp/tmpja36wjwh/el_gdt.train.gold.conllu', '--output_file', '../data/processed/depparse/el_gdt.train.in.conllu']\n","2024-03-17 14:42:10 INFO: Running tagger in predict mode\n","2024-03-17 14:42:10 INFO: Loading model from: saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:42:10 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:42:10 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:42:11 INFO: Loading data with batch size 250...\n","2024-03-17 14:42:14 INFO: Start evaluation...\n","2024-03-17 14:42:20 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:42:20 INFO: 98.85\t98.85\t96.69\t96.25\n","2024-03-17 14:42:20 INFO: POS Tagger score: el_gdt 96.25\n","2024-03-17 14:42:20 INFO: Running tagger to retag /tmp/tmpja36wjwh/el_gdt.dev.gold.conllu to ../data/processed/depparse/el_gdt.dev.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'el_gdt_nocharlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--eval_file', '/tmp/tmpja36wjwh/el_gdt.dev.gold.conllu', '--output_file', '../data/processed/depparse/el_gdt.dev.in.conllu']\n","2024-03-17 14:42:20 INFO: Running tagger in predict mode\n","2024-03-17 14:42:20 INFO: Loading model from: saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:42:20 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:42:20 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:42:20 INFO: Loading data with batch size 250...\n","2024-03-17 14:42:21 INFO: Start evaluation...\n","2024-03-17 14:42:23 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:42:23 INFO: 97.10\t97.10\t93.05\t91.99\n","2024-03-17 14:42:23 INFO: POS Tagger score: el_gdt 91.99\n","2024-03-17 14:42:23 INFO: Running tagger to retag /tmp/tmpja36wjwh/el_gdt.test.gold.conllu to ../data/processed/depparse/el_gdt.test.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'el_gdt_nocharlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--eval_file', '/tmp/tmpja36wjwh/el_gdt.test.gold.conllu', '--output_file', '../data/processed/depparse/el_gdt.test.in.conllu']\n","2024-03-17 14:42:23 INFO: Running tagger in predict mode\n","2024-03-17 14:42:23 INFO: Loading model from: saved_models/pos/el_gdt_nocharlm_tagger.pt\n","2024-03-17 14:42:23 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:42:24 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:42:24 INFO: Loading data with batch size 250...\n","2024-03-17 14:42:24 INFO: Start evaluation...\n","2024-03-17 14:42:26 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:42:26 INFO: 97.57\t97.57\t93.69\t92.80\n","2024-03-17 14:42:26 INFO: POS Tagger score: el_gdt 92.80\n","Copying from ../data/processed/depparse/el_gdt.dev.in.conllu to ../data/processed/depparse/el_gdt.dev.gold.conllu\n","Copying from ../data/processed/depparse/el_gdt.test.in.conllu to ../data/processed/depparse/el_gdt.test.gold.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_depparse UD_Greek-GDT --max_steps 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vt7WpZuNxgZF","executionInfo":{"status":"ok","timestamp":1710687046908,"user_tz":-60,"elapsed":476000,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"1ab08e69-ccf3-4a5d-910f-dcb5c1d8a4b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:42:54 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_depparse.py UD_Greek-GDT --max_steps 1000\n","2024-03-17 14:42:54 DEBUG: UD_Greek-GDT: el_gdt\n","2024-03-17 14:42:54 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:42:54 INFO: UD_Greek-GDT: saved_models/depparse/el_gdt_nocharlm_parser.pt does not exist, training new model\n","2024-03-17 14:42:54 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:42:54 INFO: Running train depparse for UD_Greek-GDT with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/depparse/el_gdt.train.in.conllu', '--eval_file', '../data/processed/depparse/el_gdt.dev.in.conllu', '--output_file', '/tmp/tmpqvvkdoey', '--gold_file', '../data/processed/depparse/el_gdt.dev.gold.conllu', '--batch_size', '5000', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--max_steps', '1000']\n","2024-03-17 14:42:55 INFO: Running parser in train mode\n","2024-03-17 14:42:55 INFO: Loading data with batch size 5000...\n","2024-03-17 14:42:55 INFO: Original data size: 1666\n","2024-03-17 14:42:55 INFO: Augmented data size: 1753\n","2024-03-17 14:42:56 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:42:57 DEBUG: 10 batches created.\n","2024-03-17 14:42:57 DEBUG: 3 batches created.\n","2024-03-17 14:42:57 INFO: Training parser...\n","2024-03-17 14:42:58 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:43:08 INFO: Finished STEP 20/1000, loss = 6.504083 (0.295 sec/batch), lr: 0.003000\n","2024-03-17 14:43:16 INFO: Finished STEP 40/1000, loss = 7.644521 (0.368 sec/batch), lr: 0.003000\n","2024-03-17 14:43:25 INFO: Finished STEP 60/1000, loss = 5.278831 (0.365 sec/batch), lr: 0.003000\n","2024-03-17 14:43:33 INFO: Finished STEP 80/1000, loss = 4.652059 (0.322 sec/batch), lr: 0.003000\n","2024-03-17 14:43:42 INFO: Finished STEP 100/1000, loss = 3.938163 (0.313 sec/batch), lr: 0.003000\n","2024-03-17 14:43:42 INFO: Evaluating on dev set...\n","2024-03-17 14:43:44 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:43:44 INFO: 59.39\t44.98\t47.32\n","2024-03-17 14:43:44 INFO: step 100: train_loss = 11.779584, dev_score = 0.5939\n","2024-03-17 14:43:44 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:43:44 INFO: new best model saved.\n","2024-03-17 14:43:45 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:43:45 INFO: new model checkpoint saved.\n","2024-03-17 14:43:54 INFO: Finished STEP 120/1000, loss = 6.183864 (0.178 sec/batch), lr: 0.003000\n","2024-03-17 14:44:03 INFO: Finished STEP 140/1000, loss = 3.383025 (0.306 sec/batch), lr: 0.003000\n","2024-03-17 14:44:11 INFO: Finished STEP 160/1000, loss = 3.566647 (0.298 sec/batch), lr: 0.003000\n","2024-03-17 14:44:20 INFO: Finished STEP 180/1000, loss = 3.867824 (0.323 sec/batch), lr: 0.003000\n","2024-03-17 14:44:28 INFO: Finished STEP 200/1000, loss = 3.038515 (0.306 sec/batch), lr: 0.003000\n","2024-03-17 14:44:28 INFO: Evaluating on dev set...\n","2024-03-17 14:44:30 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:44:30 INFO: 75.09\t62.52\t64.80\n","2024-03-17 14:44:30 INFO: step 200: train_loss = 4.193547, dev_score = 0.7509\n","2024-03-17 14:44:31 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:44:31 INFO: new best model saved.\n","2024-03-17 14:44:32 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:44:32 INFO: new model checkpoint saved.\n","2024-03-17 14:44:40 INFO: Finished STEP 220/1000, loss = 3.267332 (0.308 sec/batch), lr: 0.003000\n","2024-03-17 14:44:49 INFO: Finished STEP 240/1000, loss = 5.470122 (0.178 sec/batch), lr: 0.003000\n","2024-03-17 14:44:58 INFO: Finished STEP 260/1000, loss = 2.995343 (0.321 sec/batch), lr: 0.003000\n","2024-03-17 14:45:07 INFO: Finished STEP 280/1000, loss = 7.454865 (0.508 sec/batch), lr: 0.003000\n","2024-03-17 14:45:15 INFO: Finished STEP 300/1000, loss = 2.914879 (0.336 sec/batch), lr: 0.003000\n","2024-03-17 14:45:15 INFO: Evaluating on dev set...\n","2024-03-17 14:45:17 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:45:17 INFO: 79.83\t69.43\t71.12\n","2024-03-17 14:45:17 INFO: step 300: train_loss = 3.448076, dev_score = 0.7983\n","2024-03-17 14:45:17 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:45:17 INFO: new best model saved.\n","2024-03-17 14:45:19 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:45:19 INFO: new model checkpoint saved.\n","2024-03-17 14:45:27 INFO: Finished STEP 320/1000, loss = 2.273582 (0.315 sec/batch), lr: 0.003000\n","2024-03-17 14:45:36 INFO: Finished STEP 340/1000, loss = 2.269849 (0.314 sec/batch), lr: 0.003000\n","2024-03-17 14:45:45 INFO: Finished STEP 360/1000, loss = 2.625840 (0.321 sec/batch), lr: 0.003000\n","2024-03-17 14:45:53 INFO: Finished STEP 380/1000, loss = 2.111902 (0.310 sec/batch), lr: 0.003000\n","2024-03-17 14:46:02 INFO: Finished STEP 400/1000, loss = 2.097834 (0.333 sec/batch), lr: 0.003000\n","2024-03-17 14:46:02 INFO: Evaluating on dev set...\n","2024-03-17 14:46:03 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:46:03 INFO: 82.62\t73.59\t75.17\n","2024-03-17 14:46:03 INFO: step 400: train_loss = 2.742762, dev_score = 0.8262\n","2024-03-17 14:46:04 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:46:04 INFO: new best model saved.\n","2024-03-17 14:46:05 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:46:05 INFO: new model checkpoint saved.\n","2024-03-17 14:46:13 INFO: Finished STEP 420/1000, loss = 2.217477 (0.315 sec/batch), lr: 0.003000\n","2024-03-17 14:46:22 INFO: Finished STEP 440/1000, loss = 2.122988 (0.314 sec/batch), lr: 0.003000\n","2024-03-17 14:46:31 INFO: Finished STEP 460/1000, loss = 2.521362 (0.361 sec/batch), lr: 0.003000\n","2024-03-17 14:46:39 INFO: Finished STEP 480/1000, loss = 2.265041 (0.319 sec/batch), lr: 0.003000\n","2024-03-17 14:46:48 INFO: Finished STEP 500/1000, loss = 1.822497 (0.339 sec/batch), lr: 0.003000\n","2024-03-17 14:46:48 INFO: Evaluating on dev set...\n","2024-03-17 14:46:49 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:46:49 INFO: 83.78\t75.30\t77.02\n","2024-03-17 14:46:49 INFO: step 500: train_loss = 2.517459, dev_score = 0.8378\n","2024-03-17 14:46:49 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:46:49 INFO: new best model saved.\n","2024-03-17 14:46:51 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:46:51 INFO: new model checkpoint saved.\n","2024-03-17 14:47:00 INFO: Finished STEP 520/1000, loss = 1.840267 (0.296 sec/batch), lr: 0.003000\n","2024-03-17 14:47:09 INFO: Finished STEP 540/1000, loss = 2.336300 (0.374 sec/batch), lr: 0.003000\n","2024-03-17 14:47:17 INFO: Finished STEP 560/1000, loss = 4.130205 (0.163 sec/batch), lr: 0.003000\n","2024-03-17 14:47:25 INFO: Finished STEP 580/1000, loss = 1.724180 (0.313 sec/batch), lr: 0.003000\n","2024-03-17 14:47:34 INFO: Finished STEP 600/1000, loss = 3.868466 (0.140 sec/batch), lr: 0.003000\n","2024-03-17 14:47:34 INFO: Evaluating on dev set...\n","2024-03-17 14:47:35 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:47:35 INFO: 84.73\t76.79\t78.27\n","2024-03-17 14:47:35 INFO: step 600: train_loss = 2.285801, dev_score = 0.8473\n","2024-03-17 14:47:36 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:47:36 INFO: new best model saved.\n","2024-03-17 14:47:37 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:47:37 INFO: new model checkpoint saved.\n","2024-03-17 14:47:45 INFO: Finished STEP 620/1000, loss = 1.788454 (0.311 sec/batch), lr: 0.003000\n","2024-03-17 14:47:54 INFO: Finished STEP 640/1000, loss = 2.135422 (0.325 sec/batch), lr: 0.003000\n","2024-03-17 14:48:03 INFO: Finished STEP 660/1000, loss = 1.746434 (0.308 sec/batch), lr: 0.003000\n","2024-03-17 14:48:11 INFO: Finished STEP 680/1000, loss = 1.769671 (0.307 sec/batch), lr: 0.003000\n","2024-03-17 14:48:20 INFO: Finished STEP 700/1000, loss = 1.920201 (0.381 sec/batch), lr: 0.003000\n","2024-03-17 14:48:20 INFO: Evaluating on dev set...\n","2024-03-17 14:48:22 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:48:22 INFO: 85.46\t77.69\t79.39\n","2024-03-17 14:48:22 INFO: step 700: train_loss = 2.188799, dev_score = 0.8546\n","2024-03-17 14:48:22 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:48:22 INFO: new best model saved.\n","2024-03-17 14:48:23 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:48:23 INFO: new model checkpoint saved.\n","2024-03-17 14:48:32 INFO: Finished STEP 720/1000, loss = 1.737082 (0.314 sec/batch), lr: 0.003000\n","2024-03-17 14:48:41 INFO: Finished STEP 740/1000, loss = 1.762410 (0.301 sec/batch), lr: 0.003000\n","2024-03-17 14:48:50 INFO: Finished STEP 760/1000, loss = 2.045398 (0.321 sec/batch), lr: 0.003000\n","2024-03-17 14:48:58 INFO: Finished STEP 780/1000, loss = 1.581582 (0.332 sec/batch), lr: 0.003000\n","2024-03-17 14:49:07 INFO: Finished STEP 800/1000, loss = 2.027148 (0.363 sec/batch), lr: 0.003000\n","2024-03-17 14:49:07 INFO: Evaluating on dev set...\n","2024-03-17 14:49:08 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:49:08 INFO: 85.35\t77.95\t79.28\n","2024-03-17 14:49:08 INFO: step 800: train_loss = 2.139511, dev_score = 0.8535\n","2024-03-17 14:49:09 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:49:09 INFO: new model checkpoint saved.\n","2024-03-17 14:49:18 INFO: Finished STEP 820/1000, loss = 1.657298 (0.313 sec/batch), lr: 0.003000\n","2024-03-17 14:49:26 INFO: Finished STEP 840/1000, loss = 1.932059 (0.310 sec/batch), lr: 0.003000\n","2024-03-17 14:49:35 INFO: Finished STEP 860/1000, loss = 1.952274 (0.350 sec/batch), lr: 0.003000\n","2024-03-17 14:49:43 INFO: Finished STEP 880/1000, loss = 1.703513 (0.317 sec/batch), lr: 0.003000\n","2024-03-17 14:49:52 INFO: Finished STEP 900/1000, loss = 2.642981 (0.399 sec/batch), lr: 0.003000\n","2024-03-17 14:49:52 INFO: Evaluating on dev set...\n","2024-03-17 14:49:53 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:49:53 INFO: 85.93\t78.89\t80.08\n","2024-03-17 14:49:53 INFO: step 900: train_loss = 2.031668, dev_score = 0.8593\n","2024-03-17 14:49:54 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:49:54 INFO: new best model saved.\n","2024-03-17 14:49:55 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:49:55 INFO: new model checkpoint saved.\n","2024-03-17 14:50:03 INFO: Finished STEP 920/1000, loss = 1.552747 (0.117 sec/batch), lr: 0.003000\n","2024-03-17 14:50:12 INFO: Finished STEP 940/1000, loss = 1.891202 (0.376 sec/batch), lr: 0.003000\n","2024-03-17 14:50:21 INFO: Finished STEP 960/1000, loss = 2.057957 (0.380 sec/batch), lr: 0.003000\n","2024-03-17 14:50:29 INFO: Finished STEP 980/1000, loss = 4.765723 (0.499 sec/batch), lr: 0.003000\n","2024-03-17 14:50:38 INFO: Finished STEP 1000/1000, loss = 1.903453 (0.325 sec/batch), lr: 0.003000\n","2024-03-17 14:50:38 INFO: Evaluating on dev set...\n","2024-03-17 14:50:39 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:50:39 INFO: 86.10\t79.18\t80.36\n","2024-03-17 14:50:39 INFO: step 1000: train_loss = 1.955959, dev_score = 0.8610\n","2024-03-17 14:50:39 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:50:39 INFO: new best model saved.\n","2024-03-17 14:50:40 INFO: Model saved to saved_models/depparse/el_gdt_nocharlm_parser_checkpoint.pt\n","2024-03-17 14:50:40 INFO: new model checkpoint saved.\n","2024-03-17 14:50:40 INFO: Training ended with 1000 steps.\n","2024-03-17 14:50:40 INFO: Best dev F1 = 86.10, at iteration = 1000\n","2024-03-17 14:50:41 INFO: Using default pretrain for language, found in /root/stanza_resources/el/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:50:41 INFO: Running dev depparse for UD_Greek-GDT with args ['--wordvec_dir', '../data/wordvec', '--eval_file', '../data/processed/depparse/el_gdt.dev.in.conllu', '--output_file', '/tmp/tmpqvvkdoey', '--gold_file', '../data/processed/depparse/el_gdt.dev.gold.conllu', '--lang', 'el', '--shorthand', 'el_gdt', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/el/pretrain/conll17.pt', '--max_steps', '1000']\n","2024-03-17 14:50:41 INFO: Running parser in predict mode\n","2024-03-17 14:50:41 INFO: Loading model from: saved_models/depparse/el_gdt_nocharlm_parser.pt\n","2024-03-17 14:50:41 DEBUG: Loaded pretrain from /root/stanza_resources/el/pretrain/conll17.pt\n","2024-03-17 14:50:41 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:50:41 INFO: Loading data with batch size 5000...\n","2024-03-17 14:50:42 DEBUG: 3 batches created.\n","2024-03-17 14:50:44 INFO: F1 scores for each dependency:\n","  Note that unlabeled attachment errors hurt the labeled attachment scores\n","       acl: p 0.6667 r 0.5455 f1 0.6000 (44 actual)\n"," acl:relcl: p 0.7102 r 0.6793 f1 0.6944 (184 actual)\n","     advcl: p 0.6346 r 0.6226 f1 0.6286 (106 actual)\n","    advmod: p 0.8161 r 0.8000 f1 0.8080 (355 actual)\n","      amod: p 0.9274 r 0.9150 f1 0.9212 (824 actual)\n","     appos: p 0.5909 r 0.2653 f1 0.3662 (49 actual)\n","       aux: p 0.9742 r 0.9706 f1 0.9724 (272 actual)\n","      case: p 0.9722 r 0.9712 f1 0.9717 (936 actual)\n","        cc: p 0.8906 r 0.8879 f1 0.8892 (321 actual)\n","     ccomp: p 0.6136 r 0.7714 f1 0.6835 (70 actual)\n","  compound: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n","      conj: p 0.5202 r 0.5659 f1 0.5421 (364 actual)\n","       cop: p 0.7980 r 0.7822 f1 0.7900 (101 actual)\n","     csubj: p 0.7500 r 0.4091 f1 0.5294 (22 actual)\n","csubj:pass: p 0.3846 r 0.8333 f1 0.5263 (6 actual)\n","       det: p 0.9716 r 0.9753 f1 0.9735 (2143 actual)\n","      expl: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n","     fixed: p 0.6667 r 0.4286 f1 0.5217 (14 actual)\n","      flat: p 0.7766 r 0.7374 f1 0.7565 (99 actual)\n","      iobj: p 1.0000 r 0.5000 f1 0.6667 (2 actual)\n","      mark: p 0.8874 r 0.9371 f1 0.9116 (143 actual)\n","      nmod: p 0.8021 r 0.8027 f1 0.8024 (1166 actual)\n","     nsubj: p 0.7612 r 0.7523 f1 0.7568 (428 actual)\n","nsubj:pass: p 0.6798 r 0.8364 f1 0.7500 (165 actual)\n","    nummod: p 0.8675 r 0.8675 f1 0.8675 (83 actual)\n","       obj: p 0.8503 r 0.8606 f1 0.8554 (330 actual)\n","       obl: p 0.7880 r 0.8265 f1 0.8068 (634 actual)\n"," obl:agent: p 0.4286 r 0.1200 f1 0.1875 (25 actual)\n","    orphan: p 1.0000 r 0.1429 f1 0.2500 (7 actual)\n"," parataxis: p 0.0000 r 0.0000 f1 0.0000 (15 actual)\n","     punct: p 0.7931 r 0.7931 f1 0.7931 (1039 actual)\n","      root: p 0.9404 r 0.9404 f1 0.9404 (403 actual)\n","  vocative: p 0.6667 r 0.8571 f1 0.7500 (7 actual)\n","     xcomp: p 0.7576 r 0.5952 f1 0.6667 (84 actual)\n","2024-03-17 14:50:44 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 14:50:44 INFO: 86.10\t79.18\t80.36\n","2024-03-17 14:50:44 INFO: Parser score:\n","2024-03-17 14:50:44 INFO: el_gdt 86.10\n","2024-03-17 14:50:45 INFO: Finished running dev set on\n","UD_Greek-GDT\n","  UAS   LAS  CLAS  MLAS  BLEX\n","88.70 86.10 80.36 79.18 80.36\n"]}]},{"cell_type":"markdown","source":["##### RU"],"metadata":{"id":"LBekKfIwGcNT"}},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_tokenizer_treebank UD_Russian-GSD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeNxXKqFx7LM","executionInfo":{"status":"ok","timestamp":1710687070365,"user_tz":-60,"elapsed":8300,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"6bb9ecc3-3aec-4f29-e0d3-522f1f6dfe87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:51:05 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_tokenizer_treebank.py UD_Russian-GSD\n","Preparing data for UD_Russian-GSD: ru_gsd, ru\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-train.conllu and writing to ../data/processed/tokenize/ru_gsd.train.gold.conllu\n","Augmented 0 quotes: Counter()\n","Swapped 'w1, w2' for 'w1 ,w2' 39 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Changed 4 sentences to use fancy unicode ellipses\n","Added 72 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-dev.conllu and writing to ../data/processed/tokenize/ru_gsd.dev.gold.conllu\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-test.conllu and writing to ../data/processed/tokenize/ru_gsd.test.gold.conllu\n","Tokenizer labels written to ../data/processed/tokenize/ru_gsd-ud-train.toklabels\n","  0 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/ru_gsd-ud-train-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/ru_gsd-ud-dev.toklabels\n","  0 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/ru_gsd-ud-dev-mwt.json\n","Tokenizer labels written to ../data/processed/tokenize/ru_gsd-ud-test.toklabels\n","  0 unique MWTs found in data.  MWTs written to ../data/processed/tokenize/ru_gsd-ud-test-mwt.json\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_tokenizer UD_Russian-GSD --step 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HHgN_2tnx7LO","executionInfo":{"status":"ok","timestamp":1710687208253,"user_tz":-60,"elapsed":30475,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f3c17fff-63eb-4d0d-b57a-79fe95811334"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:53:00 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_tokenizer.py UD_Russian-GSD --step 1000\n","2024-03-17 14:53:00 DEBUG: UD_Russian-GSD: ru_gsd\n","2024-03-17 14:53:00 INFO: Save file for ru_gsd model: ru_gsd_tokenizer.pt\n","2024-03-17 14:53:00 INFO: UD_Russian-GSD: saved_models/tokenize/ru_gsd_tokenizer.pt does not exist, training new model\n","2024-03-17 14:53:00 INFO: Running train step with args: ['--label_file', '../data/processed/tokenize/ru_gsd-ud-train.toklabels', '--txt_file', '../data/processed/tokenize/ru_gsd.train.txt', '--lang', 'ru', '--max_seqlen', '400', '--mwt_json_file', '../data/processed/tokenize/ru_gsd-ud-dev-mwt.json', '--dev_txt_file', '../data/processed/tokenize/ru_gsd.dev.txt', '--dev_label_file', '../data/processed/tokenize/ru_gsd-ud-dev.toklabels', '--dev_conll_gold', '../data/processed/tokenize/ru_gsd.dev.gold.conllu', '--conll_file', '/tmp/tmp0hcwpe_8', '--shorthand', 'ru_gsd', '--step', '1000', '--save_name', 'ru_gsd_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:53:00 INFO: Running tokenizer in train mode\n","2024-03-17 14:53:02 DEBUG: 3901 sentences loaded.\n","2024-03-17 14:53:02 INFO: Found no mwts in the training data.  Setting use_mwt to False\n","2024-03-17 14:53:02 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:53:04 INFO: Step     20/  1000 Loss: 0.460\n","2024-03-17 14:53:05 INFO: Step     40/  1000 Loss: 0.377\n","2024-03-17 14:53:05 INFO: Step     60/  1000 Loss: 0.250\n","2024-03-17 14:53:05 INFO: Step     80/  1000 Loss: 0.165\n","2024-03-17 14:53:06 INFO: Step    100/  1000 Loss: 0.114\n","2024-03-17 14:53:06 INFO: Step    120/  1000 Loss: 0.076\n","2024-03-17 14:53:06 INFO: Step    140/  1000 Loss: 0.074\n","2024-03-17 14:53:06 INFO: Step    160/  1000 Loss: 0.061\n","2024-03-17 14:53:07 INFO: Step    180/  1000 Loss: 0.059\n","2024-03-17 14:53:07 INFO: Step    200/  1000 Loss: 0.054\n","2024-03-17 14:53:08 INFO: ru_gsd: token F1 = 97.96, sentence F1 = 89.53, mwt F1 = 97.96\n","2024-03-17 14:53:08 INFO: Model saved to saved_models/tokenize/ru_gsd_tokenizer.pt\n","2024-03-17 14:53:08 INFO: Dev score: 93.575\tNew best dev score!\n","2024-03-17 14:53:08 INFO: Step    220/  1000 Loss: 0.054\n","2024-03-17 14:53:09 INFO: Step    240/  1000 Loss: 0.051\n","2024-03-17 14:53:09 INFO: Step    260/  1000 Loss: 0.047\n","2024-03-17 14:53:09 INFO: Step    280/  1000 Loss: 0.055\n","2024-03-17 14:53:09 INFO: Step    300/  1000 Loss: 0.040\n","2024-03-17 14:53:10 INFO: Step    320/  1000 Loss: 0.046\n","2024-03-17 14:53:10 INFO: Step    340/  1000 Loss: 0.038\n","2024-03-17 14:53:10 INFO: Step    360/  1000 Loss: 0.039\n","2024-03-17 14:53:10 INFO: Step    380/  1000 Loss: 0.045\n","2024-03-17 14:53:11 INFO: Step    400/  1000 Loss: 0.037\n","2024-03-17 14:53:12 INFO: ru_gsd: token F1 = 98.76, sentence F1 = 90.85, mwt F1 = 98.76\n","2024-03-17 14:53:12 INFO: Model saved to saved_models/tokenize/ru_gsd_tokenizer.pt\n","2024-03-17 14:53:12 INFO: Dev score: 94.657\tNew best dev score!\n","2024-03-17 14:53:12 INFO: Step    420/  1000 Loss: 0.039\n","2024-03-17 14:53:12 INFO: Step    440/  1000 Loss: 0.042\n","2024-03-17 14:53:12 INFO: Step    460/  1000 Loss: 0.042\n","2024-03-17 14:53:13 INFO: Step    480/  1000 Loss: 0.039\n","2024-03-17 14:53:13 INFO: Step    500/  1000 Loss: 0.038\n","2024-03-17 14:53:13 INFO: Step    520/  1000 Loss: 0.034\n","2024-03-17 14:53:13 INFO: Step    540/  1000 Loss: 0.038\n","2024-03-17 14:53:14 INFO: Step    560/  1000 Loss: 0.032\n","2024-03-17 14:53:14 INFO: Step    580/  1000 Loss: 0.034\n","2024-03-17 14:53:14 INFO: Step    600/  1000 Loss: 0.035\n","2024-03-17 14:53:15 INFO: ru_gsd: token F1 = 99.14, sentence F1 = 93.32, mwt F1 = 99.14\n","2024-03-17 14:53:15 INFO: Model saved to saved_models/tokenize/ru_gsd_tokenizer.pt\n","2024-03-17 14:53:15 INFO: Dev score: 96.157\tNew best dev score!\n","2024-03-17 14:53:15 INFO: Step    620/  1000 Loss: 0.037\n","2024-03-17 14:53:16 INFO: Step    640/  1000 Loss: 0.032\n","2024-03-17 14:53:16 INFO: Step    660/  1000 Loss: 0.032\n","2024-03-17 14:53:16 INFO: Step    680/  1000 Loss: 0.037\n","2024-03-17 14:53:17 INFO: Step    700/  1000 Loss: 0.034\n","2024-03-17 14:53:17 INFO: Step    720/  1000 Loss: 0.035\n","2024-03-17 14:53:17 INFO: Step    740/  1000 Loss: 0.034\n","2024-03-17 14:53:18 INFO: Step    760/  1000 Loss: 0.033\n","2024-03-17 14:53:18 INFO: Step    780/  1000 Loss: 0.031\n","2024-03-17 14:53:18 INFO: Step    800/  1000 Loss: 0.034\n","2024-03-17 14:53:20 INFO: ru_gsd: token F1 = 99.31, sentence F1 = 93.43, mwt F1 = 99.31\n","2024-03-17 14:53:20 INFO: Model saved to saved_models/tokenize/ru_gsd_tokenizer.pt\n","2024-03-17 14:53:20 INFO: Dev score: 96.293\tNew best dev score!\n","2024-03-17 14:53:20 INFO: Step    820/  1000 Loss: 0.029\n","2024-03-17 14:53:20 INFO: Step    840/  1000 Loss: 0.030\n","2024-03-17 14:53:20 INFO: Step    860/  1000 Loss: 0.029\n","2024-03-17 14:53:21 INFO: Step    880/  1000 Loss: 0.029\n","2024-03-17 14:53:21 INFO: Step    900/  1000 Loss: 0.025\n","2024-03-17 14:53:21 INFO: Step    920/  1000 Loss: 0.030\n","2024-03-17 14:53:21 INFO: Step    940/  1000 Loss: 0.030\n","2024-03-17 14:53:22 INFO: Step    960/  1000 Loss: 0.027\n","2024-03-17 14:53:22 INFO: Step    980/  1000 Loss: 0.027\n","2024-03-17 14:53:22 INFO: Step   1000/  1000 Loss: 0.033\n","2024-03-17 14:53:23 INFO: ru_gsd: token F1 = 99.36, sentence F1 = 94.46, mwt F1 = 99.36\n","2024-03-17 14:53:23 INFO: Model saved to saved_models/tokenize/ru_gsd_tokenizer.pt\n","2024-03-17 14:53:23 INFO: Dev score: 96.862\tNew best dev score!\n","2024-03-17 14:53:23 INFO: Best dev score=0.9686151569523133 at step 1000\n","2024-03-17 14:53:23 INFO: Running dev step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/ru_gsd.dev.txt', '--lang', 'ru', '--conll_file', '/tmp/tmp0hcwpe_8', '--shorthand', 'ru_gsd', '--mwt_json_file', '../data/processed/tokenize/ru_gsd-ud-dev-mwt.json', '--step', '1000', '--save_name', 'ru_gsd_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:53:23 INFO: Running tokenizer in predict mode\n","2024-03-17 14:53:23 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:53:24 INFO: OOV rate:  0.003% (     2/ 71303)\n","2024-03-17 14:53:25 INFO: Finished running dev set on\n","UD_Russian-GSD\n","   Tokens Sentences     Words\n","    99.36     94.46     99.36\n","2024-03-17 14:53:25 INFO: Running test step with args: ['--mode', 'predict', '--txt_file', '../data/processed/tokenize/ru_gsd.test.txt', '--lang', 'ru', '--conll_file', '/tmp/tmp0hcwpe_8', '--shorthand', 'ru_gsd', '--mwt_json_file', '../data/processed/tokenize/ru_gsd-ud-test-mwt.json', '--step', '1000', '--save_name', 'ru_gsd_tokenizer.pt', '--save_dir', 'saved_models/tokenize']\n","2024-03-17 14:53:25 INFO: Running tokenizer in predict mode\n","2024-03-17 14:53:25 DEBUG: Building Adam with lr=0.002000, betas=(0.9, 0.9), eps=0.000000, weight_decay=0.0\n","2024-03-17 14:53:26 INFO: OOV rate:  0.066% (    46/ 69607)\n","2024-03-17 14:53:27 INFO: Finished running test set on\n","UD_Russian-GSD\n","   Tokens Sentences     Words\n","    99.48     95.75     99.48\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_pos_treebank UD_Russian-GSD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jtlIsiyx7LO","executionInfo":{"status":"ok","timestamp":1710687220321,"user_tz":-60,"elapsed":5106,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"57fb671e-a922-4fa5-e6b0-d9132eccff6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:53:38 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_pos_treebank.py UD_Russian-GSD\n","Preparing data for UD_Russian-GSD: ru_gsd, ru\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-train.conllu and writing to /tmp/tmpjhw2xtha/ru_gsd.train.gold.conllu\n","Augmented 0 quotes: Counter()\n","Swapped 'w1, w2' for 'w1 ,w2' 39 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Changed 4 sentences to use fancy unicode ellipses\n","Added 72 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-dev.conllu and writing to /tmp/tmpjhw2xtha/ru_gsd.dev.gold.conllu\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-test.conllu and writing to /tmp/tmpjhw2xtha/ru_gsd.test.gold.conllu\n","Copying from /tmp/tmpjhw2xtha/ru_gsd.train.gold.conllu to ../data/processed/pos/ru_gsd.train.in.conllu\n","Copying from /tmp/tmpjhw2xtha/ru_gsd.dev.gold.conllu to ../data/processed/pos/ru_gsd.dev.in.conllu\n","Copying from /tmp/tmpjhw2xtha/ru_gsd.test.gold.conllu to ../data/processed/pos/ru_gsd.test.in.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_pos UD_Russian-GSD --max_steps 500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qk8sjadRx7LP","executionInfo":{"status":"ok","timestamp":1710687686687,"user_tz":-60,"elapsed":463958,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"f96babe5-3581-4566-9093-cda02e1242d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 14:53:45 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_pos.py UD_Russian-GSD --max_steps 500\n","2024-03-17 14:53:45 DEBUG: UD_Russian-GSD: ru_gsd\n","2024-03-17 14:53:45 DEBUG: Downloading resource file from https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json\n","\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0% 0.00/46.6k [00:00<?, ?B/s]\rDownloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 19.7MB/s]        \n","2024-03-17 14:53:45 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-17 14:53:45 DEBUG: Processing parameter \"processors\"...\n","2024-03-17 14:53:45 DEBUG: Found forward_charlm: newswiki.\n","2024-03-17 14:53:45 DEBUG: Found dependencies [] for processor forward_charlm model newswiki\n","2024-03-17 14:53:45 INFO: Downloading these customized packages for language: ru (Russian)...\n","=============================\n","| Processor      | Package  |\n","-----------------------------\n","| forward_charlm | newswiki |\n","=============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/forward_charlm/newswiki.pt: 100% 20.0M/20.0M [00:00<00:00, 55.2MB/s]\n","2024-03-17 14:53:46 INFO: Downloaded file to /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 14:53:46 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-17 14:53:46 INFO: Downloaded model, using model /root/stanza_resources/ru/forward_charlm/newswiki.pt for forward charlm\n","2024-03-17 14:53:46 DEBUG: Downloading resource file from https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 20.4MB/s]        \n","2024-03-17 14:53:46 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-17 14:53:46 DEBUG: Processing parameter \"processors\"...\n","2024-03-17 14:53:46 DEBUG: Found backward_charlm: newswiki.\n","2024-03-17 14:53:46 DEBUG: Found dependencies [] for processor backward_charlm model newswiki\n","2024-03-17 14:53:46 INFO: Downloading these customized packages for language: ru (Russian)...\n","==============================\n","| Processor       | Package  |\n","------------------------------\n","| backward_charlm | newswiki |\n","==============================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/backward_charlm/newswiki.pt: 100% 20.0M/20.0M [00:00<00:00, 65.9MB/s]\n","2024-03-17 14:53:47 INFO: Downloaded file to /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 14:53:47 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-17 14:53:47 INFO: Downloaded model, using model /root/stanza_resources/ru/backward_charlm/newswiki.pt for backward charlm\n","2024-03-17 14:53:47 INFO: Default pretrain should be /root/stanza_resources/ru/pretrain/conll17.pt  Attempting to download\n","2024-03-17 14:53:47 DEBUG: Downloading resource file from https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json\n","Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 373kB [00:00, 19.6MB/s]        \n","2024-03-17 14:53:47 INFO: Downloaded file to /root/stanza_resources/resources.json\n","2024-03-17 14:53:47 DEBUG: Processing parameter \"processors\"...\n","2024-03-17 14:53:47 DEBUG: Found pretrain: conll17.\n","2024-03-17 14:53:47 DEBUG: Found dependencies [] for processor pretrain model conll17\n","2024-03-17 14:53:47 INFO: Downloading these customized packages for language: ru (Russian)...\n","=======================\n","| Processor | Package |\n","-----------------------\n","| pretrain  | conll17 |\n","=======================\n","\n","Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/pretrain/conll17.pt: 100% 109M/109M [00:01<00:00, 75.6MB/s]\n","2024-03-17 14:53:49 INFO: Downloaded file to /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 14:53:49 INFO: Finished downloading models and saved to /root/stanza_resources\n","2024-03-17 14:53:49 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:53:49 INFO: UD_Russian-GSD: saved_models/pos/ru_gsd_charlm_tagger.pt does not exist, training new model\n","2024-03-17 14:53:49 INFO: Using model /root/stanza_resources/ru/forward_charlm/newswiki.pt for forward charlm\n","2024-03-17 14:53:49 INFO: Using model /root/stanza_resources/ru/backward_charlm/newswiki.pt for backward charlm\n","2024-03-17 14:53:49 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 14:53:49 INFO: Running train POS for UD_Russian-GSD with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/pos/ru_gsd.train.in.conllu', '--output_file', '/tmp/tmp9rsa3bj5', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'train', '--eval_file', '../data/processed/pos/ru_gsd.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--max_steps', '500']\n","2024-03-17 14:53:49 INFO: Running tagger in train mode\n","2024-03-17 14:53:49 INFO: Using pretrained contextualized char embedding\n","2024-03-17 14:53:49 INFO: Loading data with batch size 250...\n","2024-03-17 14:53:49 INFO: Reading ../data/processed/pos/ru_gsd.train.in.conllu\n","2024-03-17 14:53:50 INFO: Train File ../data/processed/pos/ru_gsd.train.in.conllu, Data Size: 3922\n","2024-03-17 14:53:53 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 14:53:55 INFO: Training tagger...\n","2024-03-17 14:53:55 DEBUG: POS model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 14:53:55 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 14:53:55 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 14:53:56 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 14:53:56 INFO: Evaluating the model every 100 steps...\n","2024-03-17 14:54:14 INFO: Finished STEP 20/500, loss = 5.921406 (0.709 sec/batch), lr: 0.003000\n","2024-03-17 14:54:30 INFO: Finished STEP 40/500, loss = 4.362209 (0.703 sec/batch), lr: 0.003000\n","2024-03-17 14:54:48 INFO: Finished STEP 60/500, loss = 3.398192 (0.706 sec/batch), lr: 0.003000\n","2024-03-17 14:55:05 INFO: Finished STEP 80/500, loss = 3.027094 (0.614 sec/batch), lr: 0.003000\n","2024-03-17 14:55:22 INFO: Finished STEP 100/500, loss = 2.463830 (0.716 sec/batch), lr: 0.003000\n","2024-03-17 14:55:22 INFO: Evaluating on dev set...\n","2024-03-17 14:55:25 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:55:25 INFO: 96.16\t95.14\t74.22\t72.45\n","2024-03-17 14:55:25 INFO: step 100: train_loss = 5.324582, dev_score = 0.7245\n","2024-03-17 14:55:25 INFO: Model saved to saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 14:55:25 INFO: new best model saved.\n","2024-03-17 14:55:42 INFO: Finished STEP 120/500, loss = 2.321104 (0.689 sec/batch), lr: 0.003000\n","2024-03-17 14:55:59 INFO: Finished STEP 140/500, loss = 2.227301 (0.717 sec/batch), lr: 0.003000\n","2024-03-17 14:56:16 INFO: Finished STEP 160/500, loss = 2.088906 (0.712 sec/batch), lr: 0.003000\n","2024-03-17 14:56:33 INFO: Finished STEP 180/500, loss = 1.978679 (0.768 sec/batch), lr: 0.003000\n","2024-03-17 14:56:50 INFO: Finished STEP 200/500, loss = 2.005113 (0.702 sec/batch), lr: 0.003000\n","2024-03-17 14:56:50 INFO: Evaluating on dev set...\n","2024-03-17 14:56:54 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:56:54 INFO: 97.43\t96.36\t85.06\t83.64\n","2024-03-17 14:56:54 INFO: step 200: train_loss = 2.176192, dev_score = 0.8364\n","2024-03-17 14:56:54 INFO: Model saved to saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 14:56:54 INFO: new best model saved.\n","2024-03-17 14:57:11 INFO: Finished STEP 220/500, loss = 2.018593 (0.745 sec/batch), lr: 0.003000\n","2024-03-17 14:57:28 INFO: Finished STEP 240/500, loss = 1.842210 (0.610 sec/batch), lr: 0.003000\n","2024-03-17 14:57:45 INFO: Finished STEP 260/500, loss = 1.804407 (0.735 sec/batch), lr: 0.003000\n","2024-03-17 14:58:02 INFO: Finished STEP 280/500, loss = 1.734155 (0.758 sec/batch), lr: 0.003000\n","2024-03-17 14:58:19 INFO: Finished STEP 300/500, loss = 1.775995 (0.704 sec/batch), lr: 0.003000\n","2024-03-17 14:58:19 INFO: Evaluating on dev set...\n","2024-03-17 14:58:22 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:58:22 INFO: 97.78\t96.92\t87.86\t86.45\n","2024-03-17 14:58:22 INFO: step 300: train_loss = 1.818544, dev_score = 0.8645\n","2024-03-17 14:58:23 INFO: Model saved to saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 14:58:23 INFO: new best model saved.\n","2024-03-17 14:58:39 INFO: Finished STEP 320/500, loss = 1.656040 (0.627 sec/batch), lr: 0.003000\n","2024-03-17 14:58:56 INFO: Finished STEP 340/500, loss = 1.593261 (0.750 sec/batch), lr: 0.003000\n","2024-03-17 14:59:13 INFO: Finished STEP 360/500, loss = 1.654518 (0.756 sec/batch), lr: 0.003000\n","2024-03-17 14:59:31 INFO: Finished STEP 380/500, loss = 1.583664 (0.729 sec/batch), lr: 0.003000\n","2024-03-17 14:59:48 INFO: Finished STEP 400/500, loss = 1.532802 (0.611 sec/batch), lr: 0.003000\n","2024-03-17 14:59:48 INFO: Evaluating on dev set...\n","2024-03-17 14:59:50 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 14:59:50 INFO: 97.88\t96.95\t89.25\t87.84\n","2024-03-17 14:59:50 INFO: step 400: train_loss = 1.643182, dev_score = 0.8784\n","2024-03-17 14:59:51 INFO: Model saved to saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 14:59:51 INFO: new best model saved.\n","2024-03-17 15:00:08 INFO: Finished STEP 420/500, loss = 1.533316 (0.687 sec/batch), lr: 0.003000\n","2024-03-17 15:00:25 INFO: Finished STEP 440/500, loss = 1.497339 (0.661 sec/batch), lr: 0.003000\n","2024-03-17 15:00:42 INFO: Finished STEP 460/500, loss = 1.535933 (0.750 sec/batch), lr: 0.003000\n","2024-03-17 15:00:59 INFO: Finished STEP 480/500, loss = 1.552212 (0.596 sec/batch), lr: 0.003000\n","2024-03-17 15:01:16 INFO: Finished STEP 500/500, loss = 1.450301 (0.736 sec/batch), lr: 0.003000\n","2024-03-17 15:01:16 INFO: Evaluating on dev set...\n","2024-03-17 15:01:19 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 15:01:19 INFO: 97.89\t97.02\t90.07\t88.70\n","2024-03-17 15:01:19 INFO: step 500: train_loss = 1.536458, dev_score = 0.8870\n","2024-03-17 15:01:19 INFO: Model saved to saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 15:01:19 INFO: new best model saved.\n","2024-03-17 15:01:19 INFO: Training ended with 500 steps.\n","2024-03-17 15:01:19 INFO: Best dev F1 = 88.70, at iteration = 500\n","2024-03-17 15:01:19 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 15:01:19 INFO: Running dev POS for UD_Russian-GSD with args ['--wordvec_dir', '../data/wordvec', '--output_file', '/tmp/tmp9rsa3bj5', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'predict', '--eval_file', '../data/processed/pos/ru_gsd.dev.in.conllu', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--max_steps', '500']\n","2024-03-17 15:01:19 INFO: Running tagger in predict mode\n","2024-03-17 15:01:19 INFO: Loading model from: saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 15:01:19 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:01:19 DEBUG: POS model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:01:19 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:01:19 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:01:19 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:01:19 INFO: Loading data with batch size 250...\n","2024-03-17 15:01:20 INFO: Start evaluation...\n","2024-03-17 15:01:24 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 15:01:24 INFO: 97.89\t97.02\t90.07\t88.70\n","2024-03-17 15:01:24 INFO: POS Tagger score: ru_gsd 88.70\n","2024-03-17 15:01:25 INFO: Finished running dev set on\n","UD_Russian-GSD\n","   UPOS    XPOS  UFeats AllTags\n","  97.89   97.02   90.07   88.70\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.datasets.prepare_depparse_treebank UD_Russian-GSD"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqIgyhBdx7LP","executionInfo":{"status":"ok","timestamp":1710687748620,"user_tz":-60,"elapsed":38034,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"8cb1882e-e161-4d69-cbc3-67d431250c94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 15:01:53 INFO: Datasets program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/datasets/prepare_depparse_treebank.py UD_Russian-GSD\n","2024-03-17 15:01:53 INFO: Using tagger model in saved_models/pos/ru_gsd_charlm_tagger.pt for ru_gsd\n","2024-03-17 15:01:53 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 15:01:53 INFO: Using model /root/stanza_resources/ru/forward_charlm/newswiki.pt for forward charlm\n","2024-03-17 15:01:53 INFO: Using model /root/stanza_resources/ru/backward_charlm/newswiki.pt for backward charlm\n","Preparing data for UD_Russian-GSD: ru_gsd, ru\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-train.conllu and writing to /tmp/tmpzummupqa/ru_gsd.train.gold.conllu\n","Augmented 0 quotes: Counter()\n","Swapped 'w1, w2' for 'w1 ,w2' 39 times\n","Added 0 new sentences with asdf, zzzz -> asdf,zzzz\n","Changed 4 sentences to use fancy unicode ellipses\n","Added 72 sentences with parens replaced with square brackets\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-dev.conllu and writing to /tmp/tmpzummupqa/ru_gsd.dev.gold.conllu\n","Reading from ../data/udbase/UD_Russian-GSD/ru_gsd-ud-test.conllu and writing to /tmp/tmpzummupqa/ru_gsd.test.gold.conllu\n","2024-03-17 15:01:54 INFO: Running tagger to retag /tmp/tmpzummupqa/ru_gsd.train.gold.conllu to ../data/processed/depparse/ru_gsd.train.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'ru_gsd_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpzummupqa/ru_gsd.train.gold.conllu', '--output_file', '../data/processed/depparse/ru_gsd.train.in.conllu']\n","2024-03-17 15:01:54 INFO: Running tagger in predict mode\n","2024-03-17 15:01:54 INFO: Loading model from: saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 15:01:54 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:01:54 DEBUG: POS model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:01:54 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:01:54 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:01:55 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:01:55 INFO: Loading data with batch size 250...\n","2024-03-17 15:02:00 INFO: Start evaluation...\n","2024-03-17 15:02:17 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 15:02:17 INFO: 98.36\t98.13\t91.95\t91.25\n","2024-03-17 15:02:17 INFO: POS Tagger score: ru_gsd 91.25\n","2024-03-17 15:02:17 INFO: Running tagger to retag /tmp/tmpzummupqa/ru_gsd.dev.gold.conllu to ../data/processed/depparse/ru_gsd.dev.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'ru_gsd_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpzummupqa/ru_gsd.dev.gold.conllu', '--output_file', '../data/processed/depparse/ru_gsd.dev.in.conllu']\n","2024-03-17 15:02:17 INFO: Running tagger in predict mode\n","2024-03-17 15:02:17 INFO: Loading model from: saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 15:02:18 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:02:18 DEBUG: POS model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:18 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:02:18 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:18 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:02:18 INFO: Loading data with batch size 250...\n","2024-03-17 15:02:18 INFO: Start evaluation...\n","2024-03-17 15:02:22 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 15:02:22 INFO: 97.89\t97.02\t90.07\t88.70\n","2024-03-17 15:02:22 INFO: POS Tagger score: ru_gsd 88.70\n","2024-03-17 15:02:22 INFO: Running tagger to retag /tmp/tmpzummupqa/ru_gsd.test.gold.conllu to ../data/processed/depparse/ru_gsd.test.in.conllu\n","  Args: ['--wordvec_dir', '../data/wordvec', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'predict', '--save_dir', 'saved_models/pos', '--save_name', 'ru_gsd_charlm_tagger.pt', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--eval_file', '/tmp/tmpzummupqa/ru_gsd.test.gold.conllu', '--output_file', '../data/processed/depparse/ru_gsd.test.in.conllu']\n","2024-03-17 15:02:22 INFO: Running tagger in predict mode\n","2024-03-17 15:02:22 INFO: Loading model from: saved_models/pos/ru_gsd_charlm_tagger.pt\n","2024-03-17 15:02:22 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:02:22 DEBUG: POS model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:22 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:02:22 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:22 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:02:22 INFO: Loading data with batch size 250...\n","2024-03-17 15:02:23 INFO: Start evaluation...\n","2024-03-17 15:02:27 INFO: UPOS\tXPOS\tUFeats\tAllTags\n","2024-03-17 15:02:27 INFO: 97.59\t97.28\t90.03\t88.98\n","2024-03-17 15:02:27 INFO: POS Tagger score: ru_gsd 88.98\n","Copying from ../data/processed/depparse/ru_gsd.dev.in.conllu to ../data/processed/depparse/ru_gsd.dev.gold.conllu\n","Copying from ../data/processed/depparse/ru_gsd.test.in.conllu to ../data/processed/depparse/ru_gsd.test.gold.conllu\n"]}]},{"cell_type":"code","source":["!cd /content/gdrive/MyDrive/PLN/3/stanza-train/stanza && source scripts/config.sh && python3 -m stanza.utils.training.run_depparse UD_Russian-GSD --max_steps 1000"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X6E-CbV-x7LQ","executionInfo":{"status":"ok","timestamp":1710688510726,"user_tz":-60,"elapsed":745578,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"53dd0689-1084-465a-c849-0559325ce4b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-17 15:02:48 INFO: Training program called with:\n","/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/stanza/utils/training/run_depparse.py UD_Russian-GSD --max_steps 1000\n","2024-03-17 15:02:48 DEBUG: UD_Russian-GSD: ru_gsd\n","2024-03-17 15:02:48 INFO: Using model /root/stanza_resources/ru/forward_charlm/newswiki.pt for forward charlm\n","2024-03-17 15:02:48 INFO: Using model /root/stanza_resources/ru/backward_charlm/newswiki.pt for backward charlm\n","2024-03-17 15:02:48 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 15:02:48 INFO: UD_Russian-GSD: saved_models/depparse/ru_gsd_charlm_parser.pt does not exist, training new model\n","2024-03-17 15:02:48 INFO: Using model /root/stanza_resources/ru/forward_charlm/newswiki.pt for forward charlm\n","2024-03-17 15:02:48 INFO: Using model /root/stanza_resources/ru/backward_charlm/newswiki.pt for backward charlm\n","2024-03-17 15:02:48 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 15:02:48 INFO: Running train depparse for UD_Russian-GSD with args ['--wordvec_dir', '../data/wordvec', '--train_file', '../data/processed/depparse/ru_gsd.train.in.conllu', '--eval_file', '../data/processed/depparse/ru_gsd.dev.in.conllu', '--output_file', '/tmp/tmptgv9l2b2', '--gold_file', '../data/processed/depparse/ru_gsd.dev.gold.conllu', '--batch_size', '5000', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'train', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--max_steps', '1000']\n","2024-03-17 15:02:48 INFO: Running parser in train mode\n","2024-03-17 15:02:48 INFO: Using pretrained contextualized char embedding\n","2024-03-17 15:02:48 INFO: Loading data with batch size 5000...\n","2024-03-17 15:02:49 INFO: Original data size: 3922\n","2024-03-17 15:02:49 INFO: Augmented data size: 4258\n","2024-03-17 15:02:51 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:02:53 DEBUG: 18 batches created.\n","2024-03-17 15:02:53 DEBUG: 3 batches created.\n","2024-03-17 15:02:53 INFO: Training parser...\n","2024-03-17 15:02:53 DEBUG: Depparse model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:53 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:02:54 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:02:54 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:03:08 INFO: Finished STEP 20/1000, loss = 7.308109 (0.553 sec/batch), lr: 0.003000\n","2024-03-17 15:03:22 INFO: Finished STEP 40/1000, loss = 10.553486 (0.728 sec/batch), lr: 0.003000\n","2024-03-17 15:03:36 INFO: Finished STEP 60/1000, loss = 3.929049 (0.474 sec/batch), lr: 0.003000\n","2024-03-17 15:03:49 INFO: Finished STEP 80/1000, loss = 4.621572 (0.551 sec/batch), lr: 0.003000\n","2024-03-17 15:04:03 INFO: Finished STEP 100/1000, loss = 3.238190 (0.513 sec/batch), lr: 0.003000\n","2024-03-17 15:04:03 INFO: Evaluating on dev set...\n","2024-03-17 15:04:06 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:04:06 INFO: 55.35\t46.12\t48.90\n","2024-03-17 15:04:06 INFO: step 100: train_loss = 10.620290, dev_score = 0.5535\n","2024-03-17 15:04:06 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:04:06 INFO: new best model saved.\n","2024-03-17 15:04:08 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:04:08 INFO: new model checkpoint saved.\n","2024-03-17 15:04:23 INFO: Finished STEP 120/1000, loss = 3.957057 (0.591 sec/batch), lr: 0.003000\n","2024-03-17 15:04:36 INFO: Finished STEP 140/1000, loss = 3.506552 (0.463 sec/batch), lr: 0.003000\n","2024-03-17 15:04:50 INFO: Finished STEP 160/1000, loss = 3.068442 (0.403 sec/batch), lr: 0.003000\n","2024-03-17 15:05:04 INFO: Finished STEP 180/1000, loss = 4.036694 (0.649 sec/batch), lr: 0.003000\n","2024-03-17 15:05:17 INFO: Finished STEP 200/1000, loss = 2.521443 (0.522 sec/batch), lr: 0.003000\n","2024-03-17 15:05:17 INFO: Evaluating on dev set...\n","2024-03-17 15:05:20 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:05:20 INFO: 70.71\t65.32\t66.73\n","2024-03-17 15:05:20 INFO: step 200: train_loss = 3.765229, dev_score = 0.7071\n","2024-03-17 15:05:20 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:05:20 INFO: new best model saved.\n","2024-03-17 15:05:22 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:05:22 INFO: new model checkpoint saved.\n","2024-03-17 15:05:35 INFO: Finished STEP 220/1000, loss = 4.303423 (0.753 sec/batch), lr: 0.003000\n","2024-03-17 15:05:49 INFO: Finished STEP 240/1000, loss = 2.832374 (0.514 sec/batch), lr: 0.003000\n","2024-03-17 15:06:02 INFO: Finished STEP 260/1000, loss = 1.721102 (0.523 sec/batch), lr: 0.003000\n","2024-03-17 15:06:16 INFO: Finished STEP 280/1000, loss = 1.764270 (0.521 sec/batch), lr: 0.003000\n","2024-03-17 15:06:29 INFO: Finished STEP 300/1000, loss = 3.513037 (0.738 sec/batch), lr: 0.003000\n","2024-03-17 15:06:29 INFO: Evaluating on dev set...\n","2024-03-17 15:06:32 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:06:32 INFO: 77.00\t72.30\t73.64\n","2024-03-17 15:06:32 INFO: step 300: train_loss = 2.867757, dev_score = 0.7700\n","2024-03-17 15:06:32 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:06:32 INFO: new best model saved.\n","2024-03-17 15:06:34 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:06:34 INFO: new model checkpoint saved.\n","2024-03-17 15:06:47 INFO: Finished STEP 320/1000, loss = 1.876909 (0.420 sec/batch), lr: 0.003000\n","2024-03-17 15:07:01 INFO: Finished STEP 340/1000, loss = 1.149717 (0.213 sec/batch), lr: 0.003000\n","2024-03-17 15:07:14 INFO: Finished STEP 360/1000, loss = 1.765387 (0.545 sec/batch), lr: 0.003000\n","2024-03-17 15:07:28 INFO: Finished STEP 380/1000, loss = 2.142308 (0.465 sec/batch), lr: 0.003000\n","2024-03-17 15:07:42 INFO: Finished STEP 400/1000, loss = 2.138091 (0.417 sec/batch), lr: 0.003000\n","2024-03-17 15:07:42 INFO: Evaluating on dev set...\n","2024-03-17 15:07:45 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:07:45 INFO: 80.09\t75.91\t77.17\n","2024-03-17 15:07:45 INFO: step 400: train_loss = 2.377532, dev_score = 0.8009\n","2024-03-17 15:07:45 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:07:45 INFO: new best model saved.\n","2024-03-17 15:07:47 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:07:47 INFO: new model checkpoint saved.\n","2024-03-17 15:08:00 INFO: Finished STEP 420/1000, loss = 1.363824 (0.513 sec/batch), lr: 0.003000\n","2024-03-17 15:08:14 INFO: Finished STEP 440/1000, loss = 1.613412 (0.540 sec/batch), lr: 0.003000\n","2024-03-17 15:08:28 INFO: Finished STEP 460/1000, loss = 1.439954 (0.512 sec/batch), lr: 0.003000\n","2024-03-17 15:08:41 INFO: Finished STEP 480/1000, loss = 1.628726 (0.518 sec/batch), lr: 0.003000\n","2024-03-17 15:08:54 INFO: Finished STEP 500/1000, loss = 2.356814 (0.593 sec/batch), lr: 0.003000\n","2024-03-17 15:08:54 INFO: Evaluating on dev set...\n","2024-03-17 15:08:57 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:08:57 INFO: 82.12\t78.30\t79.29\n","2024-03-17 15:08:57 INFO: step 500: train_loss = 2.048918, dev_score = 0.8212\n","2024-03-17 15:08:57 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:08:57 INFO: new best model saved.\n","2024-03-17 15:08:59 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:08:59 INFO: new model checkpoint saved.\n","2024-03-17 15:09:12 INFO: Finished STEP 520/1000, loss = 1.512416 (0.486 sec/batch), lr: 0.003000\n","2024-03-17 15:09:26 INFO: Finished STEP 540/1000, loss = 1.886422 (0.478 sec/batch), lr: 0.003000\n","2024-03-17 15:09:40 INFO: Finished STEP 560/1000, loss = 1.977106 (0.612 sec/batch), lr: 0.003000\n","2024-03-17 15:09:53 INFO: Finished STEP 580/1000, loss = 1.272417 (0.508 sec/batch), lr: 0.003000\n","2024-03-17 15:10:06 INFO: Finished STEP 600/1000, loss = 1.798722 (0.508 sec/batch), lr: 0.003000\n","2024-03-17 15:10:06 INFO: Evaluating on dev set...\n","2024-03-17 15:10:09 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:10:09 INFO: 83.12\t79.77\t80.68\n","2024-03-17 15:10:09 INFO: step 600: train_loss = 1.961603, dev_score = 0.8312\n","2024-03-17 15:10:09 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:10:09 INFO: new best model saved.\n","2024-03-17 15:10:11 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:10:11 INFO: new model checkpoint saved.\n","2024-03-17 15:10:25 INFO: Finished STEP 620/1000, loss = 1.529690 (0.429 sec/batch), lr: 0.003000\n","2024-03-17 15:10:39 INFO: Finished STEP 640/1000, loss = 1.641365 (0.522 sec/batch), lr: 0.003000\n","2024-03-17 15:10:52 INFO: Finished STEP 660/1000, loss = 2.322880 (0.742 sec/batch), lr: 0.003000\n","2024-03-17 15:11:06 INFO: Finished STEP 680/1000, loss = 1.714805 (0.514 sec/batch), lr: 0.003000\n","2024-03-17 15:11:19 INFO: Finished STEP 700/1000, loss = 1.731384 (0.622 sec/batch), lr: 0.003000\n","2024-03-17 15:11:19 INFO: Evaluating on dev set...\n","2024-03-17 15:11:23 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:11:23 INFO: 83.69\t80.37\t81.36\n","2024-03-17 15:11:23 INFO: step 700: train_loss = 1.873941, dev_score = 0.8369\n","2024-03-17 15:11:24 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:11:24 INFO: new best model saved.\n","2024-03-17 15:11:25 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:11:25 INFO: new model checkpoint saved.\n","2024-03-17 15:11:39 INFO: Finished STEP 720/1000, loss = 1.514569 (0.564 sec/batch), lr: 0.003000\n","2024-03-17 15:11:52 INFO: Finished STEP 740/1000, loss = 1.402011 (0.436 sec/batch), lr: 0.003000\n","2024-03-17 15:12:06 INFO: Finished STEP 760/1000, loss = 2.064798 (0.583 sec/batch), lr: 0.003000\n","2024-03-17 15:12:20 INFO: Finished STEP 780/1000, loss = 1.393379 (0.552 sec/batch), lr: 0.003000\n","2024-03-17 15:12:33 INFO: Finished STEP 800/1000, loss = 1.557639 (0.505 sec/batch), lr: 0.003000\n","2024-03-17 15:12:33 INFO: Evaluating on dev set...\n","2024-03-17 15:12:35 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:12:35 INFO: 84.17\t81.09\t82.04\n","2024-03-17 15:12:35 INFO: step 800: train_loss = 1.721655, dev_score = 0.8417\n","2024-03-17 15:12:36 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:12:36 INFO: new best model saved.\n","2024-03-17 15:12:37 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:12:37 INFO: new model checkpoint saved.\n","2024-03-17 15:12:51 INFO: Finished STEP 820/1000, loss = 1.973632 (0.621 sec/batch), lr: 0.003000\n","2024-03-17 15:13:05 INFO: Finished STEP 840/1000, loss = 2.101761 (0.679 sec/batch), lr: 0.003000\n","2024-03-17 15:13:19 INFO: Finished STEP 860/1000, loss = 4.439549 (0.688 sec/batch), lr: 0.003000\n","2024-03-17 15:13:32 INFO: Finished STEP 880/1000, loss = 1.594052 (0.608 sec/batch), lr: 0.003000\n","2024-03-17 15:13:46 INFO: Finished STEP 900/1000, loss = 1.401607 (0.465 sec/batch), lr: 0.003000\n","2024-03-17 15:13:46 INFO: Evaluating on dev set...\n","2024-03-17 15:13:48 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:13:48 INFO: 84.54\t81.46\t82.32\n","2024-03-17 15:13:48 INFO: step 900: train_loss = 1.666835, dev_score = 0.8454\n","2024-03-17 15:13:49 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:13:49 INFO: new best model saved.\n","2024-03-17 15:13:50 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:13:50 INFO: new model checkpoint saved.\n","2024-03-17 15:14:04 INFO: Finished STEP 920/1000, loss = 1.734546 (0.598 sec/batch), lr: 0.003000\n","2024-03-17 15:14:18 INFO: Finished STEP 940/1000, loss = 2.617910 (0.845 sec/batch), lr: 0.003000\n","2024-03-17 15:14:31 INFO: Finished STEP 960/1000, loss = 1.415727 (0.567 sec/batch), lr: 0.003000\n","2024-03-17 15:14:45 INFO: Finished STEP 980/1000, loss = 0.907560 (0.522 sec/batch), lr: 0.003000\n","2024-03-17 15:14:58 INFO: Finished STEP 1000/1000, loss = 1.058603 (0.522 sec/batch), lr: 0.003000\n","2024-03-17 15:14:58 INFO: Evaluating on dev set...\n","2024-03-17 15:15:02 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:15:02 INFO: 84.85\t81.98\t82.95\n","2024-03-17 15:15:02 INFO: step 1000: train_loss = 1.618226, dev_score = 0.8485\n","2024-03-17 15:15:02 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:15:02 INFO: new best model saved.\n","2024-03-17 15:15:04 INFO: Model saved to saved_models/depparse/ru_gsd_charlm_parser_checkpoint.pt\n","2024-03-17 15:15:04 INFO: new model checkpoint saved.\n","2024-03-17 15:15:04 INFO: Training ended with 1000 steps.\n","2024-03-17 15:15:04 INFO: Best dev F1 = 84.85, at iteration = 1000\n","2024-03-17 15:15:04 INFO: Using default pretrain for language, found in /root/stanza_resources/ru/pretrain/conll17.pt  To use a different pretrain, specify --wordvec_pretrain_file\n","2024-03-17 15:15:04 INFO: Running dev depparse for UD_Russian-GSD with args ['--wordvec_dir', '../data/wordvec', '--eval_file', '../data/processed/depparse/ru_gsd.dev.in.conllu', '--output_file', '/tmp/tmptgv9l2b2', '--gold_file', '../data/processed/depparse/ru_gsd.dev.gold.conllu', '--lang', 'ru', '--shorthand', 'ru_gsd', '--mode', 'predict', '--wordvec_pretrain_file', '/root/stanza_resources/ru/pretrain/conll17.pt', '--charlm', '--charlm_shorthand', 'ru_newswiki', '--charlm_forward_file', '/root/stanza_resources/ru/forward_charlm/newswiki.pt', '--charlm_backward_file', '/root/stanza_resources/ru/backward_charlm/newswiki.pt', '--max_steps', '1000']\n","2024-03-17 15:15:04 INFO: Running parser in predict mode\n","2024-03-17 15:15:04 INFO: Loading model from: saved_models/depparse/ru_gsd_charlm_parser.pt\n","2024-03-17 15:15:04 DEBUG: Loaded pretrain from /root/stanza_resources/ru/pretrain/conll17.pt\n","2024-03-17 15:15:04 DEBUG: Depparse model loading charmodels: /root/stanza_resources/ru/forward_charlm/newswiki.pt and /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:15:04 DEBUG: Loading charlm from /root/stanza_resources/ru/forward_charlm/newswiki.pt\n","2024-03-17 15:15:04 DEBUG: Loading charlm from /root/stanza_resources/ru/backward_charlm/newswiki.pt\n","2024-03-17 15:15:05 DEBUG: Building Adam with lr=0.003000, betas=(0.9, 0.95), eps=0.000001\n","2024-03-17 15:15:05 INFO: Loading data with batch size 5000...\n","2024-03-17 15:15:05 DEBUG: 3 batches created.\n","2024-03-17 15:15:07 INFO: F1 scores for each dependency:\n","  Note that unlabeled attachment errors hurt the labeled attachment scores\n","          acl: p 0.6937 r 0.5969 f1 0.6417 (129 actual)\n","    acl:relcl: p 0.6709 r 0.7361 f1 0.7020 (72 actual)\n","        advcl: p 0.6379 r 0.5362 f1 0.5827 (69 actual)\n","       advmod: p 0.8378 r 0.7911 f1 0.8138 (359 actual)\n","         amod: p 0.9701 r 0.9724 f1 0.9713 (1234 actual)\n","        appos: p 0.5952 r 0.6167 f1 0.6057 (360 actual)\n","          aux: p 0.4000 r 0.5000 f1 0.4444 (4 actual)\n","     aux:pass: p 0.9394 r 0.9254 f1 0.9323 (67 actual)\n","         case: p 0.9718 r 0.9654 f1 0.9686 (1214 actual)\n","           cc: p 0.8934 r 0.9211 f1 0.9071 (355 actual)\n","        ccomp: p 0.5385 r 0.4516 f1 0.4912 (31 actual)\n","     compound: p 1.0000 r 0.6667 f1 0.8000 (9 actual)\n","         conj: p 0.7160 r 0.7024 f1 0.7092 (578 actual)\n","          cop: p 0.6522 r 0.7143 f1 0.6818 (21 actual)\n","        csubj: p 0.0000 r 0.0000 f1 0.0000 (1 actual)\n","          dep: p 0.0000 r 0.0000 f1 0.0000 (0 actual)\n","          det: p 0.9613 r 0.9430 f1 0.9521 (158 actual)\n","         expl: p 1.0000 r 0.6667 f1 0.8000 (3 actual)\n","        fixed: p 0.8421 r 0.8276 f1 0.8348 (58 actual)\n","         flat: p 0.9792 r 1.0000 f1 0.9895 (47 actual)\n"," flat:foreign: p 0.7087 r 0.8654 f1 0.7792 (104 actual)\n","    flat:name: p 0.8200 r 0.8913 f1 0.8542 (138 actual)\n","     goeswith: p 0.0000 r 0.0000 f1 0.0000 (2 actual)\n","         iobj: p 0.5270 r 0.5270 f1 0.5270 (74 actual)\n","         list: p 0.3056 r 0.3548 f1 0.3284 (31 actual)\n","         mark: p 0.7571 r 0.9138 f1 0.8281 (58 actual)\n","         nmod: p 0.8037 r 0.8383 f1 0.8206 (1416 actual)\n","        nsubj: p 0.8419 r 0.8923 f1 0.8664 (585 actual)\n","   nsubj:pass: p 0.8421 r 0.9412 f1 0.8889 (85 actual)\n","       nummod: p 0.7656 r 0.7538 f1 0.7597 (65 actual)\n","nummod:entity: p 0.4706 r 0.8000 f1 0.5926 (10 actual)\n","   nummod:gov: p 0.9368 r 0.8558 f1 0.8945 (104 actual)\n","          obj: p 0.8918 r 0.7556 f1 0.8180 (360 actual)\n","          obl: p 0.8691 r 0.8327 f1 0.8505 (813 actual)\n","    obl:agent: p 0.6296 r 0.4359 f1 0.5152 (39 actual)\n","       orphan: p 0.6667 r 0.2000 f1 0.3077 (10 actual)\n","    parataxis: p 0.4659 r 0.3565 f1 0.4039 (115 actual)\n","        punct: p 0.8310 r 0.8317 f1 0.8313 (2240 actual)\n","         root: p 0.9585 r 0.9585 f1 0.9585 (579 actual)\n","        xcomp: p 0.6912 r 0.8393 f1 0.7581 (112 actual)\n","2024-03-17 15:15:08 INFO: LAS\tMLAS\tBLEX\n","2024-03-17 15:15:08 INFO: 84.85\t81.98\t82.95\n","2024-03-17 15:15:08 INFO: Parser score:\n","2024-03-17 15:15:08 INFO: ru_gsd 84.85\n","2024-03-17 15:15:09 INFO: Finished running dev set on\n","UD_Russian-GSD\n","  UAS   LAS  CLAS  MLAS  BLEX\n","88.76 84.85 82.95 81.98 82.95\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"dvObytnDGf4K"}},{"cell_type":"code","source":["# Función para imprimir por pantalla la evaluación, como el conll18_ud_eval tiene esta implementación en main,\n","# se hace un wrapper para emplearlo como función fuera del script\n","def print_eval(verbose:bool, counts:bool, evaluation):\n","  if not verbose and not counts:\n","    print(\"LAS F1 Score: {:.2f}\".format(100 * evaluation[\"LAS\"].f1))\n","    print(\"MLAS Score: {:.2f}\".format(100 * evaluation[\"MLAS\"].f1))\n","    print(\"BLEX Score: {:.2f}\".format(100 * evaluation[\"BLEX\"].f1))\n","  else:\n","    if counts:\n","      print(\"Metric     | Correct   |      Gold | Predicted | Aligned\")\n","    else:\n","      print(\"Metric     | Precision |    Recall |  F1 Score | AligndAcc\")\n","    print(\"-----------+-----------+-----------+-----------+-----------\")\n","    for metric in[\"Tokens\", \"Sentences\", \"Words\", \"UPOS\", \"XPOS\", \"UFeats\", \"AllTags\", \"Lemmas\", \"UAS\", \"LAS\", \"CLAS\", \"MLAS\", \"BLEX\"]:\n","      if counts:\n","        print(\"{:11}|{:10} |{:10} |{:10} |{:10}\".format(\n","        metric,\n","        evaluation[metric].correct,\n","        evaluation[metric].gold_total,\n","        evaluation[metric].system_total,\n","        evaluation[metric].aligned_total or (evaluation[metric].correct if metric == \"Words\" else \"\")\n","        ))\n","      else:\n","        print(\"{:11}|{:10.2f} |{:10.2f} |{:10.2f} |{}\".format(\n","        metric,\n","        100 * evaluation[metric].precision,\n","        100 * evaluation[metric].recall,\n","        100 * evaluation[metric].f1,\n","        \"{:10.2f}\".format(100 * evaluation[metric].aligned_accuracy) if evaluation[metric].aligned_accuracy is not None else \"\"\n","        ))"],"metadata":{"id":"EnK0aJQvGf4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/gdrive/MyDrive/PLN/3')\n","import conll18_ud_eval as conll"],"metadata":{"id":"7KYloc8tyMdM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### SpaCy"],"metadata":{"id":"Bor3e25mGf4N"}},{"cell_type":"code","source":["!pip install spacy_conll"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710333181883,"user_tz":-60,"elapsed":8432,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"45668938-5e64-459e-ab80-81ea3df20110","id":"SHVHEiS_Gf4N"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting spacy_conll\n","  Downloading spacy_conll-3.4.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: spacy>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from spacy_conll) (3.7.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (4.66.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (2.6.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.1.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=3.0.1->spacy_conll) (1.25.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (2.16.3)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.0.1->spacy_conll) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.1->spacy_conll) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->spacy_conll) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=3.0.1->spacy_conll) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy>=3.0.1->spacy_conll) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy>=3.0.1->spacy_conll) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=3.0.1->spacy_conll) (2.1.5)\n","Installing collected packages: spacy_conll\n","Successfully installed spacy_conll-3.4.0\n"]}]},{"cell_type":"code","source":["import spacy_conll"],"metadata":{"id":"b_kojlklGf4O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### EL"],"metadata":{"id":"MM3X6q4-Gf4O"}},{"cell_type":"code","source":["nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/Trained/model-best\")\n","config = {\"include_headers\": True}\n","nlp.add_pipe(\"conll_formatter\", config=config, last=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710333218848,"user_tz":-60,"elapsed":1472,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"a097e024-3c87-4cc0-f6ec-6c7955fad82d","id":"Di6w8d5YGf4O"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConllFormatter(conversion_maps=None, ext_names={'conll_str': 'conll_str', 'conll': 'conll', 'conll_pd': 'conll_pd'}, field_names={'ID': 'ID', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'UPOS': 'UPOS', 'XPOS': 'XPOS', 'FEATS': 'FEATS', 'HEAD': 'HEAD', 'DEPREL': 'DEPREL', 'DEPS': 'DEPS', 'MISC': 'MISC'}, include_headers=True, disable_pandas=False)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/EL/el_gdt_gold_test.conllu\""],"metadata":{"id":"okr66C9EGf4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"g5w0MdwXGf4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  of.write(doc._.conll_str)\n","  of.write('\\n')"],"metadata":{"id":"e0m8r1lMGf4P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"RXU7ePXTGf4Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710333324285,"user_tz":-60,"elapsed":241,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"acd9654d-d633-4dc4-e338-f36deb1dbcd4","id":"dmUZZWZrGf4Q"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     10407 |     10422 |     10431 |          \n","Sentences  |       401 |       456 |       439 |          \n","Words      |     10157 |     10672 |     10431 |     10157\n","UPOS       |      9734 |     10672 |     10431 |     10157\n","XPOS       |      9718 |     10672 |     10431 |     10157\n","UFeats     |      9088 |     10672 |     10431 |     10157\n","AllTags    |      8915 |     10672 |     10431 |     10157\n","Lemmas     |      9076 |     10672 |     10431 |     10157\n","UAS        |      8659 |     10672 |     10431 |     10157\n","LAS        |      7894 |     10672 |     10431 |     10157\n","CLAS       |      3847 |      5633 |      5164 |      5624\n","MLAS       |      3100 |      5633 |      5164 |      5624\n","BLEX       |      3272 |      5633 |      5164 |      5624\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.77 |     99.86 |     99.81 |\n","Sentences  |     91.34 |     87.94 |     89.61 |\n","Words      |     97.37 |     95.17 |     96.26 |\n","UPOS       |     93.32 |     91.21 |     92.25 |     95.84\n","XPOS       |     93.16 |     91.06 |     92.10 |     95.68\n","UFeats     |     87.12 |     85.16 |     86.13 |     89.48\n","AllTags    |     85.47 |     83.54 |     84.49 |     87.77\n","Lemmas     |     87.01 |     85.04 |     86.02 |     89.36\n","UAS        |     83.01 |     81.14 |     82.06 |     85.25\n","LAS        |     75.68 |     73.97 |     74.81 |     77.72\n","CLAS       |     74.50 |     68.29 |     71.26 |     68.40\n","MLAS       |     60.03 |     55.03 |     57.42 |     55.12\n","BLEX       |     63.36 |     58.09 |     60.61 |     58.18\n"]}]},{"cell_type":"markdown","source":["##### ZH"],"metadata":{"id":"BVYFcGlxGf4Q"}},{"cell_type":"code","source":["nlp = spacy.load(\"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/Trained/model-best\")\n","config = {\"include_headers\": True}\n","nlp.add_pipe(\"conll_formatter\", config=config, last=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710336488426,"user_tz":-60,"elapsed":2050,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"b662d930-14f3-494a-e97e-51614633d15d","id":"yeZ_pb2TGf4Q"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConllFormatter(conversion_maps=None, ext_names={'conll_str': 'conll_str', 'conll': 'conll', 'conll_pd': 'conll_pd'}, field_names={'ID': 'ID', 'FORM': 'FORM', 'LEMMA': 'LEMMA', 'UPOS': 'UPOS', 'XPOS': 'XPOS', 'FEATS': 'FEATS', 'HEAD': 'HEAD', 'DEPREL': 'DEPREL', 'DEPS': 'DEPS', 'MISC': 'MISC'}, include_headers=True, disable_pandas=False)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/b/Spacy/ZH/zh_gsd_gold_test.conllu\""],"metadata":{"id":"2DpiNQY0Gf4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"59zTv6JNGf4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","with open(output_file, 'w') as of:\n","  of.write(doc._.conll_str)\n","  of.write('\\n')"],"metadata":{"id":"SoQamOXnGf4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"JBchIspCGf4R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710336573264,"user_tz":-60,"elapsed":231,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"ea120397-5406-4363-f652-7f769b1a8281","id":"bx8gKPJEGf4R"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |      6157 |     12012 |     19206 |          \n","Sentences  |       240 |       500 |      1084 |          \n","Words      |      6157 |     12012 |     19206 |      6157\n","UPOS       |      5488 |     12012 |     19206 |      6157\n","XPOS       |      5580 |     12012 |     19206 |      6157\n","UFeats     |      6014 |     12012 |     19206 |      6157\n","AllTags    |      5394 |     12012 |     19206 |      6157\n","Lemmas     |      6157 |     12012 |     19206 |      6157\n","UAS        |      1455 |     12012 |     19206 |      6157\n","LAS        |      1296 |     12012 |     19206 |      6157\n","CLAS       |       445 |      7782 |     14124 |      2205\n","MLAS       |       364 |      7782 |     14124 |      2205\n","BLEX       |       445 |      7782 |     14124 |      2205\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     32.06 |     51.26 |     39.45 |\n","Sentences  |     22.14 |     48.00 |     30.30 |\n","Words      |     32.06 |     51.26 |     39.45 |\n","UPOS       |     28.57 |     45.69 |     35.16 |     89.13\n","XPOS       |     29.05 |     46.45 |     35.75 |     90.63\n","UFeats     |     31.31 |     50.07 |     38.53 |     97.68\n","AllTags    |     28.08 |     44.91 |     34.56 |     87.61\n","Lemmas     |     32.06 |     51.26 |     39.45 |    100.00\n","UAS        |      7.58 |     12.11 |      9.32 |     23.63\n","LAS        |      6.75 |     10.79 |      8.30 |     21.05\n","CLAS       |      3.15 |      5.72 |      4.06 |     20.18\n","MLAS       |      2.58 |      4.68 |      3.32 |     16.51\n","BLEX       |      3.15 |      5.72 |      4.06 |     20.18\n"]}]},{"cell_type":"markdown","source":["#### Stanza"],"metadata":{"id":"jMQ-Fe58Gf4S"}},{"cell_type":"code","source":["from stanza.utils.conll import CoNLL"],"metadata":{"id":"KHDLuSMOya-c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### EL"],"metadata":{"id":"pwngD_khGf4S"}},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/udbase/UD_Greek-GDT/el_gdt-ud-test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/b/Stanza/EL_output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/processed/depparse/el_gdt.test.gold.conllu\""],"metadata":{"id":"eDuv8S9zyfml"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = stanza.Pipeline('el', processors='tokenize,pos,lemma,depparse', use_gpu=True,\n","                      tokenize_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/tokenize/el_gdt_tokenizer.pt',\n","                      pos_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/pos/el_gdt_nocharlm_tagger.pt',\n","                      depparse_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/depparse/el_gdt_nocharlm_parser.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424,"referenced_widgets":["f50785f4b2784255baf4558cddf98dae","29b1eeab5f1247ec8cfe2e2e2907e498","b36b97f51ceb4ba0b4c7293e683e7b83","98dce7c1d29e4dc49c2aa1c12ef12c78","6387b73078ff49fda582a7e13a224ca5","daf627957dcb46eea10ad8ece7c77a49","a185bd4dd53843c8a023cc1425a2396e","d2e7ee324f064007a69f8862c7697545","7f3baf0aeab74b4c9da89c6fe871b0f7","0439068979034bc5bf8f20f0d25106f6","d44762014b3f48fda32cc49ae4d91993"]},"executionInfo":{"status":"ok","timestamp":1710689029171,"user_tz":-60,"elapsed":1726,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"fc4fa9fc-3079-4fc2-8116-8bab42b93b79","id":"d9x12TuIyfmm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50785f4b2784255baf4558cddf98dae"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n","WARNING:stanza:Language el package default expects mwt, which has been added\n","INFO:stanza:Loading these models for language: el (Greek):\n","=======================================\n","| Processor | Package                 |\n","---------------------------------------\n","| tokenize  | /content/g...kenizer.pt |\n","| mwt       | gdt                     |\n","| pos       | /content/g..._tagger.pt |\n","| lemma     | gdt_nocharlm            |\n","| depparse  | /content/g..._parser.pt |\n","=======================================\n","\n","INFO:stanza:Using device: cuda\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: mwt\n","INFO:stanza:Loading: pos\n","INFO:stanza:Loading: lemma\n","INFO:stanza:Loading: depparse\n","INFO:stanza:Done loading processors!\n"]}]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"xtvLAUA4yfmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","CoNLL.write_doc2conll(doc, output_file)"],"metadata":{"id":"cmaM7kjAyfmm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"UUo8EQmMyfmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710689062850,"user_tz":-60,"elapsed":204,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"26ca68ae-339b-4aee-f311-c1c0414f4fcb","id":"Veb6FRyoyfmn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     10395 |     10422 |     10444 |          \n","Sentences  |       399 |       456 |       442 |          \n","Words      |     10643 |     10672 |     10693 |     10643\n","UPOS       |     10641 |     10672 |     10693 |     10643\n","XPOS       |     10641 |     10672 |     10693 |     10643\n","UFeats     |     10633 |     10672 |     10693 |     10643\n","AllTags    |     10633 |     10672 |     10693 |     10643\n","Lemmas     |     10240 |     10672 |     10693 |     10643\n","UAS        |      9537 |     10672 |     10693 |     10643\n","LAS        |      9237 |     10672 |     10693 |     10643\n","CLAS       |      4560 |      5633 |      5630 |      5609\n","MLAS       |      4486 |      5633 |      5630 |      5609\n","BLEX       |      4284 |      5633 |      5630 |      5609\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.53 |     99.74 |     99.64 |\n","Sentences  |     90.27 |     87.50 |     88.86 |\n","Words      |     99.53 |     99.73 |     99.63 |\n","UPOS       |     99.51 |     99.71 |     99.61 |     99.98\n","XPOS       |     99.51 |     99.71 |     99.61 |     99.98\n","UFeats     |     99.44 |     99.63 |     99.54 |     99.91\n","AllTags    |     99.44 |     99.63 |     99.54 |     99.91\n","Lemmas     |     95.76 |     95.95 |     95.86 |     96.21\n","UAS        |     89.19 |     89.36 |     89.28 |     89.61\n","LAS        |     86.38 |     86.55 |     86.47 |     86.79\n","CLAS       |     80.99 |     80.95 |     80.97 |     81.30\n","MLAS       |     79.68 |     79.64 |     79.66 |     79.98\n","BLEX       |     76.09 |     76.05 |     76.07 |     76.38\n"]}]},{"cell_type":"markdown","source":["##### RU"],"metadata":{"id":"Euai4Dw4Gf4S"}},{"cell_type":"code","source":["input_file = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/udbase/UD_Russian-GSD/ru_gsd-ud-test.txt\"\n","output_file = \"/content/gdrive/MyDrive/PLN/3/b/Stanza/RU_output.conllu\"\n","gold_standard = \"/content/gdrive/MyDrive/PLN/3/stanza-train/data/processed/depparse/ru_gsd.test.gold.conllu\""],"metadata":{"id":"NgojLxArymLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nlp = stanza.Pipeline('ru', processors='tokenize,pos,lemma,depparse', use_gpu=True,\n","                      tokenize_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/tokenize/ru_gsd_tokenizer.pt',\n","                      pos_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/pos/ru_gsd_charlm_tagger.pt',\n","                      depparse_model_path = '/content/gdrive/MyDrive/PLN/3/stanza-train/stanza/saved_models/depparse/ru_gsd_charlm_parser.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":499,"referenced_widgets":["9bef3d218eed4ece933caec2887099ed","2fb3704833844045bd6702f6ba806c5d","7608631d25bd4c9aa3c08bb123384d20","6968157f5531408ca20aa16e06bd5a81","46814b3b2edd49f5afaf563e705f47f0","06865aeda00f4ac9a3b145df05a51913","56a22399db0147129312199298aee76c","7f6a9fe9e7d7475e92cd170de6689c63","42dcfa0e80b046fea76763cf16ecf58b","c991073a117a46be97acbf9b802eaa81","eaa0c134fd124f26b3f4781f7ac33576","6ca4ae733d5543cf8a0368e72c9a4146","1edc6fa3be0741e6b1ba86556d588c7d","de3206b40f3240679cd760b0e8330d70","f496c5f7f887463692270ff0f190395e","62bb6af2f3ed414696dc810902c9c58c","97cc4c0b625743e0a2602269a0c2bc35","18864426d29b4ee68a7d99e0085b6169","0a29aadbc7aa4e39b8d9b1ec9b18ea6f","f4f55b43c456458e95c2465c0f99ce2a","876c68bbd15a44de919f7efb5e1b9e41","dc171a3f94474a2c913e02380bcc2852","1c167801ef664f9b82f93ee7a585e148","8a55239c124b4847b2f1a722c1a5e097","003a127f7de44397a3e62ea91382b859","71e654423b674d469fb66f866218f4b6","90989651f0e548078bdc0a7810579cc7","cd797a8636bd4b8a887dc5dd1168d623","777b5308aec64be1bf97bea98fb7c167","a3ea1b08caa3448a87fbc1a703a8ed43","babd3748a7d84299a7afcf419c2f689d","35566139333549f4a6d87cde53983fd4","b05fb043f30e4eb795c858953f60e72c","c258837b4c5e47c6a03d8e07530a8760","2f533087aa2d4a48b62752f270b364d8","b1b8650baf7441d9850df538f133f691","4f003351e6664c29bc0fdd1da0b41df2","68ed1d8e8b854457b19f9b67889a9091","c17ed8d25fba440e928f7d932ccf76df","e29fbd283fb64bd68cb2331c25031695","84fe3705b637423898ce8ae2ad0ea935","db1f9cd9c4f24633b4c18679ab476de4","eb04f3e043784b8ab95fd8dc51c67081","f61566ea259f419daaf1661a974a8f8e","ff0f3acc08f940f0b8b8f23069fb2d70","21ff49fcc05a4f1f8f14ef5eaa20e1a7","5f660bdf8fa44170831a288cee1ff9e5","357d202d412042fcbc8ef3ab684bc1d4","4245d8d606384b589e34a918fdfe42c7","0ff61a4b781e4792b100d3712ba6d893","086e0a7d66984e8e90a053eccc43ad7c","e85bc099a97a467fae6310ffbab241d0","e5e3c1ec1b3c433e8c89b40baa30ce56","2dbbb7f18cad4f59a20412b648589faa","68ac7220e695437499571bd993e32371"]},"executionInfo":{"status":"ok","timestamp":1710689091438,"user_tz":-60,"elapsed":7613,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"fc4ba283-19ff-429f-e68f-9e9aaa07df10","id":"_2O-f2LkymLe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bef3d218eed4ece933caec2887099ed"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/tokenize/syntagrus.pt:   0%|   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca4ae733d5543cf8a0368e72c9a4146"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/pos/syntagrus_charlm.pt:   0%| …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c167801ef664f9b82f93ee7a585e148"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/lemma/syntagrus_nocharlm.pt:   …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c258837b4c5e47c6a03d8e07530a8760"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading https://huggingface.co/stanfordnlp/stanza-ru/resolve/v1.8.0/models/depparse/syntagrus_charlm.pt:  …"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff0f3acc08f940f0b8b8f23069fb2d70"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:stanza:Loading these models for language: ru (Russian):\n","=======================================\n","| Processor | Package                 |\n","---------------------------------------\n","| tokenize  | /content/g...kenizer.pt |\n","| pos       | /content/g..._tagger.pt |\n","| lemma     | syntagrus_nocharlm      |\n","| depparse  | /content/g..._parser.pt |\n","=======================================\n","\n","INFO:stanza:Using device: cuda\n","INFO:stanza:Loading: tokenize\n","INFO:stanza:Loading: pos\n","INFO:stanza:Loading: lemma\n","INFO:stanza:Loading: depparse\n","INFO:stanza:Done loading processors!\n"]}]},{"cell_type":"code","source":["with open(input_file, 'r') as file:\n","  t_input = re.sub(\"\\s\\s+\", \" \", \" \".join(file.read().splitlines()))\n","doc = nlp(t_input)"],"metadata":{"id":"-Xk0SvtaymLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Se guarda el texto procesado en el archivo de salida.\n","CoNLL.write_doc2conll(doc, output_file)"],"metadata":{"id":"V-fo9DZKymLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gold = conll.load_conllu_file(gold_standard)\n","test = conll.load_conllu_file(output_file)\n","metrics = conll.evaluate(gold, test)"],"metadata":{"id":"LQvnwoE4ymLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print_eval(True, True, metrics)\n","print('\\n')\n","print_eval(True, False, metrics)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710689107517,"user_tz":-60,"elapsed":206,"user":{"displayName":"David Perez Roman","userId":"16259599937444749915"}},"outputId":"93a8f5e2-77e8-4933-9c04-5d3edeae017f","id":"QYV97vMdymLf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metric     | Correct   |      Gold | Predicted | Aligned\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     11329 |     11385 |     11391 |          \n","Sentences  |       574 |       601 |       598 |          \n","Words      |     11329 |     11385 |     11391 |     11329\n","UPOS       |     11329 |     11385 |     11391 |     11329\n","XPOS       |     11325 |     11385 |     11391 |     11329\n","UFeats     |     11317 |     11385 |     11391 |     11329\n","AllTags    |     11314 |     11385 |     11391 |     11329\n","Lemmas     |     10666 |     11385 |     11391 |     11329\n","UAS        |     10007 |     11385 |     11391 |     11329\n","LAS        |      9559 |     11385 |     11391 |     11329\n","CLAS       |      5993 |      7343 |      7349 |      7304\n","MLAS       |      5917 |      7343 |      7349 |      7304\n","BLEX       |      5539 |      7343 |      7349 |      7304\n","\n","\n","Metric     | Precision |    Recall |  F1 Score | AligndAcc\n","-----------+-----------+-----------+-----------+-----------\n","Tokens     |     99.46 |     99.51 |     99.48 |\n","Sentences  |     95.99 |     95.51 |     95.75 |\n","Words      |     99.46 |     99.51 |     99.48 |\n","UPOS       |     99.46 |     99.51 |     99.48 |    100.00\n","XPOS       |     99.42 |     99.47 |     99.45 |     99.96\n","UFeats     |     99.35 |     99.40 |     99.38 |     99.89\n","AllTags    |     99.32 |     99.38 |     99.35 |     99.87\n","Lemmas     |     93.64 |     93.68 |     93.66 |     94.15\n","UAS        |     87.85 |     87.90 |     87.87 |     88.33\n","LAS        |     83.92 |     83.96 |     83.94 |     84.38\n","CLAS       |     81.55 |     81.62 |     81.58 |     82.05\n","MLAS       |     80.51 |     80.58 |     80.55 |     81.01\n","BLEX       |     75.37 |     75.43 |     75.40 |     75.84\n"]}]}]}